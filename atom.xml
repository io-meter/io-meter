<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[IO-meter]]></title>
  <subtitle><![CDATA[Programic Creativity]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="https://io-meter.com/"/>
  <updated>2021-10-18T13:14:31.029Z</updated>
  <id>https://io-meter.com/</id>
  
  <author>
    <name><![CDATA[Chase Zhang]]></name>
    <email><![CDATA[yun.er.run@gmail.com]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[TiFlink: 使用TiKV和Flink实现强一致的物化视图]]></title>
    <link href="https://io-meter.com/2021/10/18/tiflink/"/>
    <id>https://io-meter.com/2021/10/18/tiflink/</id>
    <published>2021-10-18T13:00:00.000Z</published>
    <updated>2021-10-18T13:14:31.029Z</updated>
    <content type="html"><![CDATA[<p>在本年初的TiDB Hackathon上，我和一众队友尝试使用Flink为TiDB添加物化视图功能，并摘得了“最佳人气奖”。可以说，物化视图在这届比赛中可谓是一个热点。单单是结合Flink实现相关功能的队伍就有三四个。必须承认的是，在比赛结束时我们项目的完成度很低，虽然基本思路已经定型，最终呈现的结果却远没达到预期。经过半年多断断续续的修补，在今天终于可以发布一个<a href="https://github.com/TiFlink/TiFlink">预览版本</a>给大家试用。这篇文章就是对我们思路和成果的一个介绍。</p>
<a id="more"></a>
<p>相比其他队伍，我们的主要目标是实现强一致的物化视图构建。也就是保证查询时的物化视图可以达到接近快照隔离（Snapshot Isolation）的隔离级别，而不是一般流处理系统的最终一致性（Eventual Consistency）。关于实现一致性的讨论在下文有详细介绍。</p>
<h2 id="u4F7F_u7528_u7B80_u4ECB"><a href="#u4F7F_u7528_u7B80_u4ECB" class="headerlink" title="使用简介"></a>使用简介</h2><p>尽管是一个实验性的项目，我们仍然探索了一些方便实用的特性，包括：</p>
<ol>
<li>零外部依赖：除了TiDB集群和Flink部署环境之外，无需维护任何其他组件（包括Kafka集群和TiCDC）。这是因为TiFlink直接从TiKV读写数据，不经过任何中间层，为更高吞吐、更低延迟和更易维护创造了可能</li>
<li>易用的接口：尽管为了实现强一致性TiFlink引进了一些新的概念，但是通过特别编写的<code>TiFlinkApp</code> 接口，用户可以快速启动一个任务，也无需手动创建写入目标表</li>
<li>批流结合：任务启动后会先批量消费源表当前已有的数据，随后自动切换到CDC日志消费。这个过程也会确保视图的一致性</li>
</ol>
<p>关于TiFlink实用的详细信息，请参考<a href="https://github.com/TiFlink/TiFlink/blob/main/README.md">README</a>。下面是快速启动一个任务的代码片段：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">TiFlinkApp.newBuilder()</span><br><span class="line">   .setJdbcUrl(<span class="string">&quot;jdbc:mysql://root@localhost:4000/test&quot;</span>) <span class="comment">// Please make sure the user has correct permission</span></span><br><span class="line">   .setQuery(</span><br><span class="line">       <span class="string">&quot;select id, &quot;</span></span><br><span class="line">           + <span class="string">&quot;first_name, &quot;</span></span><br><span class="line">           + <span class="string">&quot;last_name, &quot;</span></span><br><span class="line">           + <span class="string">&quot;email, &quot;</span></span><br><span class="line">           + <span class="string">&quot;(select count(*) from posts where author_id = authors.id) as posts &quot;</span></span><br><span class="line">           + <span class="string">&quot;from authors&quot;</span>)</span><br><span class="line">   <span class="comment">// .setColumnNames(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) // Override column names inferred from the query</span></span><br><span class="line">   <span class="comment">// .setPrimaryKeys(&quot;a&quot;) // Specify the primary key columns, defaults to the first column</span></span><br><span class="line">   <span class="comment">// .setDefaultDatabase(&quot;test&quot;) // Default TiDB database to use, defaults to that specified by JDBC URL</span></span><br><span class="line">   .setTargetTable(<span class="string">&quot;author_posts&quot;</span>) <span class="comment">// TiFlink will automatically create the table if not exist</span></span><br><span class="line">   <span class="comment">// .setTargetTable(&quot;test&quot;, &quot;author_posts&quot;) // It is possible to sepecify the full table path</span></span><br><span class="line">   .setParallelism(<span class="number">3</span>) <span class="comment">// Parallelism of the Flink Job</span></span><br><span class="line">   .setCheckpointInterval(<span class="number">1000</span>) <span class="comment">// Checkpoint interval in milliseconds. This interval determines data refresh rate</span></span><br><span class="line">   .setDropOldTable(<span class="keyword">true</span>) <span class="comment">// If TiFlink should drop old target table on start</span></span><br><span class="line">   .setForceNewTable(<span class="keyword">true</span>) <span class="comment">// If to throw an error if the target table already exists</span></span><br><span class="line">   .build()</span><br><span class="line">   .start(); <span class="comment">// Start the app</span></span><br></pre></td></tr></table></figure>
<h3 id="u7269_u5316_u89C6_u56FE_uFF08_u6D41_u5904_u7406_u7CFB_u7EDF_uFF09_u7684_u4E00_u81F4_u6027"><a href="#u7269_u5316_u89C6_u56FE_uFF08_u6D41_u5904_u7406_u7CFB_u7EDF_uFF09_u7684_u4E00_u81F4_u6027" class="headerlink" title="物化视图（流处理系统）的一致性"></a>物化视图（流处理系统）的一致性</h3><p>目前主流的物化视图（流处理）系统主要使用最终一致性。也就是说尽管最终结果会收敛到一致的状态，但在处理期间终端用户仍可能查询到一些不一致的结果。最终一致性在很多应用中被证明是足够的，那么更强的一致性是否真的需要呢？这里的一致性和Flink的Exact Once语义又有什么关系呢？有必要进行一些介绍。</p>
<h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><p>ACID是数据库的一个基本的概念。一般来说，作为CDC日志来源的数据库已经保证了这四条要求。但是在使用CDC数据进行流式处理的时候，其中的某些约束却有可能被破坏。</p>
<p>最典型的情况是失去Atomic特性。这是因为在CDC 日志中，一个事务的修改可能覆盖多条记录，流处理系统如果以行为单位进行处理，就有可能破坏原子性。也就是说，在结果集上进行查询的用户看到的事务是不完整的。</p>
<p>一个典型的案例如下：</p>
<p><img src="/img/posts/Table_ACID.jpg" alt="Change Log与原子性"></p>
<p>在上述案例中，我们有一个账户表，账户表之间会有转账操作，由于转账操作涉及多行修改，因此往往会产生多条记录。假设我们有如下一条SQL定义的物化视图，计算所有账户余额的总和：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">SUM</span>(balance) <span class="keyword">FROM</span> ACCOUNTS;</span><br></pre></td></tr></table></figure>
<p>显然，如果我们只存在表内账户之间的转账，这个查询返回的结果应该恒为某一常数。但是由于目前一般的流处理系统不能处理事务的原子性，这条查询产生的结果却可能是不断波动的。实际上，在一个不断并发修改的源表上，其波动甚至可能是无界的。</p>
<p>尽管在最终一致的模型下，上述查询的结果在经过一段时间之后将会收敛到正确值，但没有原子性保证的物化视图仍然限制的应用场景：假设我想实现一个当上述查询结果偏差过大时进行报警的工具，我就有可能会接收到很多虚假报警。也就是说此时在数据库端并没有任何异常，数值的偏差只是来源于流处理系统内部。</p>
<p>在分布式系统中，还有另一种破坏原子性的情况，就是当一个事务修改产生的副作用分布在多个不同的节点处。如果在这时不使用2PC等方法进行分布式提交，则也会破坏原子性：部分节点（分区）上的修改先于其他节点生效，从而出现不一致。</p>
<h3 id="u7EBF_u6027_u4E00_u81F4_u6027"><a href="#u7EBF_u6027_u4E00_u81F4_u6027" class="headerlink" title="线性一致性"></a>线性一致性</h3><p>不同于由单机数据库产生的CDC日志（如MySQL的Binlog），TiDB这类分布式数据库产生的日志会有线性一致性的问题。在我们的场景下，线性一致性的问题可以描述为：从用户的角度先后执行的一些操作，其产生的副作用（日志）由于消息系统传递的延迟，以不同的先后顺序被流处理系统处理。</p>
<p>假设我们有订单表（ORDERS）和付款信息表（PAYMENTS）两个表，用户必须先创建订单才能进行支付，因此下列查询的结果必然是正数：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">WITH</span> order_amount <span class="keyword">AS</span> (<span class="keyword">SELECT</span> <span class="keyword">SUM</span>(amount) <span class="keyword">AS</span> total <span class="keyword">FROM</span> ORDERS),</span><br><span class="line"><span class="keyword">WITH</span> payment_amount <span class="keyword">AS</span> (<span class="keyword">SELECT</span> <span class="keyword">SUM</span>(amount) <span class="keyword">AS</span> total <span class="keyword">FROM</span> PAYMENTS)</span><br><span class="line"><span class="keyword">SELECT</span> order_amount.total - payment_amount.total</span><br><span class="line"><span class="keyword">FROM</span> order_amount, payment_amount;</span><br></pre></td></tr></table></figure>
<p>但是由于ORDERS表和PAYMENTS表在分别存储在不同的节点上，因此流处理系统消费他们的速度可能是不一致的。也就是说，流处理系统可能已经看到了支付信息的记录，但是其对应的订单信息还没到达。因此就可能观察到上述查询出现负数的结果。</p>
<p>在流处理系统中，有一个Watermark的概念可以用来同步不同表的数据的处理进度，但是它并不能避免上述线性一致性问题。这是因为Watermark只要求时间戳小于其的所有记录都已经到达，不要求时间戳大于其的记录都没有到达。也就是说，尽管ORDERS表和PAYMENTS表现在拥有相同的Watermark，后者仍然可能会有一些先到的记录已经生效。</p>
<p>由此可见，单纯依靠Watermark本身是无法处理线性一致性问题的，必须和源数据库的时间产生系统和消息系统配合。</p>
<h3 id="u66F4_u5F3A_u4E00_u81F4_u6027_u7684_u9700_u6C42"><a href="#u66F4_u5F3A_u4E00_u81F4_u6027_u7684_u9700_u6C42" class="headerlink" title="更强一致性的需求"></a>更强一致性的需求</h3><p>尽管最终一致性在很多场景下是够用的，但其依然存在很多问题：</p>
<ol>
<li>误导用户：由于很多用户并不了解一致性相关的知识，或者对其存在一定的误解，导致其根据尚未收敛的查询结果做出了决策。这种情况在大部分关系型数据库都默认较强一致性的情况下是应该避免的</li>
<li>可观测性差：由于最终一致性并没有收敛时间的保证，再考虑到线性一致性问题的存在，很难对流处理系统的延迟、数据新鲜度、吞吐量等指标进行定义。比如说用户看到的JOIN的结果可能是表A当前的快照和表B十分钟前的快照联接的结果，此时应如何定义查询结果的延迟度呢？</li>
<li>限制了部分需求的实现：正如上文所提到的，由于不一致的内部状态，导致某些告警需求要么无法实现，要么需要延迟等待一段时间。否则用户就不得不接受较高的误报率</li>
</ol>
<p>实际上，更强一致性的缺乏还导致了一些运维操作，特别是DDL类的操作难以利用之前计算好的结果。参考关系型数据库和NoSQL数据库的发展历史，我们相信目前主流的最终一致性只是受限于技术发展的权宜之计，随着相关理论和技术研究的进步，更强的一致性将会慢慢成为流处理系统的主流。</p>
<h2 id="u6280_u672F_u65B9_u6848_u7B80_u4ECB"><a href="#u6280_u672F_u65B9_u6848_u7B80_u4ECB" class="headerlink" title="技术方案简介"></a>技术方案简介</h2><p>这里详细介绍一下TiFlink在技术方案上的考虑，以及如何实现了强一致的物化视图（StreamSQL）维护。</p>
<h3 id="TiKV_u548CFlink"><a href="#TiKV_u548CFlink" class="headerlink" title="TiKV和Flink"></a>TiKV和Flink</h3><p>尽管这是一个TiDB Hackthon项目，因此必然会选择TiDB/TiKV相关的组件，但是在我看来TiKV作为物化视图系统的中间存储方案具备很多突出的优势：</p>
<ol>
<li>TiKV是一个比较成熟分布式KV存储，而分布式环境是下一代物化视图系统必须要支持的场景。利用TiKV配套的Java Client，我们可以方便的对其进行操作。同时TiDB本身作为一个HTAP系统，正好为物化视图这个需求提供了一个Playground</li>
<li>TiKV提供了基于Percolator模型的事务支持和MVCC，这是TiFlink实现强一致流处理的基础。在下文中可以看到，TiFlink对TiKV的写入主要是以接连不断的事务的形式进行的</li>
<li>TiKV原生提供了对CDC日志输出的支持。实际上TiCDC组件正是利用这一特性实现的CDC日志导出功能。在TiFlink中，为了实现批流一体并简化系统流程，我们选择直接调用TiKV的CDC GRPC接口，因此也放弃了TiCDC提供的一些特性</li>
</ol>
<p>我们最初的想法本来是直接将计算功能集成进TiKV，选择Flink则是在比赛过程中进一步思考后得到的结论。选择Flink的主要优势有：</p>
<ol>
<li>Flink是目前市面上最成熟的Stateful流处理系统，其对处理任务的表达能力强，支持的语义丰富，特别是支持批流一体的StreamSQL实现，是我们可以专心于探索我们比较关注的功能，如强一致性等</li>
<li>Flink比较完整地Watermark，而我们发现其基于Checkpoint实现的Exactly Once Delivery语义可以很方便地和TiKV结合来实现事务处理。实际上，Flink自己提供的一些支持Two Phase Commit的Sink就是结合Checkpoint来进行提交的</li>
<li>Flink的流处理（特别是StreamSQL）本身就基于物化视图的理论，在比较新的版本开始提供的DynamicTable接口，就是为了方便将外部的Change Log引入系统。它已经提供了对INSERT、DELETE、UPDATE等多种CDC操作的支持</li>
</ol>
<p>当然，选择TiKV+Flink这样的异构架构也会引入一些问题，比如SQL语法的不匹配，UDF无法共享等问题。在TiFlink中，我们以Flink的SQL系统和UDF为准，将其作为TiKV的一个外挂系统使用，但同时提供了方便的建表功能。</p>
<h3 id="u5F3A_u4E00_u81F4_u7684_u7269_u5316_u89C6_u56FE_u7684_u5B9E_u73B0_u601D_u8DEF"><a href="#u5F3A_u4E00_u81F4_u7684_u7269_u5316_u89C6_u56FE_u7684_u5B9E_u73B0_u601D_u8DEF" class="headerlink" title="强一致的物化视图的实现思路"></a>强一致的物化视图的实现思路</h3><p>这一部分将介绍TiFlink如何在TiDB/TiKV的基础上实现一个比较强的一致性级别：延迟快照隔离（Stale Snapshot Isolation）。在这种隔离级别下，查询者总是查询到历史上一个一致的快照状态。在传统的快照隔离中，要求查询者在$T$时间能且只能观察到Commit时间小于$T$的所有事务。而延迟快照隔离只能保证观察到$T-\Delta t$之前所有已提交的事务。</p>
<p>在TiDB这样支持事务的分布式数据库上实现强一致的物化视图，最简单的思路就是使用一个接一个的事务来更新视图。事务在开始时读取到的是一个一致的快照，而使用分布式事务对物化视图进行更新，本身也是一个强一致的操作，且具有ACID的特性，因此得以保证一致性。</p>
<p><img src="/img/posts/Transaction_To_MV.jpg" alt="使用连续的事务实现物化视图的更新"></p>
<p>为了将Flink和这样的机制结合起来且实现增量维护，我们利用了TiKV本身已经提供的一些特性：</p>
<ol>
<li>TiKV使用Time Oracle为所有的操作分配时间戳，因此虽然是一个分布式系统，其产生的CDC日志中的事务的时间戳实际上是有序的</li>
<li>TiKV的节点（Region）可以产生连续不断的增量日志（Change Log），这些日志包含了事务的各种原始信息并包含时间戳信息</li>
<li>TiKV的增量日志会定期产生Resolved Timestamp，声明当前Region不再会产生时间戳更老的消息。因此很适合用来做Watermark</li>
<li>TiKV提供了分布式事务，允许我们控制一批修改的可见性</li>
</ol>
<p>因此TiFlink的基本实现思路就是：</p>
<ol>
<li>利用流批一体的特性，以某全局时间戳对源表进行快照读取，此时可以获得所有源表的一个一致性视图</li>
<li>切换到增量日志消费，利用Flink的DynamicTable相关接口，实现物化视图的增量维护和输出</li>
<li>以一定的节奏Commit修改，使得所有的修改以原子的事务方式写入目标表，从而为物化视图提供一个又一个更新视图</li>
</ol>
<p>以上几点的关键在于协调各个节点一起完成分布式事务，因此有必要介绍一下TiKV的分布式事务执行原理。</p>
<h3 id="TiKV_u7684_u5206_u5E03_u5F0F_u4E8B_u52A1"><a href="#TiKV_u7684_u5206_u5E03_u5F0F_u4E8B_u52A1" class="headerlink" title="TiKV的分布式事务"></a>TiKV的分布式事务</h3><p>TiKV的分布式事务基于著名的Percolator模型。Percolator模型本身要求存储层的KV Store有MVCC的支持和单行读写的原子性和乐观锁（OCC）。在此基础上它采用以下步骤完成一次事务：</p>
<ol>
<li>指定一个事务主键（Primary Key）和一个开始时间戳并写入主键</li>
<li>其他行在Prewrite时以副键（Secondary Key）的形式写入，副键会指向主键并具有上述开始时间戳</li>
<li>在所有节点Prewrite完成后，可以提交事务，此时应先Commit主键，并给定一个Commit时间戳</li>
<li>主键Commit成功后事务实际上已经提交成功，但此时为了方便读取，可以多节点并发地对副键进行Commit并执行清理工作，之后写入的行都将变为可见</li>
</ol>
<p>上述分布式事务之所以可行，是因为对主键的Commit是原子的，分布在不同节点的副键是否提交成功完全依赖于主键，因此其他的读取者在读到Prewrite后但还没Commit的行时，会去检查主键是否已Commit。读取者也会根据Commit时间戳判断某一行数据是否可见。Cleanup操作如果中途故障，在之后的读取者也可以代行。</p>
<p>为了实现快照隔离，Percolator要求写入者在写入时检查并发的Prewrite记录，保证他们的时间戳符合一定的要求才能提交事务。本质上是要求写入集重叠的事务不能同时提交。在我们的场景中假设物化视图只有一个写入者且事务是连续的，因此无需担心这点。</p>
<p>在了解了TiKV的分布式事务原理之后，要考虑的就是如何将其与Flink结合起来。在TiFlink里，我们利用Checkpoint的机制来实现全局一致的事务提交。</p>
<h3 id="u4F7F_u7528Flink_u8FDB_u884C_u5206_u5E03_u5F0F_u4E8B_u52A1_u63D0_u4EA4"><a href="#u4F7F_u7528Flink_u8FDB_u884C_u5206_u5E03_u5F0F_u4E8B_u52A1_u63D0_u4EA4" class="headerlink" title="使用Flink进行分布式事务提交"></a>使用Flink进行分布式事务提交</h3><p>从上面的介绍可以看出，TiKV的分布式事务提交可以抽象为一次2PC。Flink本身有提供实现2PC的Sink，然而并不能直接用在我们的场景下。原因是Percolator模型在提交时需要有全局一致的事务开始时间戳和提交时间戳。而且仅仅是在Sink端实现2PC是不足以实现强一致隔离级别的：我们还需要在Source端配合，使得每个事务恰好读入所需的增量日志。</p>
<p>幸运的是，Flink的2PC提交机制实际上是由Checkpoint驱动的：当Sink接收到Checkpoint请求时，会完成必要的任务以进行提交。受此启发，我们可以实现一对Source和Sink，让他们使用Checkpoint的ID共享Transaction的信息，并配合Checkpoint的过程完成2PC。而为了使不同节点可以对事务的信息（时间戳，主键）等达成一致，需要引入一个全局协调器。事务和全局协调器的接口定义如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Transaction</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">Status</span> </span>&#123;</span><br><span class="line">    NEW,</span><br><span class="line">    PREWRITE,</span><br><span class="line">    COMMITTED,</span><br><span class="line">    ABORTED;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">long</span> <span class="title">getCheckpointId</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">long</span> <span class="title">getStartTs</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">default</span> <span class="keyword">long</span> <span class="title">getCommitTs</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">default</span> <span class="keyword">byte</span>[] getPrimaryKey();</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">default</span> Status <span class="title">getStatus</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Coordinator</span> <span class="keyword">extends</span> <span class="title">AutoCloseable</span>, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="function">Transaction <span class="title">openTransaction</span><span class="params">(<span class="keyword">long</span> checkpointId)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Transaction <span class="title">prewriteTransaction</span><span class="params">(<span class="keyword">long</span> checkpointId, <span class="keyword">long</span> tableId)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Transaction <span class="title">commitTransaction</span><span class="params">(<span class="keyword">long</span> checkpointId)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="function">Transaction <span class="title">abortTransaction</span><span class="params">(<span class="keyword">long</span> checkpointId)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用上述接口，各个Source和Sink节点可以使用CheckpointID开启事务或获得事务ID，协调器会负责分配主键并维护事务的状态。为了方便起见，事务Commit时对主键的提交操作也放在协调器中执行。协调器的实现有很多方法，目前TiFlink使用最简单的实现：在JobManager所在进程中启动一个GRPC服务。基于TiKV的PD（ETCD）或TiKV本身实现分布式的协调器也是可能的。</p>
<p><img src="/img/posts/TiFlink_transaction_management.jpg" alt="事务与Checkpoint的协调执行"></p>
<p>上图展示了在Flink中执行分布式事务和Checkpoint之间的协调关系。一次事务的具体过程如下：</p>
<ol>
<li>Source先从TiKV接收到增量日志，将他们按照时间戳Cache起来，等待事务的开始</li>
<li>当Checkpoint进程开始时，Source会先接收到信号。在Source端的Checkpoint与日志接收服务运行在不同的线程中</li>
<li>Checkpoint线程先通过全局协调器获得当前事务的信息（或开启一个新事务），分布式情况下一个CheckpointID对应的事务只会开启一次</li>
<li>得到事务的开始时间戳后，Source节点开始将Cache中小于此时间戳的已提交修改Emit到下游计算节点进行消费。此时Source节点也会Emit一些Watermark</li>
<li>当所有Source节点完成上述操作后，Checkpoint在Source节点成功完成，此后会向后继续传播，根据Flink的机制，Checkpoint在每个节点都会保证其到达之前的所有Event都已被消费</li>
<li>当Checkpoint到达Sink时，之前传播到Sink的Event都已经被Prewrite过了，此时可以开始事务的提交过程。Sink在内部状态中持久化事务的信息，以便于错误时恢复，在所有Sink节点完成此操作后，会在回调中调用协调器的Commit方法从而提交事务</li>
<li>提交事务后，Sink会启动线程进行Secondary Key的清理工作，同时开启一个新的事务</li>
</ol>
<p>注意到，在第一个Checkpoint开始前，Sink可能已经开始接收到写入的数据了，而此时它还没有事务的信息。为了解决这一问题，TiFlink在任务开始时会直接启动一个初始事务，其对应的CheckpointID是0，用于提交最初的一些写入。这样的话，在<code>CheckpointID=1</code>的Checkpoint完成时，实际上提交的是这个0事务。事务和Checkpoint以这样的一种错位的方式协调执行。</p>
<p>下图展示了包含协调器在内的整个TiFlink任务的架构：</p>
<p><img src="/img/posts/TiFlink_System_Design.jpg" alt="TiFlink的系统架构"></p>
<p>基于以上的系统设计，我们就得到了一个在TiKV上实现延迟快照隔离的物化视图。</p>
<h3 id="u5176_u4ED6_u8BBE_u8BA1_u8003_u8651"><a href="#u5176_u4ED6_u8BBE_u8BA1_u8003_u8651" class="headerlink" title="其他设计考虑"></a>其他设计考虑</h3><p>众所周知，KSQL是Flink之外另一个流行的流处理系统，它直接与Kafka消息队列系统结合，用户无需部署两套处理系统，因此受到一些用户的青睐。很多用户也使用KSQL实现类似物化视图这样的需求。然而在我看来，这种强耦合于消息队列的流处理系统并不适合物化视图的使用场景。</p>
<p>KSQL可以说是Log Oriented数据处理系统的的代表，在这种系统中，数据的本源在于日志信息，所有的表都是为了方便查询而消费日志信息从而构建出来的视图。这种系统具有模型简单、容易实现、可以长时间保存日志记录等优点。</p>
<p>与之相对是Table Oriented数据处理系统，MySQL、TiDB/TiKV都属于这一类系统。这一类系统的所有修改操作都作用于表数据结构，虽然期间也会有日志生成，但往往对表数据结构和日志的修改是一起协调进行的。这里日志的主要是为持久化和事务服务，往往不会留存太长时间。相比于Log Oriented数据处理系统，这类系统对写入和事务的处理都更为复杂一点，然而却拥有更强可扩展性的要求。</p>
<p>归根结底，这是因为Log Oriented系统中的数据是以日志的形式存储，因此在扩展时往往需要进行成本较高的Rehash，也更难实现再平衡。而Table Oriented的系统，数据主要以表的形式存储，因此可以以某些列进行有序排列，从而方便在一致性Hash的支持下实现Range的切分、合并和再平衡。</p>
<p>个人认为，在批流一体的物化视图场景下，长时间保存日志并无太大的意义（因为总是可以从源表的快照恢复数据）。相反，随着业务的发展不断扩展数据处理任务和视图是一件比较重要的事。从这个角度来看Table Oriented系统似乎更适合作为物化视图需求的存储承载介质。</p>
<p>当然，在实时消费增量Log时发生的分区合并或分裂是一个比较难处理的问题。TiKV在这种情况下会抛出一个GRPC错误。TiFlink目前使用的是比较简单的静态映射方法处理任务和分区之间的关系，在未来可以考虑更为合理的解决方案。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了使用Flink在TiKV上实现强一致的物化视图的基本原理。以上原理已经基本上在TiFlink系统中实现，欢迎各位读者试用。以上所有的讨论都基于Flink的最终一致模型的保证，即：流计算的结果只与消费的Event和他们在自己流中的顺序有关，与他们到达系统的顺序以及不同流之间的相对顺序无关。</p>
<p>目前的TiFlink系统还有很多值得提高的点，如：</p>
<ol>
<li>支持非Integer型主键和联合主键</li>
<li>更好的TiKV Region到Flink任务的映射</li>
<li>更好的Fault Tolerance和任务中断时TiKV事务的清理工作</li>
<li>完善的单元测试</li>
</ol>
<p>如果各位读者对TiFlink感兴趣的话，欢迎试用并提出反馈意见，如果能够贡献代码帮助完善这个系统那就再好不过了。</p>
<p>关于物化视图系统一致性的思考是我今年最主要的收获之一。实际上，最初我们并没有重视这一方面，而是在不断地交流当中才认识到这是一个有价值且很有挑战性的问题。通过TiFlink的实现，可以说是基本上验证了上述方法实现延迟快照一致性的可行性。当然，由于个人的能力水平有限，如果存在什么纰漏，也欢迎各位提出讨论。</p>
<p>最后，如果我们假设上述延迟快照一致性的论述是正确的，那么实现真正的快照隔离的方法也就呼之欲出。不知道各位读者能否想到呢？</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在本年初的TiDB Hackathon上，我和一众队友尝试使用Flink为TiDB添加物化视图功能，并摘得了“最佳人气奖”。可以说，物化视图在这届比赛中可谓是一个热点。单单是结合Flink实现相关功能的队伍就有三四个。必须承认的是，在比赛结束时我们项目的完成度很低，虽然基本思路已经定型，最终呈现的结果却远没达到预期。经过半年多断断续续的修补，在今天终于可以发布一个<a href="https://github.com/TiFlink/TiFlink">预览版本</a>给大家试用。这篇文章就是对我们思路和成果的一个介绍。</p>]]>
    
    </summary>
    
      <category term="Distributed System" scheme="https://io-meter.com/tags/Distributed-System/"/>
    
      <category term="Materialized View" scheme="https://io-meter.com/tags/Materialized-View/"/>
    
      <category term="Flink" scheme="https://io-meter.com/tags/Flink/"/>
    
      <category term="TiFlink" scheme="https://io-meter.com/tags/TiFlink/"/>
    
      <category term="TiKV" scheme="https://io-meter.com/tags/TiKV/"/>
    
      <category term="TiDB" scheme="https://io-meter.com/tags/TiDB/"/>
    
      <category term="Transaction" scheme="https://io-meter.com/tags/Transaction/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Nvm Store: 第二届阿里数据库大赛参赛记录]]></title>
    <link href="https://io-meter.com/2020/12/12/nvm-store/"/>
    <id>https://io-meter.com/2020/12/12/nvm-store/</id>
    <published>2020-12-12T05:25:12.000Z</published>
    <updated>2020-12-13T08:55:25.098Z</updated>
    <content type="html"><![CDATA[<p>前段时间因兴趣使然，参加了第二届阿里数据库大赛，并成功冲入决赛。
本届数据库大赛的题目是在Intel提供的持久化内存（Persistent Memory）上实现一套KV Store。
持久化内存一直是数据库研究的一个新兴研究方向，十分高兴这次有机会在真正的持久化内存上实现系统并测试。
这里是我们参赛作品的一个介绍。</p>
<a id="more"></a>
<h2 id="u9898_u76EE_u7B80_u4ECB"><a href="#u9898_u76EE_u7B80_u4ECB" class="headerlink" title="题目简介"></a>题目简介</h2><p>本次数据库大赛的题目是在Intel Optane Persistent Memory上实现一套高性能的KV Store，
访问模式主要是随机访问。由于使用的是持久化内存，要求实现的系统能够持久化数据，
在系统Crash等场景下可以正确恢复。Key的写入要求是原子的，写入失败不能影响旧值。</p>
<p>测试使用16个线程写入随机键值对，每个线程写入大约20M条记录，随后会进行十次混合读写。
混合读写阶段的读写具有热点，以写入过程的时间和混合读写过程中最慢一次的时间作为成绩。
总共提供的PMEM大小是64G，但写入数据量会大于64G（因为有重复Key的写入）。
复赛阶段提供了8G DRAM以供使用。具体的题目描述请参见比赛<a href="https://tianchi.aliyun.com/competition/entrance/531820/information">官方网站的介绍</a>。
我所在的队伍在最后的决赛获得了季军（第四名）。</p>
<p>首先需要介绍一下Persistent Memory，这是一种插在内存插槽上的新兴存储设备，
在数据库领域是一个前沿研究热点。它具有类似DRAM的随机读取能力，但是能在掉电之后保持数据不丢失。
与插在PCI-E/M.2插槽的所谓NVMe SSD不同，PMEM具有更细的访问粒度（8byte字长），
更强的随机访问能力。但我们在测试中发现，它的性能相比DRAM还有一定的差距。</p>
<p>PMEM目前的一种常用配置是将DRAM运行为CPU的L4 Cache，使用单位容量价格较低的PMEM作为主存，
这种方式可以使现有应用程序无痛迁移到PMEM上，且不会相比DRAM有太大的性能差异。
但是想要充分利用PMEM的性能，最佳方案仍然是设计专业的应用程序。
为此，需要使用<a href="https://pmem.io/pmdk/">PMDK</a>等工具直接访问PMEM。
Linux等操作系统也已经位PMEM提供的DAX功能，可以绕过操作系统的页面管理，直接写入PMEM。</p>
<p>本赛题的背景即是如此。对题目的信息进行分析，可以知道：</p>
<ol>
<li>写入数据量大于PMEM空间，说明存在大量的覆盖写，对Allocator的设计要求比较高</li>
<li>内存相对来说比较充裕，且PMEM相比DRAM的总体性能还是有一定差距，因此应该尽量将不需要持久化的数据维护在DRAM</li>
<li>并发写入的线程数较多，应该尽量使用Thread Local的数据结构，避免线程间同步。
必须要同步的地方使用细粒度锁</li>
</ol>
<p>此外，在测试的时候发现，本地使用DRAM虚拟的PMEM和硬件PMEM的特性差异较大，
因此需要尽量在实际硬件环境下测试才能得到有意义的结果，不能依赖本地试验结果。</p>
<p>在以上分析的基础上，我们的系统采用了如下设计。</p>
<h2 id="u6982_u89C8"><a href="#u6982_u89C8" class="headerlink" title="概览"></a>概览</h2><p>我们设计的系统架构图如下：</p>
<p><img src="/img/nvmstore/overview.jpg" alt="Overview"></p>
<p>总体来说，系统分为以下三个部分：</p>
<ol>
<li><strong>Hash Index</strong>：记录Key到Value映射的内存索引，实现查询和更新操作</li>
<li><strong>Allocator</strong>：用来管理Heap上的存储空间，实现空间的分配和回收</li>
<li><strong>Heap</strong>：用于写入数据记录的PMEM空间</li>
</ol>
<p>KV Store的读写操作都很简单，其中，写入操作使用类似影子分页
（<a href="https://zh.wikipedia.org/wiki/%E5%BD%B1%E5%AD%90%E5%88%86%E9%A1%B5">Shadow Paging</a>）
的方法：</p>
<ol>
<li>先使用Allocator分配一块新的Heap空间</li>
<li>直接将Record写入新分配的空间</li>
<li>更新Hash Index，指向新写入的地址</li>
</ol>
<p>读取也很简单：通过Hash Index找到Heap上的地址并读取即可。</p>
<h2 id="Heap"><a href="#Heap" class="headerlink" title="Heap"></a>Heap</h2><p>堆是存储实际数据的地方，它的设计关系到如何实现写入的持久化、原子性和可恢复性。
同时，写入堆的方式和堆上记录（Record）的写入方法也极大地关系到写入的性能。
下图展示了Heap的大致结构。</p>
<p><img src="/img/nvmstore/heap.jpg" alt="Heap, Block, Record"></p>
<p>在我们的系统中，Heap被划分为等长的Block，因此Heap内存的分配都是以Block为单位的。
Heap的第一个块用于写入Magic Number。Hash Index当中的Entry指向Record的地址，
而Allocator中会维护Heap中所有的空闲空间的位置。</p>
<p>Record是写入在Heap上的表示，它要记录所写入的Key和Value，并保证可以原子地写入数据并可以恢复。
下图是Record的结构的展示：</p>
<p><img src="/img/nvmstore/records.jpg" alt="Records"></p>
<p>Record由整数个Block构成，在Record的头部是存储元信息的Header，之后是Key和Value组成的Payload，
由于Record总是由整数个Block构成，因此在Record的结尾可能会有一部分冗余空间没有被利用。
Record中最重要的是Header，它的结构包括：</p>
<ul>
<li><strong>BlockSize</strong>：Record包含的Block的总数量，由于Value的长度小于1024，因此一条记录的总长度
总小于1048（Header+Key+Value），则BlockSize不大于17，可以用5个二进制位表示</li>
<li><strong>PayloadSize</strong>：存储Payload的实际长度，Payload最长不超过1040字节，因此可以用11个二进制位表示</li>
<li><strong>CRC16</strong>：由Payload的CRC校验折叠而成。用于保证Record写入的原子性</li>
<li><strong>Serial Number</strong>：Record的序列号，用于判断Record的先后顺序</li>
</ul>
<p>在Heap上写入Record的方法是先在内存中组装好一个Record，并写入Header中的字段，
然后使用<code>pmem_memcpy</code>命令的<code>NON_TEMPORAL</code>模式写入。在内存中组装Record的原因，
一方面是内存的访问性能仍然快于PMEM，另一方面是因为可以利用<code>NON_TEMPORAL</code>模式，
使用一次刷写持久化一整个Record。</p>
<p>所谓的<code>NON_TEMPORAL</code>写入，在一些文献中称为Stream写入。简单来说，一般CPU写入一段内存空间时，
会先将对应内存中的一个CacheLine加载到CPU的缓存中，进行修改之后再写回。也就是说，
正常情况下，即使你只在某个位置写入了几个Byte的数据，CPU仍然会把所在的CacheLine读入。
这在很多情况下显然是低效的，因此现代CPU提供了对应的指令，可以实现对CacheLine的直接刷写，
避免读入。PMEM作为一种特殊的内存，也适用于这些概念。</p>
<p>我们发现，使用CacheLine对齐的Buffer组装Record，并利用<code>NON_TEMPORAL</code>写入方式写入PMEM所得性能最高。
这也意味着我们必须将Heap上的Block设置为64Byte大小，并对齐到CacheLine。</p>
<p>虽然有了<code>NON_TEMPORAL</code>写入，仍不能保证写入Record的原子性。在这里
我们要保证写入的一个Record要么完整地写入成功，要么写入失败（不影响旧值）。
这是因为PMEM只能保证对一个字长（8Byte）写入的原子性，即使是一个CacheLine，
它也不能保证一定是整体写入成功或失败的。</p>
<p>因此，我们在Header中集成了CRC：由于Header被压缩在8个Byte，PMEM可以保证它的原子写入，
因此可以通过校验CRC判断整个Record是否合法。</p>
<p>Serial Number的作用则是用来判断Record的写入顺序，比如说有同一个Key，先后写入了两条数据，
第二条数据的值应该覆盖掉第一条。但是因为有内存回收的原因，第二条数据在文件中的位置可能更早，
因此需要它来判断哪一条更新，以避免恢复出旧值。我们在比赛时使用的是简单的线程本地计数器，
为了实现线程间的有序，可以考虑使用时间戳或全局递增计数器来实现，Serial Number也不必要放在Header里。</p>
<p>在本系统中，将BlockSize和PayloadSize分开存储，这是希望一旦一个Record的空间被分配出去之后，
就不再改变这一块空间的大小。也就是说，未来如果有其他不同长度的数据写到这里，BlockSize仍然不变。
这是因为BlockSize改变可能会导致恢复的问题，比如在一个原来长度10的Record所占位置写入长度5的数据，
如果更改了BlockSize并在此时Crash，则恢复进程可能找不到下一条记录的正确位置。
原因是可能出现Header写入成功但内容写入失败的现象。如果此时恢复进程按照Header中指示的BlockSize（5）
来跳转，会跳转到随机数据所在的位置。</p>
<p>以上设计保证了Record的写入原子性和持久性。恢复记录的算法就非常简单：</p>
<ol>
<li>检查PMEM文件的第一个块是否有Magic Number，如果有就开始恢复进程</li>
<li>依次读入记录，进行CRC校验，跳过校验失败的Record。将合法的Record登记到Hash Index上（Serial Number较大的胜出）</li>
<li>重复以上过程直到处理完所有能读出的Record</li>
</ol>
<h2 id="Hash_Index"><a href="#Hash_Index" class="headerlink" title="Hash Index"></a>Hash Index</h2><p>Hash Index也是系统设计中很重要的一部分，他的查询性能是KV Store性能的基础，
此外也需要在这上面实现合理的并发控制，保证多线程写入的一致性。我们设计的Hash Index
有如下特点：</p>
<ol>
<li>开放寻址（<a href="https://en.wikipedia.org/wiki/Open_addressing">Open Addressing</a>）</li>
<li>线性探查（<a href="https://en.wikipedia.org/wiki/Linear_probing">Linear Probing</a>）</li>
<li>Record地址使用<code>uint32</code>表示</li>
<li>Hash函数使用<a href="https://github.com/google/cityhash">CityHash</a></li>
<li>细粒度锁</li>
</ol>
<p>首先，受Google的<a href="https://github.com/abseil/abseil-cpp/blob/master/absl/container/flat_hash_map.h">Flat Hash Map</a>
启发，我们对计算出的Key的Hash值做了如下图所示处理：</p>
<p><img src="/img/nvmstore/hash.jpg" alt="Hash"></p>
<p>Hash值总共64bit，其中后15个bit被用作H2，剩下的bit被用于H1。H1用来寻址Key应在的Bucket，
H2则存放在HashMap的Bucket里。HashMap的Bucket具有如下图所示的构造：</p>
<p><img src="/img/nvmstore/hash-bucket.jpg" alt="Buckets"></p>
<p>HashMap的一个Bucket是对齐到CacheLine边界的连续三个CacheLine。
每个Bucket可以存放8条记录，从左到右，依次是lock段、ctrl段、value段、block size段和key段。
其中lock段通过原子操作实现细粒度的SpinLock；ctrl段存放8个H2值，用于进行快速比对；
value段存放Key对应的记录地址。block size段和key段通过将key和block size缓存在内存中，
避免写入阶段对PMEM的读取。</p>
<p>为什么要设计ctrl段呢？当我们使用H1找到一个Key应该在的Bucket之后，与其逐个比较每个Slot，
不如先使用H2探针来快速判断是否有匹配的Entry。具体来说，可以使用如下流程的SIMD指令，
在少数几个Instruction的操作下，快速以很高的概率查找到匹配的点。</p>
<p><img src="/img/nvmstore/simd-instructions.jpg" alt="SIMD Instructions"></p>
<p>在上述案例中，我们要查找的Key的H2值是<code>0x0F23</code>，在对应的Bucket的ctrl段在slot 2有匹配的值。
通过<code>_mm_cmpeq_epi16</code>和<code>_mm_movemask_epi8</code>指令操作之后，可以快速从16byte的ctrl段找到这个位置。
这里还利用了<code>__builtin_ffs</code>快速求解一个整型数值的第一个<code>1</code>的位置。</p>
<p>利用ctrl段可以减少Hash碰撞的概率和线性探查的长度：
传统HashMap在利用Hash值定位到某个位置后，需要向后逐个对比Key值来找到匹配的Entry，
通常不会存储之后的Key的Hash以供快速检查。使用我们（<code>flat_hash_map</code>）的解决方案，
实际相当于先用Hash的一部分寻找Bucket，再用另一部分进行快速比对，可以更充分地利用Hash值中的每一位。</p>
<p>在使用ctrl段找到一个匹配后，还需要再检查Key以避免碰撞的发生。在一开始的时候，我们的系统会去PMEM上读取Key的值，
后来发现这种混合读写对PMEM性能伤害很大。后来我们采取了将Key缓存在Bucket中的方案，这就是Bucket中的key段的来源。
后来，Block Size也被整合进来，使得无论是写入还是内存回收的时候都不需要访问PMEM，极大地提高了系统的性能。</p>
<p>在本系统的Hash Index的设计中，插入和更新操作会锁定对应的Bucket，由于每个Bucket只有8个slot，所以锁的粒度很细。
在查找操作的探查阶段，我们也不加锁，
这是参考了<a href="http://infoscience.epfl.ch/record/203822/files/Tech_report_CLHT_BSTTK.pdf">CLHT</a>的设计，
x86系统采用的<a href="https://en.wikipedia.org/wiki/MESIF_protocol">MESIF protocol</a>具有较强的Memory Order保证，
以及对短于一个字的内存读写的原子性。在查询阶段不加锁，不但可以避免锁等待，
还可以避免查询Miss的情况下对内存的任何写入。实际上，在多核强竞争场景下写入多核共享的CacheLine，
会导致CacheLine同步和核间通讯，因此可能大大降低性能。</p>
<p>但是值得注意的是，在命中记录开始读取值之前，要锁定Bucket以防止脏读。这是因为在并发线程同时读取一个Key时，
可能出现第1个线程先读到了Key对应记录的地址，第二个线程写入同一个Key，回收了此前的记录，
然后又在第2个写入中利用了这个地址的情况。此时就会出现两个线程对同一段内存的并发读写，触发脏读。
下图展示了这种情况：</p>
<p><img src="/img/nvmstore/read-value-consistency.jpg" alt="Read Consistency"></p>
<h2 id="Allocator"><a href="#Allocator" class="headerlink" title="Allocator"></a>Allocator</h2><p>Allocator是整个系统当中最核心的部分，他的性能和策略设计，直接决定了系统的性能。
在我们的系统中，每个线程都有自己本地的Allocator。Heap空间被预先分配给16个线程。
每个线程的分配策略是先从头开始进行连续写（类似Log-Structured），
随后开始从Allocator记录的空闲空间开始利用，最后使用保留段。基本策略如下图所示：</p>
<p><img src="/img/nvmstore/alloc-strategies.jpg" alt="Allocate Strategies"></p>
<p>Allocator主要由块状链表组成，不同长度的空闲空间根据它们的Block长度不同，被放置在不同的块状链表中。
每个块状链表的节点存储着一系列空闲空间的地址，并使用一个<code>top</code>指针指向下一个地址存放的位置。
块状链表的块使用<code>next</code>指针相连。为了避免频繁的内存分配，我们对块状链表的块使用了Memory Pool。
使用块状链表的原因是为了在保证Alloc和Free取出和存放地址都是<code>O(1)</code>同时，避免随机内存访问和提高内存利用率。 
块状链表比静态分配Stack更灵活。</p>
<p>给定一条记录，我们可以先计算出他所需要的Block数，然后在Allocator中从下到上寻找可以放入这条记录的最小空闲空间。
默认不改变对应空间原来的BlockSize，有可能出现把短记录放在很长的空闲段里，导致空间浪费和OOM，
为此必须要考虑修改长段的长度。在比赛中，我们采用的是在Alloc切分一段空间前，先在后面写入块来维护元数据，
保证恢复进程可以跳转。后来跟其他参赛选手交流后发现，逐块扫描校验CRC也许是一种更好的实现。</p>
<p>下图展示了切分段的解决方法，在将长10的空闲段切开时，先在后面写入一块帮助恢复进程找到跳转位置，
再返回前面的空间。</p>
<p><img src="/img/nvmstore/split-long-space.jpg" alt="Split Long Space"></p>
<p>除此之外，我们在Allocator中加入了一个<code>short_alloc</code>字段，
用来在上述情况中，将长段的第二部分放在Allocator的头，在alloc的时候优先检查它。
由于大部分写入的值长度都比较短，因此大概率<code>short_alloc</code>当中的空间会被立即使用，
之后如果有剩余的空间仍然放在<code>short_alloc</code>里，因此可以获得局部的连续写入。</p>
<p>上面提到，分配给每个Allocator管理的段在末尾还有一段保留段。
这是因为有切分块的存在，上述策略对短块友好，因此Heap会越切越细。
如果有长记录的写入到来，可能会出现找不到连续长空间的问题。
为此增加一段保留段，在Allocator分配不出长空间时启用保留段，
避免OOM。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>我们首先实现了PMEM上高性能KV Store的基础框架，它具有以下特性：</p>
<ol>
<li>保证了写入的原子性和持久性</li>
<li>实现了基于SIMD指令快速查找和细粒度锁的Hash Index</li>
<li>实现了简单高效且适应性强的Allocator</li>
</ol>
<p>在第一阶段我们实现了大约54秒的测试成绩。之后我们将Block Size和Key信息缓存在Hash Index
中，使得写入和Free空间时无需读取PMEM，立即使得成绩提升了8秒到达46秒左右。</p>
<p>最后我们尝试了在内存中组装Record，使用64byte的Block，
并对齐到CacheLine。再配合<code>NON_TEMPORAL</code>写入模式，达到了我们的最佳成绩36秒。</p>
<p>这一成绩距离第2名和第3名的成绩差距不到1秒，应该说是一个级别的实现方案了。
综合来看我们的方案在实现并发控制、持久化和原子性方面的细节方面是比较周到的：</p>
<ol>
<li>使用了CRC校验保证记录写入的完整性</li>
<li>使用细粒度的Hash Index锁保证并发性能</li>
<li>使用Serial Number保证记录的恢复顺序</li>
<li>对切分块场景下的恢复提出了合理的方案</li>
</ol>
<p>个人认为我们的方案没有特别地利用测试程序的访问模式，通用性非常好。
虽然没有能够拿到更好的名次，总体来说还是非常令人满意的。</p>
<p>在本方案的基础上，参考其他队伍的解决方案，我觉得还有以下一些可以提高的地方：</p>
<ol>
<li>使用HugePage或使用预热TLB的方法来减少Page Fault。有其他参赛选手通过预热TLB获得了可观的性能提升，
但是我觉得在实际生产环境中配置HugePage来减少页表大小是更好的手段。在比赛时有考虑过相关实现，
遗憾的是发现HugePage在测试环境中无法激活后我就放弃了这个方向</li>
<li>实现内存碎片整理。目前的解决方案会出现不断碎片化的问题，被切碎的空间即使相连也不会互相合并，
这主要是考虑到实现的复杂性和性能问题。在实际生产环境中，有必要添加内存碎片整理机制，定期合并碎片以获得连续段</li>
<li>增加写入的连续性。事实表明，顺序写入PMEM相比于随机写仍然有相当可观的性能提升。
冠军队伍通过利用这一特性获得了超过我们数秒的提升。然而遗憾的是，冠军队伍的实现利用了测试程序访问模式的弱点
（先写入的记录会先被覆盖，因此前段的空间大概率会有连续空闲段）。实际工作负载中是否有此模式是存疑的，
而且冠军队伍的实现在空闲空间不连续的情况下会退化成线性扫描，我相信这方面仍然是可以提高的</li>
</ol>
<h2 id="u53C2_u8D5B_u611F_u60F3"><a href="#u53C2_u8D5B_u611F_u60F3" class="headerlink" title="参赛感想"></a>参赛感想</h2><p>这是我第一次参加类似的编程竞赛，很高兴最后能拿奖。特别是在比赛的过程中还学到了很多东西：
在比赛前，我对C++编程语言、内存模型、Memory Order、并发控制等的了解都比较肤浅，在这个比赛中，
我了解到很多内存管理和编写高性能应用的知识。比如：在此之前，
我从来都没有想过内存对象在内存中的地址会对软件的性能产生巨大影响，对齐到CacheLine之后竟然能获得数十秒的性能提升。
也没想过存在于同一CacheLine的两个锁竟然会有False Sharing，两个线程分别对这样的两个锁加锁，
竟然会互相干扰并导致性能退化！可以说涉及到系统调用、TLB、指令集和CPU Cache级别的性能优化技巧让我大开眼界。</p>
<p>编写如此接近硬件的程序让我对C++（以及其他系统编程语言）和高性能编程产生了浓厚的兴趣。
希望未来还可以在这个方向上继续学习。</p>
<p>最后，我们实现的KV Store<a href="https://github.com/shanzi/NvmEngine">在Github上开源</a>，以供参考。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>前段时间因兴趣使然，参加了第二届阿里数据库大赛，并成功冲入决赛。
本届数据库大赛的题目是在Intel提供的持久化内存（Persistent Memory）上实现一套KV Store。
持久化内存一直是数据库研究的一个新兴研究方向，十分高兴这次有机会在真正的持久化内存上实现系统并测试。
这里是我们参赛作品的一个介绍。</p>]]>
    
    </summary>
    
      <category term="database" scheme="https://io-meter.com/tags/database/"/>
    
      <category term="kv" scheme="https://io-meter.com/tags/kv/"/>
    
      <category term="memory" scheme="https://io-meter.com/tags/memory/"/>
    
      <category term="hashmap" scheme="https://io-meter.com/tags/hashmap/"/>
    
      <category term="allocator" scheme="https://io-meter.com/tags/allocator/"/>
    
      <category term="NVM" scheme="https://io-meter.com/tags/NVM/"/>
    
      <category term="Persistent Memory" scheme="https://io-meter.com/tags/Persistent-Memory/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[SIGMOD 16 | How to Architect a Query Compiler]]></title>
    <link href="https://io-meter.com/2020/02/24/how-to-architect-a-query-compiler/"/>
    <id>https://io-meter.com/2020/02/24/how-to-architect-a-query-compiler/</id>
    <published>2020-02-24T10:29:55.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>这篇发表在 SIGMOD 16 的论文来自洛桑联邦理工学院（EFPL），这所学校在计算机领域以Scala编程语言的发源地而闻名于世。不出意外，这篇论文虽然发表于数据处理相关顶会，却弥漫着浓厚的函数式编程和PL的气氛。连系统实现和代码样例都使用 Scala 描述。</p>
<a id="more"></a>
<p>从研究的依赖关系上，本文是之前介绍过的同样来自EFPL的研究<a href="https://zhuanlan.zhihu.com/p/89644696" target="_blank" rel="noopener">LegoBase</a>的延伸。本文在之前从Scala编译到C语言的系统之上，进一步地建立起了多层次的查询编译器架构，并提出了一套实现易操控和可维护的SQL查询编译系统的方法论。</p>
<h2 id="u7B80_u4ECB"><a href="#u7B80_u4ECB" class="headerlink" title="简介"></a>简介</h2><p>SQL编译查询不是新鲜事物。在Hekaton，Impala，Presto，MemSQL和Calcite当中都有使用。由于现阶段OLAP任务的主要瓶颈还在于IO，各个系统对相关领域的研究不算深入。其中Java系的大数据处理平台很多使用<a href="https://janino-compiler.github.io/janino/" target="_blank" rel="noopener">Janino</a>作为Bytecode编译器，也有很多系统将查询翻译成C/C++语言，并使用GCC/Clang或直接使用LLVM进行处理。本文指出，现阶段很多查询编译系统仍然停留在模板展开（template expander）的层次，简单来说也就是拼接代码和进行Operator调用内联（inlining）。本文指出，这类查询编译结局方案缺乏应用多种编程语言优化技术的能力，且需要的规则数和代码量随着算子数量的上升，至少以 N^2 的速度上升。此外，目前的解决方案也很难利用编译器来直接支持 Pipeline。</p>
<p>本文的解决方案在于为查询编译实现专门的DSL，而且是实现一系列堆叠起来的具有不同表现力和底层操控能力的DSL。在这一堆栈的最上层是最接近于关系模型的QPlan和QMonad DSL，这一层次的DSL非常的声明式（Declarative）。相反，在这一堆栈的最下层是C.Scala——一个几乎可以直接逐句翻译成C语言的DSL。显然，在最上层，用户得到的是抽象程度高的编程语言，在这一层次用户可以使用非常简洁地表示查询，也方便应用很多PL优化算法，但缺乏对程序细节（内存分配、数据结构、执行顺序等）的控制，也难以进行性能调优。在最下层，用户得到了一个非常接近硬件的命令式的DSL，因此可以对执行细节进行详细的操控，但是程序的表现力减弱且应用各种编译优化技巧变得困难起来。实际上，为了平衡这两者，本论文提出在两个极端之间插入多种中间DSL语言，在每个层次应用不同层次的PL优化技术。同时，在编译时，使用逐层下降的方法将高层次的语言（SQL）翻译成低层次的语言（C）从而实现模块化并提高可维护性。下图展示了本文提出的DSL堆栈。</p>
<p><img src="img/DSL-stack.png" alt=""></p>
<p>总体来说，在堆栈的每个层次，系统都会完成两项任务：</p>
<ul>
<li>应用适合于当前层次的编程语言优化规则和算法，在当前层次对执行方案进行优化</li>
<li>进行数据结构特化，即将某种抽象的数据结构（List，Map，MultiMap）等，具体化更低层次的抽象（ArrayList，LinkedList，HashMap，TreeMap等）</li>
</ul>
<p>经过这两步处理，高层次的DSL会被下降为低层次的DSL，直到最终的C语言实现，所有的内存管理和数据结构就都被具体化了，可以通过编译来直接执行。</p>
<h2 id="DSL__u5806_u6808"><a href="#DSL__u5806_u6808" class="headerlink" title="DSL 堆栈"></a>DSL 堆栈</h2><p>本文使用Scala语言实现了名为ScaLite的DSL，这一DSL吸取了函数式编程思想。本文指出，函数式编程的语言介于纯声明式语言（SQL）和纯命令式语言（C）之间，是作为插入DSL层的理想选择。而且这类语言易于理解和推理，可以复用PL社区的研究成果，也便于计算机进行抽象处理并应用一些编程语言优化算法。在这里，论文着重介绍了函数式编程的不可变性（Immutability）为程序分析带来的好处——具有副作用的编程语言语句有时很难使用算法进行分析和优化。</p>
<p>从抽象到具体，本文提出的DSL堆栈主要有一下几个层次：</p>
<h3 id="SQL__u5C42"><a href="#SQL__u5C42" class="headerlink" title="SQL 层"></a>SQL 层</h3><p>SQL层就是最上层用户交互的层次，它包括传统数据库优化的技术栈，如使用算子和关系代数描述语句，并可以使用Volcano/Cascades模型对关系代数进行优化。在本文中，以下述SQL作为输入案例：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SELECT</span> <span class="type">COUNT</span>(*)</span><br><span class="line"><span class="type">FROM</span> <span class="type">R</span>, <span class="type">S</span></span><br><span class="line"><span class="type">WHERE</span> <span class="type">R</span>.name = <span class="string">"R1"</span></span><br><span class="line">  <span class="type">AND</span> <span class="type">R</span>.sid = <span class="type">S</span>.rid;</span><br></pre></td></tr></table></figure>
<h3 id="QPlan/QMonad__u5C42"><a href="#QPlan/QMonad__u5C42" class="headerlink" title="QPlan/QMonad 层"></a>QPlan/QMonad 层</h3><p>QPlan和QMonad是两个可以相互替换的高层次声明式DSL，它们非常接近SQL的关系代数表示，但是在这个层次，SQL已经可以被翻译为能被Scala理解的语法了。相比起来，QPlan的表示方法更接近关系代数，而QMonad更接近于函数式编程和Collection Programming。</p>
<p>上述SQL在QPlan中的表示是：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">AggOp</span>(</span><br><span class="line">  <span class="type">HashJoinOp</span>(</span><br><span class="line">    <span class="type">SelectOp</span>(<span class="type">R</span>, <span class="string">"name"</span>, <span class="type">EQ</span>, <span class="string">"R1"</span>),</span><br><span class="line">    <span class="type">S</span>, <span class="string">"sid"</span>, <span class="string">"rid"</span></span><br><span class="line">  ),</span><br><span class="line">  <span class="type">COUNT</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>上述 SQL 在 QMonad 上的表示是：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">R</span>.filter(r =&gt; r.name == <span class="string">"R1"</span>)</span><br><span class="line">  .hashJoin(<span class="type">S</span>)(r =&gt; r.sid)(s =&gt; s.sid)</span><br><span class="line">  .count</span><br></pre></td></tr></table></figure>
<p>随后，QPlan/QMonad会被翻译成 <code>ScaLite[Map, List]</code>。值得注意的是，在这一步系统会进行Pipelining的优化。比方说上述QMonad代码中的 filter 和 hashJoin 两个操作，其实可以将 hashJoin 操作的前半部分（为其中一个表构建Hash表）的循环和 filter 当中过滤元素的循环合并起来。因为我们在构建 Hash 表的时候，显然不需要无关的来自 R 表中的记录。下面层次的 DSL 表示已经执行了这一优化。</p>
<h3 id="ScaLite_5BMap_2C_List_5D__u5C42"><a href="#ScaLite_5BMap_2C_List_5D__u5C42" class="headerlink" title="ScaLite[Map, List] 层"></a>ScaLite[Map, List] 层</h3><p>这一层次，DSL可以使用抽象的Map和List数据结构来进行描述，而无需考虑这些Map和List的具体实现。下面是上述QPlan和QMonad翻译成的 ScaLite[Map, List]。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> hm = <span class="keyword">new</span> <span class="type">MultiMap</span>[<span class="type">Int</span>, <span class="type">R</span>]</span><br><span class="line"><span class="keyword">for</span> (r &lt;- <span class="type">R</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (r.name == <span class="string">"R1"</span>) &#123; <span class="comment">// Pipelining</span></span><br><span class="line">    hm.addBinding(r.sid, r)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> (s &lt;- <span class="type">S</span>) &#123;</span><br><span class="line">  hm.get(s.rid) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(rList) =&gt; </span><br><span class="line">      <span class="keyword">for</span> (r &lt;- rList) &#123;</span><br><span class="line">        <span class="keyword">if</span> (r.sid == s.rid) count +=<span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; ()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<p>在这一层次，系统会对 Map 数据结构进行特化，将其翻译成使用List或Array来描述的形式。在这个例子中，根据系统掌握的信息，他有可能把 MultiMap 翻译成 Array[List] 或者直接使用 Array （当 r.sid 是 Unique 主键时）。也就是说，在这一层次会进行数据结构的特化，将 MultiMap 转变成最合适的底层实现。经过这样的操作，所有的 Map 都被底层的 Array 或 List 替代，从而下降到 ScaLite[List]。</p>
<p>值得注意的是，在这一 DSL 层次，所有Map的Key和Value都假定是不可变的。因此在当前层次，可以应用对 FOR 循环的多种优化规则，因为已经插入 Map 的值不可变，程序分析时更容易对循环的Access Pattern进行推断。值得注意的是，第一个循环其实是上层 QMonad DSL 表示中 filter 和 hashJoin 算子 Fusion 之后的实现。本文还提到，在对 Map 类数据结构进行下降的时候，可以在合适的情况下使用 String Dictionary 来加速对字符串相关列的处理。</p>
<h3 id="ScaLite_5BList_5D__u5C42"><a href="#ScaLite_5BList_5D__u5C42" class="headerlink" title="ScaLite[List] 层"></a>ScaLite[List] 层</h3><p>所有的Map数据结构都被特化，用Array等其他底层数据结构取代。在这一层次，我们放松了上一层次对不变性的要求，允许程序修改Array中List的值，这样，上述代码中第一个循环的MultiMap的构建过程，就可以更为具体地以命令式的方式表达出来。下面是DSL下降到这一层次的代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> <span class="type">MR</span>: <span class="type">Array</span>[<span class="type">List</span>[<span class="type">R</span>]] = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">List</span>[<span class="type">R</span>]](<span class="type">R_GROUPS</span>);</span><br><span class="line"><span class="keyword">for</span>(r &lt;- <span class="type">R</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (r.name == <span class="string">"R1"</span>) <span class="type">MR</span>(r.sid) += r <span class="comment">// Materialized here</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> (s &lt;- <span class="type">S</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> rList = <span class="type">MR</span>(s.rid)</span><br><span class="line">  <span class="keyword">for</span> (r &lt;- rList) &#123;</span><br><span class="line">    <span class="keyword">if</span> (r.sid == s.rid) count += <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<p>可以看到，对于 MultiMap 的构建和访问都已经以命令式的形式翻译成对 Array[List] 的操作了。</p>
<p>从这一层次进行下降，系统进行的变换是具像化 List。比方说，根据系统掌握的信息，可以将 List 翻译成 LinkedList 或者Array。在翻译成 LinkedList 的时候，与其使用一个封装类，系统可以将next指针内联到Record之中。也就是生成一个新的结构体，这个结构体除了保存原来数据条目的每个记录之外，还包含一个指向下一条记录的指针。这样就避免了使用封装链表访问数据字段的一次指针跳转。通过对 ScaLite[List] 进行下降，我们就得到了 ScaLite。</p>
<h3 id="ScaLite"><a href="#ScaLite" class="headerlink" title="ScaLite"></a>ScaLite</h3><p>ScaLite 的核心是一个简单类型的 Lambda Calculus，它不支持递归且主要由数据结构的构造和函数的调用构成。这一层次的DSL已经距离纯函数式编程相当远，数据结构的可变性和副作用都被允许。它支持定长数组、变长数组和有序列表等基本数据结构。下面是 ScaLite 的代码</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> <span class="type">MR</span>: <span class="type">Array</span>[<span class="type">R</span>] = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">R</span>](<span class="type">R_GROUPS</span>)</span><br><span class="line"><span class="keyword">for</span> (r &lt;- <span class="type">R</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (r.name == <span class="string">"R1"</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="type">MR</span>(r.sid) == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="type">MR</span>(r.sid) = r</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      r.next = <span class="type">MR</span>(r.sid)</span><br><span class="line">      <span class="type">MR</span>(r.sid) = r</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> (s &lt;- <span class="type">S</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> r = <span class="type">MR</span>(s.rid)</span><br><span class="line">  <span class="keyword">while</span> (r != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (r.sid == s.rid) count += <span class="number">1</span></span><br><span class="line">    r = r.next</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<p>可以看到，在这个层次，连 List 抽象数据结构也不存在了，对数据的访问已经转换为对 next 指针命令式的赋值和读取。在这个层次，系统会进行一个重要的下降转换：数据结构布局的变换和内存控制的变换。也就是说，在从这个层次进行下降的过程中，会加入内存分配和访问相关的代码，并可能根据系统信息将数据结构转换为不同的Layout。常见的Layout有：</p>
<ul>
<li>Boxed layout：指向结构体指针的数组</li>
<li>Row layout：结构体排列在一起形成的数组</li>
<li>Columnar layout：将结构体的每个字段组合在形成多个列式的数组</li>
</ul>
<p>下图展示了不同的数据布局表示：</p>
<p><img src="img/data-layout.png" alt=""></p>
<p>在 ScaLite 下降之后，就形成了 C.Scala。</p>
<h3 id="C-Scala"><a href="#C-Scala" class="headerlink" title="C.Scala"></a>C.Scala</h3><p>这一DSL层次是一个几乎可以逐行翻译成C语言的DSL，它已经包含了所有的内存分配等操作，完全可以直接用于执行了。下面是 C.Scala 的例子：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> <span class="type">MR</span>: <span class="type">Array</span>[<span class="type">Pointer</span>[<span class="type">R</span>]] = malloc[<span class="type">Pointer</span>[<span class="type">R</span>]](<span class="type">R_GROUPS</span>)</span><br><span class="line"><span class="keyword">for</span> (r &lt;- <span class="type">R</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (r -&gt; name == <span class="string">"R1"</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="type">MR</span>(r-&gt;sid) == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="type">MR</span>(r-&gt;sid) = r</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      r-&gt;next = <span class="type">MR</span>(r-&gt;sid)</span><br><span class="line">      <span class="type">MR</span>(r-&gt;sid) = r</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">var</span> count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> (s &lt;- <span class="type">S</span>) &#123;</span><br><span class="line">  <span class="keyword">var</span> r: <span class="type">Pointer</span>[<span class="type">R</span>] = <span class="type">MR</span>(s-&gt;rid)</span><br><span class="line">  <span class="keyword">while</span>(r != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (r-&gt;sid == s.rid) count += <span class="number">1</span></span><br><span class="line">    r = r-&gt; next</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> count</span><br></pre></td></tr></table></figure>
<p>在这一层次之后，DSL会用来生成真的C代码，从而交付给编译器进行编译。在编译的过程当中，C语言常用的编译优化规则自然也可以被应用，从而进一步加快执行。</p>
<p>值得注意的是，在本文系统架构翻译出的可执行代码，和 HyPer 等系统一样使用的是 Push 模型。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文在 LegoBase 的基础上提出了构建查询编译引擎的一些有益思路。通过将PL领域的相关研究和数据库领域的一些发展结合起来，提出了一个用来简化查询编译系统开发、推理和维护的框架。可以说是跨领域学科研究的一个不错的案例。</p>
<p>尽管现阶段常见OLAP系统当中主要的性能瓶颈仍是IO，因此从现实角度来说，In-memory 数据库从这个研究中获益更大。但是随着硬件的不断发展和RDMA系统的逐渐普及，也许在未来类似的查询编译系统将会成为主流。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这篇发表在 SIGMOD 16 的论文来自洛桑联邦理工学院（EFPL），这所学校在计算机领域以Scala编程语言的发源地而闻名于世。不出意外，这篇论文虽然发表于数据处理相关顶会，却弥漫着浓厚的函数式编程和PL的气氛。连系统实现和代码样例都使用 Scala 描述。</p>]]>
    
    </summary>
    
      <category term="functional programming" scheme="https://io-meter.com/tags/functional-programming/"/>
    
      <category term="database" scheme="https://io-meter.com/tags/database/"/>
    
      <category term="compiler" scheme="https://io-meter.com/tags/compiler/"/>
    
      <category term="scala" scheme="https://io-meter.com/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[OLAP 任务的并发执行与调度]]></title>
    <link href="https://io-meter.com/2020/01/04/olap-distributed/"/>
    <id>https://io-meter.com/2020/01/04/olap-distributed/</id>
    <published>2020-01-03T16:23:17.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>OLAP 是大数据分析应用非常重要的组成部分。这篇文章是介绍 OLAP 任务在并发/分布式环境下执行和调度的算法和模型的。我们将从最简单的 Volcano 模型开始讲起，逐步引出分布式环境下执行 OLAP 查询操作的一些挑战和经典的解决方案。</p>
<a id="more"></a>
<p>这些算法和模型将主要在 SQL 和关系模型的语境之内讨论， Spark 和 Flink 这类基于 DAG 的处理系统内也有很多相似的概念，在本文中将不会赘述。</p>
<h2 id="u57FA_u7840_u6A21_u578B"><a href="#u57FA_u7840_u6A21_u578B" class="headerlink" title="基础模型"></a>基础模型</h2><p><strong>Volcano 模型</strong></p>
<p>在《<a href="https://zhuanlan.zhihu.com/p/48735419" target="_blank" rel="noopener">SQL 查询优化原理与 Volcano Optimizer 介绍</a>》中，我们已经对以关系代数为基础的 SQL 查询优化算法进行了介绍，本文的很多内容也将建立在前文内容的基础之上。首先我们来介绍在单线程执行环境下广为人知的经典模型——Volcano 模型。（值得注意的是，这里的 Volcano 模型指的是查询的执行模型，和前文的优化器模型并非同一事物。）</p>
<p>Volcano 模型又叫迭代器模型，其基本思路十分简单：将关系代数当中的每一个算子抽象成一个迭代器。每个迭代器都带有一个 <code>next</code> 方法。每次调用这个方法将会返回这个算子的产生的一行数据（或者说一个 <code>Tuple</code>）。程序通过在 SQL 的计算树的根节点不断地调用 <code>next</code>方法来获得整个查询的全部结果。比如 <code>SELECT col1 FROM table1 WHERE col2 &gt; 0;</code>这条 SQL 就可以被翻译成由三个算子组成的计算树。如下图所示，我们也可以使用伪代码将这三个算子的执行逻辑表示出来。</p>
<p><img src="/img/olap/simple-sql-execution.jpg" alt=""></p>
<p>可以看到，Volcano 模型是十分简单的，而且他对每个算子的接口都进行了一致性的封装。也就是说，从父节点来看，子节点具体是什么类型的算子并不重要，只需要能源源不断地从子节点的算子中 Fetch 到数据行就可以。这样的特性也给优化器从外部调整执行树而不改变计算结果创造了方便。为了方便分析上述计算方案的调用顺序和时间花费，我们将一个 <code>next</code> 函数的调用分为三部分：调用部分（Call）、执行部分（Execution）和返回部分（Return）。下图描绘了之前的计算树的执行过程：</p>
<p><img src="/img/olap/simple-execution-time.jpg" alt=""></p>
<p>如上图所示，绿色方块代表对 <code>next</code> 方法的调用，黄色方块代表对应算子的执行内容，红色方块代表算子的数据返回。可以看到，上述计算树的执行，是通过不断地重复对  \
PROJECT 算子的调用开始的。当 PROJECT 算子被调用后，他紧接着要先调用  \
FILTER 算子的 <code>next</code> 方法，而 FILTER 算子又会进一步调用 SCAN 算子。因此，最先执行计算任务的是 SCAN 算子，在 SCAN 算子返回一行结果之后，FILTER 算子开始进行处理，直到 PROJECT 算子完成他的任务。</p>
<p>以上只是 Volcano 模型完成一行操作所进行的任务，一次查询需要不断地进行上述操作以处理表中的每一行。《<a href="https://15721.courses.cs.cmu.edu/spring2019/papers/15-execution/boncz-cidr2005.pdf" target="_blank" rel="noopener">MonetDB/X100: Hyper-Pipelining Query Execution</a>》当中的分析表明，这些对 <code>next</code> 方法的调用（绿色部分）本身就占用了大量的执行时间，因此一个很容易想到的优化方案就是在调用 <code>next</code> 方法的时候一次处理一批数据。这种优化方案被称为向量化（Vectorization）这种向量化的执行方案不但使得函数调用的成本得以被均摊，也对 CPU 的 Cache 更为友好。向量化还为进一步的优化（如 SIMD 指令执行）提供了有利条件。</p>
<p>上述 SQL 和执行方案只是最简单的一个案例，接下来让我们讨论一个稍微复杂一点的例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> t1.col1, t1.col2, t2.col2</span><br><span class="line"><span class="keyword">FROM</span> t1 <span class="keyword">JOIN</span> t2 <span class="keyword">ON</span> t1.col1 = t2.col1;</span><br></pre></td></tr></table></figure>
<p>在这个例子中，有一个 JOIN 算子，因此在生成的执行方案树当中会有一个分叉。我们假定 <code>t2</code> 表的行数远小于 <code>t1</code> 表，这样一个合理的执行方案可能是先将 t2 表的所有数据读出来构造一个 Hash 表，再将 <code>t1</code> 表当中的每一行读出并通过 Hash 表查询获得结果。此时的 Volcano 模型的执行要更复杂些。JOIN 算子为了向上封装这些细节，需要在内部不断调用 <code>t2</code> 表的 <code>next</code> 方法直到将其内容全部读取出来。因此，对于这样一条 SQL，他的执行树需要表示成下图的样子。</p>
<p><img src="/img/olap/join-sql-execution.jpg" alt=""></p>
<p>如上图所示，我们现将 <code>t2</code> 的内容读入 Hash 表，构建 <code>t2.col1 -&gt; t2.col2</code> 的映射。之后再逐一读入 <code>t1</code> 表的内容，对于 <code>t1</code> 表的每一行，我们使用它的 <code>col1</code> 列在 Hash 表中进行查询，从而得到 JOIN 之后的结果。</p>
<p>对于这样的几个执行方案，他的执行顺序图可以表示成如下情况。可以看到，对 t2 表的扫描完全包含在 JOIN 算子的执行过程当中。</p>
<p><img src="/img/olap/join-execution-time.jpg" alt=""></p>
<p>可以看到，JOIN 算子的执行分为两个部分。第一个部分它会在内部不断调用 <code>t2.next()</code> 函数构建 Hash 表，之后调用 <code>t1</code> 的 SCAN 算子一次以便返回第一行结果。之后对 JOIN 的调用就只会读取 t1 的内容进行并在 Hash 表里探查（Probe）。这一方式实现的 Hash 表是一个带有内部状态的算子，与其他的算子大不相同。而它构建内部 Hash 表的过程可以被认为是一种物化（Materialization）。物化这一概念在之后讨论并发执行的时候也十分重要。</p>
<p><strong>Push 模型（Bottom to Top 模型 ）</strong></p>
<p>除了上述 Volcano/迭代器模型，还有一种反向的调用模型也十分流行，那就是 Push 模型。Push 模型简单来说就是由调度器先分析执行树，然后从树的叶子节点开始执行，在执行之后，有子节点通知父节点执行操作。Push 模型的时间顺序图如下：</p>
<p><img src="/img/olap/push-execution-time.jpg" alt=""></p>
<p>Push 模型的执行看起来更为直观，但是由于控制流是反转的，一般实现起来会比较繁琐。相比起来 Volcano 模型更易于操作，比如在终止查询的时候，Volcano 模型只要停止从根节点继续迭代即可。但是 Push 模型相对单纯的 Volcano 模型也有很多优点：由于子算子产生的结果会直接 Push 给父算子进行操作，Push 模型的 Context switch 相对较少，对 CPU Cache 的友好性也更强。</p>
<p>可以看到，无论是 Volcano 还是 Push 模型，执行查询的步骤都是调度问题。在下文，我们将会先以 Volcano 模型为例子，介绍其并发执行的解决方案。</p>
<h2 id="u5E76_u884C_u6A21_u578B"><a href="#u5E76_u884C_u6A21_u578B" class="headerlink" title="并行模型"></a>并行模型</h2><p>SQL 执行树的并发执行一般有两种类型：<strong>算子内部并行</strong>和<strong>算子间并行</strong>。这两种并发模型往往被组合使用。所谓算子内部并行，是指我们将数据进行分区，因此一个算子可以同时工作在不同的分区上，从而加快查询执行。算子间并行是指不同的算子（尤其是父子算子）同时在不同的 CPU 内核上运行，算子间通过通讯得以传递数据。算子间并行常见于流处理系统。</p>
<p>下图是上述简单 SQL 查询在算子内并行和算子间并行的示意图。</p>
<p><img src="/img/olap/parallel-execution-time.jpg" alt=""></p>
<p>在示意图左边表示的是算子内部并行，这意味着每个算子处理的都是数据的不同分区（Partition），在右边表示的是算子间并行，这意味着每个算子都会处理所有的数据，只是下游的算子无需等待上游的算子结束任务——他可以持续地处理自己已经接收到的数据。</p>
<p>对于算子间并行来说，其执行树和在 Volcano 模型下的实现并没有特别大的区别，只是各个算子在调用 <code>next</code> 方法时可能会被阻塞。在 Push 模型下，它们也可以以类似 Actor Model 那样，为每个算子提供一个信箱或者 Buffer 以储存接收到的数据。</p>
<p>对于算子内部并行来说，如果只是向上述图示的简单查询，每个分片都可以被独立的处理而不同的 CPU 不需要任何数据交换。但是对于我们讨论的第二条带有 JOIN 语句的 SQL，一个算子内部并行的不同部分也需要进行数据交换。也就是说，有时我们可能需要进行 Shuffle 操作。</p>
<p><strong>分布式/并行执行的 Shuffle 操作</strong></p>
<p>在分布式/并行执行环境下需要执行 Shuffle 的原因有很多。其中一种情况是因为性能或者储存能力的原因，我们无法使用一个全局的 Hash 表，而必须使用分布式 Hash 表。分布式 Hash 表在每个 CPU 内核（或计算机节点）上只处理 Hash 表的某一分区。如果在 CPU 的另一个内核（或另一个计算机节点）上有这一个分区的数据，则必须将数据发送到这一分区进行处理，以保证数据的全局一致性。</p>
<p><img src="/img/olap/shuffle.jpg" alt=""></p>
<p>在上文所提到的带有 JOIN 的 SQL 查询中，JOIN 算子恰好需要构建一个 Hash 表。因此它也需要能够 Shuffle 数据。然而，这里就带来一个难点：我们并不想为并行执行的 JOIN 算子编写额外的代码，有没有办法让每个算子都以单线程模式执行，使得 Shuffle 操作对这些算子透明呢？</p>
<p>换句话说，我们仍然只需要以单线程模式实现每个算子（而不需要大幅修改它们），每个算子可以被自然地并发调度起来，不需要管理数据的 Shuffle 。这样执行器的实现就变的简单起来——我们可以基于单线程的算子来实现并行。</p>
<p>Volcano 模型已经提供了这一问题的解决方案：EXCHANGE 算子</p>
<p><strong>EXCHANGE 算子</strong></p>
<p>EXCHANGE 算子是用来为其他算子实现 Shuffle 功能的算子，它相当于将 Shuffle 的功能抽取出来作为一个独立的模块。在进行并行计算时，执行器会在执行方案树的合适位置插入 EXCHANGE 算子，然后将这一执行方案在数据的不同分区当中运行起来，每个分区的执行可以在一个不同的 CPU 内核（或计算节点）上。同一个 EXCHANGE 算子在不同内核（节点）上的实例会相互交换数据，保证上层算子可以透明地通过 <code>next</code> 调用得到正确的分区内的数据。</p>
<p>下图是上述复杂 SQL 在插入 EXCHANGE 算子并进行并行执行后的执行方案示意图。</p>
<p><img src="/img/olap/parallel-join-sql-execution.jpg" alt=""></p>
<p>如图所示，我们在 <code>t2</code> 表的 SCAN 算子上方添加了一个 EXCHANGE 算子。这样，当每个 CPU 上运行的 JOIN 算子从这里执行 <code>next</code> 操作时，只会取到对应分区的数据行。如果 EXCHANGE 算子从下面的 SCAN 算子取到了其他分区的数据行，它会将其发送给对应 CPU 内核（或节点）上的 EXCHANGE 算子实例。因此，所有的其他算子都不需要对数据的分布和 Shuffle 操作有任何了解。</p>
<p>值得注意的是，我们在这里只为 <code>t2</code> 表添加了 EXCHANGE 算子而不是给所有算子都添加了 EXCHANGE，这是因为，我们可以使用 <code>t1</code> 表原本的分区来决定 JOIN 算子中构建的 Hash 表的分区，因此在对 <code>t1</code> 表进行 Probe 的时候，是不需要通过 EXCHANGE 算子来交换数据的。这一优化可以直接通过静态分析而实现。</p>
<p><strong>Pipeline（处理管线）</strong></p>
<p>前文提到 Push 模型的 Context Switch 较少，在 Volcano 模型下，当一连串算子互相之间都不需要交换数据，我们可以使用数据管线技术来实现相似的目的。数据管线技术将一连串算子使用Operator Fusion 技术合并成一个算子那样进行调用，比如说，对于前文简单 SQL 的伪代码，使用处理管线合并之后的执行代码将会更加简洁。Pipeline 也常常配合代码编译技术使用，以极大地加速查询的执行。</p>
<p><img src="/img/olap/pipeline-execution.jpg" alt=""></p>
<p>值得注意的是，对于我们的第二个 SQL 查询，虽然有 EXCHANGE 算子在其中，导致右边的 <code>t2</code> 表的 SCAN 算子无法管线化，但是左边 <code>t1</code> 表、JOIN 和 PROJECT 三个算子是可以组成一个 Pipeline 的。</p>
<p><img src="/img/olap/pipeline-join-sql-execution.jpg" alt=""></p>
<p><strong>并行执行面临的挑战</strong></p>
<p>前文提到了对 SQL 执行方案提到了对数据进行分割的两种方法：对 SCAN 输入的数据进行分区和在处理时对数据进行分段（向量化执行）。我们可以认为这两种分割方法前者是横向（Horizontal）切分，后者是纵向（Vertical）切分。如下图所示：</p>
<p><img src="/img/olap/horizontal-vertical-partition.jpg" alt=""></p>
<p>在启用数据分区来实现并行处理后，我们的分布式/并行任务执行就会面临如下的一些挑战：</p>
<ul>
<li><strong>数据倾斜</strong>：数据倾斜常见的情况有两种：1）对输入的数据进行分区时，不同分区数据量区别很大；2）经过一些计算（如 FILTER 操作）之后不同分区保留下来的数据量区别很大。由于并行处理任务结束的时间取决于最慢的任务，因此数据倾斜对执行性能的影响很大。一般来说，第一种数据倾斜的情况较为容易处理，我们可以通过再平衡和换用更好的分区方法来解决。第二种数据倾斜就比较难预测和处理了。</li>
<li><strong>处理速度倾斜</strong>：除了数据倾斜之外，还有一种非常影响性能的倾斜是处理速度倾斜。这种倾斜是指不同的处理器内核（或节点）处理同样数据量所花费的时间不同。它常常出现在某些处理器内核（或节点）因环境干扰、任务调度、阻塞、错误和失败等原因减慢甚至中止响应的情况下。处理速度倾斜受环境因素影响大，很难发现和优化。</li>
<li><strong>Data Locality</strong>：当一个算子完成它所进行的计算并将结果传递给下一个算子时，我们往往希望下一个算子被调度在同一个 CPU 内核（或节点）上。这是因为内核间的内存交换或节点间的网络传输是一个非常耗时的操作。有时我们必须在 Data Locality 和数据/处理速度倾斜之间进行取舍，这对调度算法的设计带来了严峻的挑战。</li>
</ul>
<p>为了解决上述三个难点并在调度算法设计时对其进行取舍，学术界和工业界做出了不懈的努力并产生了很多好的论文和实践。接下来我们将会看到一些经典的方案和最新的优化方向。</p>
<h2 id="u7ECF_u5178_u6A21_u578B"><a href="#u7ECF_u5178_u6A21_u578B" class="headerlink" title="经典模型"></a>经典模型</h2><p><strong>NUMA 架构</strong></p>
<p>在介绍解决 OLAP 并行执行的经典模型之前，我们先介绍对我们所面临问题的一个抽象建模 NUMA。NUMA 是 Non-Uniform Memory Access 的缩写。它指的是在较新生产的多核 CPU 中，不同 CPU 内核访问不同内存位置的速度不同的现象。</p>
<p>为什么会有这种现象呢？在过去，CPU 只有一个内存总线，所有的 CPU 内核访问内存时，都通过这个总线进行，因此每个 CPU 访问内存位置的速度都是相同的。这种访问模式被称为 UMA （Uniform Memory Access）。但是使用一个总线阻止了 CPU 对内存的并发访问，为了增加内存访问性能，新的 CPU 开始加入多个可以同时独立访问不同内存条的 Socket，并将相邻的 CPU 内核连接在这些 Socket 上。也就是说，一块 CPU 上的内核被组织成不同的分区，每个分区有一个 Socket 可以直接访问一块内存条，为了能在这些 CPU 分区之间共享内存，它们之间也建立了内存访问通路。下图左边部分表示了这种架构。</p>
<p><img src="/img/olap/numa.jpg" alt=""></p>
<p>显然，一个 CPU 内核如果要访问另一个 CPU 管理的内存，就需要通过它们之间的联络通路进行一次跳跃，这种跳跃本身将会花费一定的时间。在现代操作系统（如 Linux 等）中，进行内存分配和进程调度时已经考虑了这种情况，因此会按照一定的算法对任务和数据进行分配。然而，由于操作系统无法具体确知进程的具体逻辑，这种算法对于数据库和 OLAP 应用往往并不理想。因此很多数据库自己实现了相关调度功能。</p>
<p>在上图的右侧是一个基于网络的处理集群的示意图，我们可以看到，通过网络执行任务的集群和带有 NUMA 属性的 CPU 有相似之处，如果在一个节点当中执行计算得到的计算结果需要被其他节点访问，也需要在节点之间进行一次传输操作。而每个节点自身也拥有一个类似内存的储存空间（硬盘）。这两种架构虽然有不同的规模，其结构却是雷同的。因此很多时候我们也可以把应用于 NUMA CPU 的并行调度算法应用于分布式系统当中。</p>
<p><strong>Morsel-Driven Parallelism</strong></p>
<p>接下来我们来介绍在 NUMA-aware 查询执行方面非常经典的论文《<a href="https://15721.courses.cs.cmu.edu/spring2019/papers/14-scheduling/p743-leis.pdf" target="_blank" rel="noopener">Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age</a>》提出的模型。这一篇论文以 HyPer 系统为基础，主要有以下几个特点：</p>
<ul>
<li>使用 Pipeline 技术组合算子</li>
<li>使用自底向上的 Push 模型调度任务。当一个任务执行结束时，它会通知调度器将后序任务假如到任务队列中</li>
<li>既使用水平数据分区，也使用垂直数据分区，每个数据块的单位被称为 Morsel。一个Morsel 大约包含10000行数据。查询任务的执行单位是处理一个 Morsel</li>
<li>NUMA-aware，为了实现 Data Locality，一个内核上执行的任务，由于其产出结果都储存在当前内核的 Cache 或 Memory 里，因此会优先将这个任务产生的后序任务调度在同一个内核上。这样就避免了在内核间进行数据通信的开销。</li>
<li>使用 Work-stealing 实现弹性伸缩和任务负载均衡，以缓解数据倾斜和处理速度倾斜带来的性能瓶颈。也就是说，当一个内核空闲时，它有能力从其他内核“偷取”一个任务来执行，这虽然有时会增加一个数据传输的开销，但是却缓解了忙碌内核上任务的堆积，总体来说将会加快任务的执行。</li>
<li>使用 Delay Scheduling 防止过于频繁的 Work stealing。在内核空闲并可以偷取任务时，调度器并非立即满足空闲内核的要求，而是让它稍稍等待一段时间。在这段时间里，也许忙碌内核就可以完成自己的任务，而跨内核调度任务就可以被避免。令人惊讶的是，这种简单的处理方式在实际应用中效果非常好。</li>
</ul>
<p>在这一模型中，Pipeline 执行、以 Morsel 为单位进行数据切分和放置以及 Push 模型的任务调度前文都有涉及，也不难理解。在此特别介绍一下这一模型使用的 NUMA-aware、Work-stealing 和  Delay Scheduling 算法。</p>
<p>在上述论文中，NUMA-aware/Data Locality 的实现是基于一个全局的任务队列。这一任务队列使用<a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" target="_blank" rel="noopener">无锁数据结构</a>实现，因此可以被各个内核上的不同线程高效地访问和修改。每个被添加的到队列中的任务与各个内核之间有不同的亲近（Affinity）值。一个任务如果在某一个内核上执行，那么他产生的后序任务和这个内核就都具有较高的亲近值，因此当此内核空闲时，新的任务就非常可能会被调度到它上。这样就实现了对 Data Locality 的满足。</p>
<p>进一步，由于可能出现数据倾斜和处理速度倾斜，严格静态的满足 Data Locality 的要求可能不是最佳的解决方案。因此论文提出了使用 Work-stealing 技术进行负载均衡的方法。</p>
<p>熟悉 Java 并发编程的朋友可能对 <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html#newWorkStealingPool--" target="_blank" rel="noopener">WorkStealingPool</a> 很熟悉，在这种 Executor 当中，空闲的 Thread 可以从其他 Thread “偷窃”一个任务来执行，这样各个线程的负载就会越来越均衡。在 HyPer 中，这是通过空闲内核上的线程从全局队列当中偷取与其他内核亲近值较高的任务来实现的。</p>
<p>为了防止偷取过于频繁得发生，HyPer 还引入了 Delay Schedule 的概念，也就是稍稍等待任务原本应该执行的内核一小会，期待原内核上的任务在这段时间内就可以完成，从而避免偷窃任务带来的数据传输开销。这一方法并非由 HyPer 首创，实际上，早在 2010 年由 Spark 主要作者 Matei 发表的《<a href="http://elmeleegy.com/khaled/papers/delay_scheduling.pdf" target="_blank" rel="noopener">Delay Scheduling: A Simple Technique for Achieving Locality and Fairness in Cluster Scheduling</a>》就介绍了这种方法。它不光应用于 NUMA-aware 的数据库系统中，还广泛应用于各种大数据处理系统和任务调度系统（如 Hadoop、YARN  等）。HyPer 的任务调度策略可以由下图表示。</p>
<p><img src="/img/olap/hyper-numa.jpg" alt=""></p>
<p>除了上述特性以外，HyPer 还会在每个内核调度两个线程，以便最好地利用每个内核的 CPU 时间，填充其中一个线程出现 IO 产生的空隙。</p>
<p>除了 HyPer 所实现的 NUMA-aware 模型，SAP HANA 系统也实现了类似的 Morsel-Driven 系统。不同的是，HANA 不是使用所有线程共享的全局队列，而是为每个线程配置本地的任务队列。而任务的再平衡也是通过一个独立运行的 Watch Dog 线程完成的。在这一模型中，Watch Dog 线程可以实现非常丰富的功能，灵活地监控和调配资源。但是任务再平衡的逻辑就比较复杂，没有 Work-stealing 这么简单直观了。</p>
<p>为了防止某些不适合被放到其他内核的任务被调度走 ，HANA 会为每个线程配置 Hard Queue 和 Soft Queue 两个队列。其中，Soft Queue 里的任务可以被 Watch Dog 线程重新配置到其他内核。</p>
<p><img src="/img/olap/hana-numa.jpg" alt=""></p>
<p><strong>分布式和本地并行混合方案</strong></p>
<p>在 2015 年的 VLDB 论文《<a href="https://www.vldb.org/pvldb/vol9/p228-roediger.pdf" target="_blank" rel="noopener">High-Speed Query Processing over High-Speed Networks</a>》里介绍了 HyPer 系统在高速网络尤其是 RDMA 系统上实现的进一步优化。在本文中，我们略去其中有关高速网络应用的部分，仅关注其中有关分布式和本地并行混合模型的优化方案。</p>
<p>所谓分布式与本地并行的混合方案，指的是在分布式系统中，每个节点又都是具备多核计算能力的服务器。因此，从微观来说，每个节点本身是一个 NUMA 系统，从宏观来说，这些节点组成的集群也是一个 NUMA 系统。</p>
<p><img src="/img/olap/hybrid-numa.jpg" alt=""></p>
<p>这篇文章提出的第一个优化是，对于某些 EXCHANGE 算子，如果我们知道它下面的输出结果集比较小，我们可以不通过 Shuffle 的方式而是通过 Broadcast 的方式来将其传递到各个节点。这也是执行 OLAP 计算的一种常见优化。比方说，在上述 t1 JOIN t2 的 SQL 查询中，如果 t2 的数据量很小，那么将其全部物化并直接构建出一个 Hash 表，并传播给各个节点是一个不错的选择，这是因为大部分聚合操作在本地就完成了，避免了多次数据的交换。</p>
<p>这篇论文提出的另一个相关的技术也很简单。在传统的模型下，假如我们有 $M$ 台机器，每台机器运行 $N$ 个查询进程，每个进程里有一个 EXCHANGE 算子。那么这些 EXCHANGE 算子之间就有 $(M\times N)\cdot (M\times N - 1)$ 条相互交流的链路。也就是说所有这些 EXCHANGE 算子都可能会相互交换信息，这将产生巨大的连接数。如果这些链路同时发送数据包，很有可能产生数据涌塞。因此，此论文提议在每台机器上启动一个 Multiplexer 专门用来管理数据请求。也就是说，同一个节点上的 EXCHANGE 实例会先将数据发送到 Multiplexer，而本机内的数据 EXCHANGE 直接通过 Multiplexer 处理而无需使用网络栈。对于外部的数据请求，Multiplexer 将会进行缓冲 和批量传送。因此链路数减少到 $M\times (M - 1)$ ，获得了一个量级上的减少。</p>
<p><strong>动态调整数据放置和执行计划</strong></p>
<p>前面提到，SAP HANA 的 NUMA-aware 模型使用了 Watch Dog 线程。这一实现增加了调度的灵活性，Watch Dog 线程也可以掌握到很多系统的信息并根据这些信息动态调整数据放置和资源调度。2019 VLDB 的论文《<a href="https://pdfs.semanticscholar.org/ab35/4a7c41e4a7a6bd65c07adb21683a01f9c9ee.pdf" target="_blank" rel="noopener">Adaptive NUMA-aware data placement and task scheduling for analytical workloads in main-memory column-stores</a>》就是基于这一优势所做出的改进。论文中提出了算法以很低的资源消耗获得较为准确的内存和 CPU 使用估量，并根据这个估量和对查询当中数据放置（数据分区）的了解来实现较为复杂和精准的调度。</p>
<p>这篇论文的一个很重要的贡献就是发现 Memory 密集的操作（如 SCAN 操作）不适合被 Steal 到其他内核运行。论文中提出的算法可以智能地发现这些 Memory 密集的操作，从而逐步将其锁定 在最合适的内核上，以便进一步压榨 NUMA 系统中的计算资源。</p>
<p>动态调整数据放置和执行计划可以说是数据库系统调度的最前沿研究和发展了。其难度和复杂度都相当高。在本文中只能对其小部分思想进行简介，有兴趣的朋友可以阅读原论文以获得更准确的信息。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文以 SQL 查询为基础，在关系模型的执行方案下讨论了分布式/并行 OLAP 任务执行的基本模型和经典方案，并且涵盖了一些最新研究（如动态调整技术）的介绍。我们可以看到，对于并行 执行来说，数据的横向和纵向分割都是必不可少的。对数据进行横向分区使得我们可以在不同的分区上并行执行任务，将数据在纵向上切分，可以减少方法调用次数、减少 Context Switch 以及为弹性扩展和解决数据倾斜问题提供可能。</p>
<p>EXCHANGE 算子是在 Volcano 模型下实现数据交换（Shuffle）的重要解决方案，它使得其他算子完全可以以单线程模式运行，并将数据交换变为一个透明的操作。EXCHANGE 算子的引入使得传统关系模型的执行方案可以被优雅地转换为并行执行方案。</p>
<p>NUMA 模型是分布式/并行执行 OLAP 查询的一个基础抽象，它既可以应用于单机多核环境，也可以应用于多机集群环境。我们介绍了两种 NUMA-aware 的经典模型，它们一般使用 Work-stealing/relocation 方法来处理数据失衡和处理速度失衡，同时使用 Delay Scheduling 来防止过于频繁的任务偷窃或交换。</p>
<p>最后我们提到了一些比较新和复杂的实现，如动态调整数据放置和执行计划等。这些崭新的研究可以进一步压榨计算资源，获得更高的执行性能。</p>
<p>在本文中，没有详细介绍一种很简单的优化方式，那就是<strong>慢任务异地重试机制</strong>。有时因为节点失败或者网络阻塞等原因，一个查询的分布式任务中会有一小部分执行非常慢，而整体的查询速度则受限于这些查询。这类任务被称为尾部（Tail）任务。分布式系统业界的知名大佬 Jeff Dean 在其《<a href="https://cseweb.ucsd.edu/~gmporter/classes/fa17/cse124/post/schedule/p74-dean.pdf" target="_blank" rel="noopener">The tail at scale</a>》一文中详细介绍了这种情况和解决方案。</p>
<p>从上述 Work-stealing、Delay Scheduling 和慢任务异地重试可以看出，很多分布式系统当中的棘手问题都可以使用十分简单的解决办法获得不错的效果。让人不禁感慨系统设计有时真是大道至简。</p>
<!-- Docs to Markdown version 1.0β17 -->
]]></content>
    <summary type="html">
    <![CDATA[<p>OLAP 是大数据分析应用非常重要的组成部分。这篇文章是介绍 OLAP 任务在并发/分布式环境下执行和调度的算法和模型的。我们将从最简单的 Volcano 模型开始讲起，逐步引出分布式环境下执行 OLAP 查询操作的一些挑战和经典的解决方案。</p>]]>
    
    </summary>
    
      <category term="olap" scheme="https://io-meter.com/tags/olap/"/>
    
      <category term="schedule" scheme="https://io-meter.com/tags/schedule/"/>
    
      <category term="sql" scheme="https://io-meter.com/tags/sql/"/>
    
      <category term="distributed system" scheme="https://io-meter.com/tags/distributed-system/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Stream SQL 的执行原理与 Flink 的实现]]></title>
    <link href="https://io-meter.com/2019/03/16/streaming-incremental-sql-execution/"/>
    <id>https://io-meter.com/2019/03/16/streaming-incremental-sql-execution/</id>
    <published>2019-03-16T11:45:31.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>在数据仓库应用中，执行 ETL 过程是一种常见的需求。我们希望通过 ETL 过程预处理我们的原始数据，
从而达到抽取有用信息和将数据转换为适合进一步查询的格式等目的。MapReduce 和 Spark
等批数据处理系统已经很好地解决了在高延迟的场景下的需求，目前低延迟的流式处理和增量计算是主要的发展方向。
本文将结合 Apache Flink 系统讨论相关技术课题。</p>
<a id="more"></a>
<p>伴随着流处理系统的发展，SQL 特别是 Stream SQL 系统也渐渐流行起来。这可能得益于 SQL
是一门已经被学界和工业界充分研究过的查询语言。 尽管 SQL 可以认为是图灵完备的，但其相较于更加通用的一些计算模型，
其表现力和应用范围是受限的。在这篇文章中将讨论一下 Stream SQL 实现原理、应用场景和能力范围。</p>
<p>一般来讲，现实应用中各个计算模型能力范围可以表示成如下图所示。</p>
<p><img src="/img/streaming-sql/computing-models.jpg" alt="Computing Models"></p>
<p>尽管已经知道这件事情，我们仍然对如下一些问题感兴趣：</p>
<ol>
<li>SQL 和 Stream SQL 的能力的边界在哪里？给定任意一个 SQL 查询，我们是否可以判断其能否使用 Stream SQL 执行？</li>
<li>如果一条 SQL 可以使用流式处理来执行，具体要如何实现？我们格外感兴趣的是 Group By 和 Join 操作的实现。</li>
<li>在了解过 Stream SQL 的基本原理之后，我们进一步感兴趣的问题是现存的系统(特别是 Flink)的相关实现细节。</li>
</ol>
<p>接下来的文章我们就来讨论这些问题。在<a href="#u589E_u91CF_SQL__u67E5_u8BE2_u7B97_u6CD5">增量 SQL 查询算法</a>这一章首先来介绍诸如 Flink 这类系统所采用的实现 Stream SQL 查询的理论，
在<a href="#u6D41_u5F0F_u5904_u7406_u4E0E_u65F6_u95F4_u64CD_u4F5C">流式处理与时间控制</a>这一章，我们将讨论 Stream 处理系统的一些基本的概念和如何操作时间。最后，
我们将会讨论 <a href="#Apache_Flink_uFF1A_u80FD_u529B_u4E0E_u5C40_u9650">Apache Flink 的能力与局限</a>，致力于对 Flink 执行相关任务方法的进行一个简单刻画。特别地，我们会花费一些篇幅在 Flink
内部状态的管理。</p>
<h2 id="u589E_u91CF_SQL__u67E5_u8BE2_u7B97_u6CD5"><a href="#u589E_u91CF_SQL__u67E5_u8BE2_u7B97_u6CD5" class="headerlink" title="增量 SQL 查询算法"></a>增量 SQL 查询算法</h2><p>一般来讲，给定一条 SQL 如果其源数据表中有一些数据发生了改变，我们需要重新全量执行这条 SQL 才能得到更新过的结果。
增量 SQL 查询则意味着我们可以只依赖源数据的改变量，局部地执行查询并更新原来的结果。使用增量模型，
我们往往可以得到更快的执行方案。很显然，Stream SQL 执行就是增量 SQL 查询：新到达的数据就是在一张“源数据表”
当中新加入的数据项。</p>
<p>为了介绍增量 SQL 查询算法，首先来看一些术语的解释：</p>
<ol>
<li><strong>视图(View)</strong>：是在关系型数据库当中被保存的一个查询</li>
<li><strong>物化视图(Materialized View)</strong>：是将一个视图的内容“物化/预计算保存”下来的结果</li>
<li><strong>表(Table)</strong>：是一类可以支持扫描(Scan)或查询(Query)的数据源</li>
<li><strong>索引(Index)</strong>：是附加于表或者视图上用于加快查询的数据结构</li>
</ol>
<p>请注意，在本文的讨论当中，索引指代的是一类需要引用原始数据的数据结构，也就是说索引只包含了原始数据当中的一部分信息。
包含原数据的全部信息并且可以无损翻译回去的可以认为是物化视图。另外，物化视图显然也是一种表：他支持扫描和查询操作。</p>
<p>容易得到，增量 SQL 查询的问题就是物化视图内容维护的问题。我们显然希望增量地维护物化视图的内容，
而不是每当源数据表改变就全量刷新。</p>
<p>物化视图的概念最早由 Oracle 和 SQL Server 等商业数据库作为索引的一种补充而引入。
学术界和工业界至今已经积累了很多相关研究，从而形成了一整套方法论。
很多现代的流式处理系统也采用了这些方案：Stream SQL 是物化视图维护问题的一个子问题。</p>
<p>为了阐释为什么物化视图是一种有效地加速查询的功能，我们先来花一些时间在 SQL 查询的优化与执行规划问题上。</p>
<h3 id="SQL__u4F18_u5316_u4E0E_u6267_u884C_u89C4_u5212"><a href="#SQL__u4F18_u5316_u4E0E_u6267_u884C_u89C4_u5212" class="headerlink" title="SQL 优化与执行规划"></a>SQL 优化与执行规划</h3><p>在 <a href="/2018/11/01/sql-query-optimization-volcano/">SQL 查询优化原理与 Volcano Optimizer 介绍</a>
一文中，我们已经对相关算法进行了详细介绍。简单重复一下的话，作为一种声明式的查询语言，我们可以将 SQL
转化成一种叫关系代数(Relation Algebra)的抽象表示来进行计算。这样的一种抽象表示被称为 SQL 执行的逻辑计划(Logical Plan)。
逻辑计划一般由一棵算子(Operator)组成的的树表示，这棵树表示了算子之间的依赖关系和执行顺序。特别地，
我们还可以为这课树表示的方案及其每棵子树进行执行花费的估算。下图展示的就是一条 SQL 的执行方案。</p>
<p><img src="/img/streaming-sql/relation-algebra.jpg" alt="Relation Algebra"></p>
<p>上图左边是逻辑计划，右侧是对计划成本的估算，其中展示的算子有 Join、Project 和 Filter 等。这里 Project
表示的是对上游输入的每个元素进行变换处理(如选取列、对每行进行数值变换等)的算子。利用右侧成本估算进行 SQL 
查询优化的优化器被称为基于成本(Cost-based)的优化器。在实现上，
每个抽象算子可以结合子树传入的成本和自己的内部实现向上返回一个对自己成本的估算。也就是说成本估算是递归执行的。</p>
<p>比较先进的优化器大多基于成本估算，其基本原理是反复应用查询变换的规则将原查询修改为语义相同等另一方案，
在这一过程中不断估算成本并最终选取成本最低的方案。关于高效实现这一思路的 Volcano/Cascades 算法，
前面提到的文章已经进行了充分介绍，这里不再赘述。</p>
<p>在本文的语境当中，值得关注的是这种优化器提供的两种特别的可能性：</p>
<ol>
<li>将逻辑计划转换为物理计划的能力</li>
<li>将整棵子树转换为单个算子节点返回预计算结果的能力</li>
</ol>
<p>所谓的<strong>物理计划</strong>，指的是方案中每个算子都包含了执行这个方案所需要的信息的方案。在有的实现中，
物理计划当中的算子可以直接被调用执行。将计划划分为逻辑计划和物理计划的意义在于，
我们可以为语义相同的算子提供不同的物理实现。比方说如下图所示，针对 Join 节点我们有两种不同的实现方法：
使用哈希表的 Hash Join 和使用排序方法的 Sort Join。这两种实现方法有不同的适用场景，
比方说，Hash Join 一般性能较好，但是适用的数据规模有限，而使用外部排序的方法
Sort Join 一般可以支持非常大的数据范围。在现代数据库的优化器当中，这两种物理算子的选取是依据方案的成本估计来选取的。</p>
<p><img src="/img/streaming-sql/logical-to-physical.jpg" alt="Choosing Physical Plan"></p>
<p>可以看到，在上述方案选取当中，尽管 Hash Join 本身可以以更高的性能执行，然而 Sort Join 可以具备返回有序结果的特性。
因此，在规划时更上层的算子可以利用这一特性，反而可以得到更优的成本估算，因此包含 Sort Join 算子的方案会最后胜出。
在这里，逻辑计划到物理计划的转变同样也是通过规则来实现的，我们可以看到在这一模型中，
查询优化和物理计划的生成被统一成一个过程，不得不说是十分精巧的设计。</p>
<p>使用预计算结果代换整棵子树更容易理解：获得子树计算结果最快的方式就是直接从预计算结果当中读取。
这恰恰就是使用物化视图的思路所在：将所有的物化视图注册在优化器当中，
优化器就有可能自动发现一个方案可以利用这些预计算结果。</p>
<p><img src="/img/streaming-sql/materialized-view.jpg" alt="Materialized View"></p>
<h3 id="u7269_u5316_u89C6_u56FE_u589E_u91CF_u7EF4_u62A4_u7684_u7B80_u5355_u7B97_u6CD5"><a href="#u7269_u5316_u89C6_u56FE_u589E_u91CF_u7EF4_u62A4_u7684_u7B80_u5355_u7B97_u6CD5" class="headerlink" title="物化视图增量维护的简单算法"></a>物化视图增量维护的简单算法</h3><p>如上文所述，物化视图就是对一条 SQL 查询的缓存。由于 SQL 是一门封闭的查询语言，它具有以下两条特点：</p>
<ol>
<li>如果一颗树是 SQL 的代数表示，那这棵树的所有子树也是某条 SQL 查询的代数表示</li>
<li>将一颗表示 SQL 的树表示插入到另一颗树中作为子树，得到的树仍然是 SQL 的代数表示</li>
</ol>
<p>因此，如果我们使用子查询或者视图进行查询，我们就可以将子查询和视图的代数表示直接插入到父查询之中，
作为一个整体优化和计算。这一过程称为子查询/视图展开。反过来，视图/物化视图也就可以完全由 SQL 查询来定义。
特别地，我们可以把视图/物化视图直接作为一个表来看待，在思考问题的时候不去考虑他的内部结构，
这样就比较容易进行讨论。</p>
<p>因此，对物化视图进行增量维护的最简单算法就是从根算子开始，将其左右两颗子树作为整体看作“似表(Table-Like)”。
显然，这些似表都支持扫描和查询功能。与一般的 SQL 查询不同，在增量 SQL 查询中，当一个表的内容改变，
我们希望这些表将内容的修改表示成包含增加的行和减少的行的增量表(Delta Table)的形式。
这些增量表将会被送入上层算子进行处理。</p>
<p>当上层算子接收到增量表了之后，他可以通过三种数据来源来判断要如何增量地执行这一查询，
并进一步将生成的增量表向上发送。这三种数据来源是：</p>
<ol>
<li>这一算子自己维护的内部状态</li>
<li>某一子节点向上发送的增量表</li>
<li>把子树当成表并发送请求查询其内容</li>
</ol>
<p>下图展示了这一框架：</p>
<p><img src="/img/streaming-sql/incremental-operator.jpg" alt="Incremental Operating"></p>
<p>在最上层的根节点完成这样的计算后所得的增量表，就可以应用在物化视图原先保存的结果上，从而得到新的结果。
而如果我们能为每一个算子，如 Project、Filter 和 Join 都设计这样的执行方案(实现对应的物理算子)
是不是我们就可以为任意的 SQL 实现增量查询了呢？答案是肯定的: 对于任何标准 SQL 里的算子，
我们总可以将其转换成上述产生增量表的形式。也就是说我们有 $\alpha(T + \Delta T) = \alpha(T) + Q(T, \Delta T)$。
这里 $\alpha$ 代表一个算子，$T$ 是基表，$\Delta T$ 是增量表，$Q$ 是一个以 $T$ 和 $\Delta T$ 为参数的查询。
显然 $Q(T,\Delta T)$ 即我们所需输出增量表。</p>
<p>尽管上述增量维护的简单算法(或称为代数算法)提供了一条实现通用增量执行的道路，
仍有一些问题值得讨论:</p>
<ol>
<li>时间成本：执行增量刷新操作的时间花费</li>
<li>空间花费：为了支持增量刷新，算子内部需要保存的状态大小</li>
<li>刷新时机：激发刷新操作的正确时机是什么？</li>
</ol>
<p>问题3的答案很简单，通过时算子缓冲一些修改批量执行或者添加其他的控制策略，可以有效的提高执行效率，节约资源。
本文不对这一问题进一步展开，而将主要关注时间和空间花费两方面。</p>
<h3 id="u67E5_u8BE2_u653E_u5927_u95EE_u9898_u53CA_u5176_u89E3_u51B3_u601D_u8DEF"><a href="#u67E5_u8BE2_u653E_u5927_u95EE_u9898_u53CA_u5176_u89E3_u51B3_u601D_u8DEF" class="headerlink" title="查询放大问题及其解决思路"></a>查询放大问题及其解决思路</h3><p>上文提到，增量查询的简单算法(代数算法)有时需要通过查询上游表来获得必要的数据，从而生成输出给下游的增量表。
一个问题就是增量表的计算公式 $Q(T, \Delta T)$ 的执行效率。遗憾的是，在前述算法当中的一些相当简单的算子(如 Project)等，
这一公式的执行效率都不高，有的甚至隐含着需要全表刷新。下面是一些例子:</p>
<ol>
<li>Project 查询放大问题：考虑简单查询<code>SELECT MAX(a, 42) FROM example</code>。当下游给定了一个删除某以<code>a = 100</code> 的行，
这时因为在物化视图当中，每一个因 <code>MAX</code> 函数执行而产生的数值 42 都是相同的，但 Project 算子又必须保留元素的排序，
从而出现了不知道删除哪条记录的情况，因此必须全量查询原表并重新刷新视图</li>
<li>聚合计算查询放大问题：考虑查询<code>SELECT count(distinct a) FROM example</code> 由于表中 a 元素可能会有重复，
在没有其他附加信息的情况下，每次增量查询执行只能重新扫描全表。这种情况在执行 <code>SELECT a, count(distinct b) FROM example</code>
的时候也会出现，根据 (a, b) 数据的分布，相关聚合算子 AGG 可能需要进行规模不等的扫描。</li>
<li>TopK (Sort Limit) 查询放大问题，设想查询<code>SELECT a FROM example ORDER BY a LIMIT 10</code>。很显然，
虽然输出的视图里只包含10条元素，然而为了处理某一增量表，相关查询不得不重新扫描全表来选取最小的十个数字.</li>
<li>Theta Join 问题。对于比较自由的 Join 条件，如查询 <code>SELECT T1.a, T2.a FROM T1 JOIN T2 ON T1.a * T2.a &lt; 100</code>
尽管最终符合条件的元素数量并不多，但仍然可能需要对两个表进行大量查询</li>
</ol>
<p>然而，解决查询放大问题并没有一定之规。现有的方法主要是针对各种特定情况进行优化。几种可能的思路：</p>
<ol>
<li>确保处理过程当中的行唯一性。也就是说首先为每一行指定一个唯一的 ID，保证这些 ID 在整个计算过程中不断地在算子之间传递。
有些操作如 Group By 等需要根据条件修改这些 ID。保证这些 ID 被增量表中的每一行携带。
这样就容易获知应该修改目标视图当中的哪些行。然而对于比较自由的 Join 算子，可能无法为下游行生成合理的 ID，
这也是有些系统只支持 EquiJoin(带有相等条件的 Join)的原因。</li>
<li>使得算子保存额外的内部状态，将 $Q(T, \Delta T)$ 变换为 $Q’(T, \Delta T, S)$ 这里 $S$ 是算子的内部状态。
这样得到的函数 $Q’$ 就可以支持更加快速的查询并使得扫描的范围更小。额外的内部状态可能包括对子树内容的物化(缓存)本身，
也可以有根据查询条件或 Join 条件生成的索引等。实现这种思路没有一劳永逸的方法，
大多需要根据<a href="#SQL__u4F18_u5316_u4E0E_u6267_u884C_u89C4_u5212">SQL 优化与执行规划</a>
这一章介绍的优化模型进行统筹考虑和方案选择。也就是说提供多种物理计划算子以待选择</li>
<li>使用近似计算。对于某些聚合查询，如<code>COUNT(DISTINCT value))</code>和 TopK 等，可以使用 HyperLogLog 等算法进行近似计算，
并将结果保存在内部状态中。这样查询虽然输出了近似结果，但是在时间和空间上都获得了优化</li>
<li>限制或扩充语义。一方面可以对 SQL 在某些方面的能力进行限制，从而防止全量查询的发生。
另一方面可以增强 SQL 的建模能力，加入诸如 Window 之类的概念，使得用户可以更好地描述自己的需求，
并将相关查询的扫描范围限制在一定的规模。这种方式往往常用于 Stream SQL，在之后会进一步介绍相关内容</li>
</ol>
<p>在上述各种方案都无法有效解决问题的时候，一种方法就是完全退化为全量刷新。
这是因为某些场景下增量查询的执行可能比全量刷新具有更高的成本，这时根据 SQL 的成本估算选择全量刷新执行是更明智的。</p>
<h3 id="u4FEE_u6539_u653E_u5927_u95EE_u9898_u53CA_u5176_u89E3_u51B3_u601D_u8DEF"><a href="#u4FEE_u6539_u653E_u5927_u95EE_u9898_u53CA_u5176_u89E3_u51B3_u601D_u8DEF" class="headerlink" title="修改放大问题及其解决思路"></a>修改放大问题及其解决思路</h3><p>实现 SQL 增量执行最棘手的问题是修改放大问题。这一问题指的是源数据表当中一条简单的修改，
在算子增量执行的时候会产生大量的下游修改。也就是说某一个算子接收了一个很小的增量表，却向下游输出巨大的增量表。
这种情况往往出现在使用 Join 的时候。在这里，我们假设系统已经根据上文当中的查询放大问题进行了优化，
因此算子输出的增量表的内容都是必要的。研究下面的 SQL 的例子：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A.a, B.b <span class="keyword">FROM</span> A <span class="keyword">CROSS</span> <span class="keyword">JOIN</span> B</span><br></pre></td></tr></table></figure>
<p>作为一个没有条件的 Cross Join，很显然，<code>A</code>或<code>B</code>表当中的任何修改都会导致另外一个表的全部内容被查询并插入到增量表。
在一些即使有限制条件，但是数据分布比较倾斜的 Join 场景下也会出现这样的问题。这时往往只有一些无奈的选择：</p>
<ol>
<li>延迟刷新：通过选择时机，预防连续小的修改产生连续的批量计算操作</li>
<li>限制/扩充语义：和解决查询放大问题相同，通过限制和扩充语义，只满足用户的一部分需求。
特别是在流处理系统当中，引入一些新的 Join 形式和 Window 的概念，反而可以增强用户表达和实现流式处理需求的能力</li>
</ol>
<p>在后文的流处理模型介绍一章将会进一步介绍新引入的流式 Join 形式。</p>
<h3 id="u53EF_u81EA_u6211_u7EF4_u62A4_u6027_28Self-maintainability_29"><a href="#u53EF_u81EA_u6211_u7EF4_u62A4_u6027_28Self-maintainability_29" class="headerlink" title="可自我维护性(Self-maintainability)"></a>可自我维护性(Self-maintainability)</h3><p>一个算子被称为<strong>可自我维护的</strong>，当他可以完全使用内部状态处理增量表并输出数据给下游。
也就是说，对于可自我维护的算子，其增量表生成函数的形式是 $Q’’(\Delta T, S)$，其中 $\Delta T$
是增量表、$S$是内部状态。</p>
<p>可自我维护性在流处理和分布式查询场景下十分有用。首先对于流处理来说，输入表也许是不可重入的，
也就是说你不能轻易地查询任意久远之前的数据。这时就要求算子能支持一定的可自我维护性，
避免反向查询输入流的操作。对于分布式查询来说，不同算子可能运行在不同的机器上，
因此跨算子的查询因为网络延迟的原因往往会比较低效。</p>
<p>有一些算子，如 Filter 等天然就可自我维护。另外一些算子(Join、Agg 等)
往往需要通过全量物化自己代表的视图才获得，这种做法往往需要消耗大量的状态空间。
当然也存在一些空间消耗比较适中的特别解决方案，但是他们都要根据其参数和输入数据分布，
通过成本估算来选定算法来实现，没有通用的解法。</p>
<p>一般来说，一个算子是否可以自我维护在 SQL 优化和计划生成阶段就完成了，但也有一些研究着眼于动态可自我维护性。
这种方法实现的算子会维护一些特别的状态，以便于分析输入的增量表，对于其中可以自行解决的项目直接利用内部状态计算，
其他的部分再反向查询。</p>
<p>值得注意的一点是，可自我维护性并不是取得高查询性能的必要条件。查询的执行器应该综合考虑时间和空间成本的平衡，
在整个查询产生的算子树上选择部分合适的节点物化内容和实现可自我维护性。从这里可以看出，
查询优化器及其相关算法增量 SQL 处理过程当中的重要作用。事实上，根据输入数据的分布的统计数据和算子的特性，
建立查询成本估计的数学模型是一项非常重要且紧缺的技能。</p>
<p><img src="/img/streaming-sql/optimizer-guy-wanted.png" alt="Optimizer Guy Wanted"></p>
<h2 id="u6D41_u5F0F_u5904_u7406_u4E0E_u65F6_u95F4_u64CD_u4F5C"><a href="#u6D41_u5F0F_u5904_u7406_u4E0E_u65F6_u95F4_u64CD_u4F5C" class="headerlink" title="流式处理与时间操作"></a>流式处理与时间操作</h2><p>流(Stream)可以被看作一种无界(Unbounded)且只可追加的(Append-Only)的数据表。
如果把新来的事件看作插入条目的增量表，我们就可以用之前提到的物化视图维护算法增量地执行 SQL。
Apache Flink 和 Samza 之类的系统大多采用了这种方式。</p>
<p>由于流处理系统的输入是无限增长的，我们希望能就以下问题进行讨论：</p>
<ol>
<li>如何在流处理系统当中处理时间，并利用这一特性限制内部状态的大小</li>
<li>如何扩展 SQL 以支持描述时间方面的需求，使得执行器更好地理解需求并执行</li>
</ol>
<h3 id="u6D41_u5904_u7406_u7CFB_u7EDF_u7684_u65F6_u95F4_u64CD_u4F5C"><a href="#u6D41_u5904_u7406_u7CFB_u7EDF_u7684_u65F6_u95F4_u64CD_u4F5C" class="headerlink" title="流处理系统的时间操作"></a>流处理系统的时间操作</h3><p>在现实世界的分布式系统当中处理流主要面对的问题有：</p>
<ol>
<li>绝对时钟(Absolute Clock)问题：现实世界当中的时钟往往不精确，而且在分布式系统当中实现时间绝对同步是(物理上)不可能的</li>
<li>时间倾斜(Time Skew)问题：由于系统中必然会存在网络延迟、网络中断和系统崩溃等问题，
发送到系统的消息和系统内部的消息很可能失序乃至丢失</li>
</ol>
<p>对于第一个问题，现代操作系统普遍使用事件驱动(Event-Driven)模型来处理。通过使用消息本身携带的生成时间(Event-Time)
而不是系统接收到消息的时间(Processing Time)来进行处理。这样的系统当中，时钟是由事件来驱动的。
没有新的事件到开，系统的状态就如同冻结起来了一样。</p>
<p><strong>激发器(Trigger)</strong>是一类特别的事件，当这种事件的消息被接收到时，某些任务会被激发和执行。
可以被当作激发器的消息有很多:</p>
<ol>
<li>新的数据从消息队列中到达</li>
<li>某一算子计算产生的增量表发送到下游算子</li>
<li>下游算子对上游算子发送的 ACK 消息</li>
</ol>
<p>有了激发器之后，我们的模型当中就不需要存在物理时间，
采用了这种事件驱动模型或者反应式设计模型的系统可以变得更加函数式和无状态。</p>
<p>值得注意的是，每个算子可以自行决定自己处理激发器的逻辑。它们可以自由地忽略、收集、聚合和发送事件。
这些逻辑设计有可能有助于提高系统的性能和降低通讯开销。</p>
<p>接下来考虑时间倾斜问题，可以回忆一下 TCP 是如何处理丢包和不按顺序到达的包的：
为每个包编号并维护已经获得 ACK 的包的编号。在流式系统里也采用了类似的方法。</p>
<p><strong>水印(Watermark)</strong>就是用来处理这一问题的。简单来说，水印就是根据消息的事件时间来决定一条消息应该被处理还是被丢弃的标记。
下图展示了水印起作用的方式：</p>
<p><img src="/img/streaming-sql/time-handling.jpg" alt="Watermark"></p>
<p>上图中，从右到左是消息到达的时间，在某时刻，消息8通过激发器激发了一次对水印的修改。此时水印的时间限制被修改为 4 。
这意味着之后到达的标号时间小于4 的消息都会被丢弃。在消息 8 之后到达的消息 7 和 5，虽然时间戳比消息 8 要早，
但是因为仍在 Watermark 的范围里，因此会被考虑在内。最后到达的消息有时间标号 9，他是一条当前观察到过的消息之后的消息，
因此也会被处理。</p>
<p>从上述讨论当中我们可以看到:</p>
<ol>
<li>水印应该永远小于当前处理过的事件的时间戳</li>
<li>水印是通过激发器的激发来移动的，算子可以自己决定移动水印的时间，而不是每个接收到的事件都会改变水印</li>
<li>水印必须是单调递增的。否则，一旦水印向前移动，我们无法知道是否已经有被包含在水印范围里的消息被丢弃</li>
</ol>
<p>水印不仅仅是处理时间偏移问题的利器，他也有助于实现限制算子内部状态大小的逻辑。算子可以通过检查水印标记的时间，
将自己内部状态中较老的不会被用到的条目移除掉。在实现严格单次发送(Exactly-Once Delivery)的系统中，
正确管理水印对于防止移除之后仍可能被查询到的条目非常重要。因此，在比较先进的系统中使用者都可以指定一个如下形式的函数:</p>
<p>$$t_{watermark}=F(t_{processed}, t_{ack}, Env)$$</p>
<p>在上述公式中，水印 $t_{watermark}$ 是由处理过的消息的时间 $t_{processed}$、从下游接收到的 ACK 消息附带的时间 
$t_{ack}$ 和系统的其他环境参数 $Env$ 所决定的。算子决定水印的逻辑十分有灵活性，但是设计这样一个函数也需要一些灵感：</p>
<ol>
<li>如果水印前进的太慢，算子的内部状态可能膨胀于过大</li>
<li>如果水印前进太快，过多的消息可能被丢弃掉</li>
</ol>
<p><strong>窗口(Window)</strong>是一种设计出来让用户更好地描述它们对时间的需求的工具。
他可以让用户在一个窗口里以有限时间/数据范围的方式操作数据，同时也为进一步优化时间空间成本提供了可能。</p>
<p>流处理系统提供的常见的窗口类型有：</p>
<ol>
<li>固定窗口(Fixed Window)：长度固定的窗口，每个窗口一个紧跟着一个将时间维度划分成片段</li>
<li>滑动窗口(Sliding Window)：长度固定，但每个窗口的开始时间相比于前一个窗口都有一个固定的时间偏移</li>
<li>会话窗口(Session Window)：使用事件的属性和相互的时间间隔把他们组织在一个窗口里。这些窗口的开始时间、
持续长度等都会变化。这类窗口用于用户追踪、线索跟踪等场景十分有效</li>
</ol>
<p><img src="/img/streaming-sql/windowings.jpg" alt="Windows"></p>
<p>有了窗口的语义，流处理引擎就可以强制一些不适合全局使用的计算(如 Join 和 Group By 等操作)在同一个窗口内完成。
这样，执行任务时需要处理的数据量和计算成本都有了边界。事实上，有些系统只支持窗口内的 Stream Join。</p>
<p>值得注意的是，窗口和水印是两个不同的概念。一个窗口的结束时间已经过去，
并不意味着这个窗口不能再接收迟到的落入这个窗口的消息。实际上，这个窗口的内部状态可以被一直保存，
以便于在接收到新的消息之后刷新窗口内容并输出增量表。一个窗口及其内部状态将只会在水印完全通过之后被回收。
事实上，一个窗口的打开和关闭都有赖于激发器的作用。</p>
<p><img src="/img/streaming-sql/window-with-watermark-triggers.jpg" alt="Window with Watermark/Trigger"></p>
<p>从上图可以看出，窗口不仅是一个查询聚合的单位，也是状态管理的单位。水印则要么完全包含一个窗口，
要么完全通过一个窗口。图中也介绍了一个新的概念<strong>句点(Punctation)</strong>。句点是一些在窗口关闭之前激发的激发器，
他使得窗口可以输出他的中间结果而不必等带整个窗口的消息都处理过。这对于提供低延迟数据传达十分有用。</p>
<p>对于激发器、水印、窗口和句点这些概念，十分建议进一步阅读如下文章和论文:</p>
<ol>
<li><a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101" target="_blank" rel="noopener">Stream 101: The world beyond batch</a></li>
<li><a href="https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102" target="_blank" rel="noopener">Stream 102: The world beyond batch</a></li>
<li><a href="https://ai.google/research/pubs/pub43864" target="_blank" rel="noopener">The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded,
Out-of-Order Data Processing</a></li>
</ol>
<h3 id="Stream_Join__u7684_u8BED_u4E49"><a href="#Stream_Join__u7684_u8BED_u4E49" class="headerlink" title="Stream Join 的语义"></a>Stream Join 的语义</h3><p>了解完流式处理当中的时间处理，接下来我们总结一下在流式系统当中实现 Join 的语义。
显而易见，由于 Stream 都是无边界的数据，传统数据表当中的 Join 概念在流处理系统当中可能不完全适用。
来流处理系统当中的 Join 往往有以下几种类别和语义：</p>
<ol>
<li>Stream 与纯静态表 Join。这里的纯静态表的内容不会改变，因此 Join 的实现只是在 Stream 
端对每个消息在静态表内进行查询</li>
<li>Stream 与动态表的快照 Join。动态表的内容可能会出现增删改等情况，这里的 Join 的语义是，
当对流当中的某个消息实施 Join ，相当于查询了动态表在那一时刻的快照</li>
<li>Stream 与 Stream Join，操作的两边都是 Stream，这种情况最为复杂也很难实现，在之后将会进一步介绍</li>
</ol>
<p><img src="/img/streaming-sql/stream-join.jpg" alt="Stream Joins"></p>
<p>与纯静态表 Join 是简单的。动态表与Stream Join 则是通过将动态表处理成类似 MVCC 并发控制那样的形式，
因此在每一个来自于 Stream 的消息需要 Join 时，只需要查询对应<strong>事件时间</strong>下动态表的快照即可。
前面说过，Stream 也可以认为是一种表，如果把 Stream 里的消息解读成插入或覆盖操作，
就可以得到一个动态表。请注意，在 Stream Join 动态表这个模型中，动态表这端虽然可能也是由 Stream
而来，但是对动态表的插入和修改操作(也表示称 Stream 消息)并不会激发 Join 结果的刷新。
这些消息只是被加入到内部状态中，等待 Stream 里的消息激发刷新时查询。
这是动态表 Join Stream 与Stream Join Stream 最大的区别。</p>
<p>Stream Join Stream 是最难以实现的 Join 方式，前文提过，这种类型的 Join
在两边有消息来的时候都有可能激发大量查询和修改操作，因此面临着严峻的查询放大放大和修改放大问题。
因此虽然可以利用物化视图的算法来解决，实际应用中却不十分方便。
在流式处理系统中，一种解决方法是结合窗口语义实现局部的 Join，下图描述了不同窗口下 Join 的语义。</p>
<p><img src="/img/streaming-sql/windowed-join.jpg" alt="Windowed Join"></p>
<p>可以看到，如此 Stream Join 就被转换为了局部的窗口 Join。除了这篇文章内介绍的 Join 方式，
学术界和工业界还提出了许多其他的形式和实现方法，在这里不再一一枚举。这些 Join
都是为了满足实际需求所提出 Join 的简化变种。</p>
<h2 id="Apache_Flink__u7684_u80FD_u529B_u4E0E_u5C40_u9650"><a href="#Apache_Flink__u7684_u80FD_u529B_u4E0E_u5C40_u9650" class="headerlink" title="Apache Flink 的能力与局限"></a>Apache Flink 的能力与局限</h2><p>在介绍完的一些基本理论之后，这一章节结合实际系统 Apache Flink 对相关技术实现进行一点总结。
简单来说，前面所介绍的流式处理的各种概念，基本上都已经被 Flink 采纳和实现了。
因而我们将主要讨论其他涉及的问题:</p>
<ol>
<li>Flink 内部的状态如何管理？</li>
<li>Flink 如何实现严格单次发送(Exactly-once Delivery)？</li>
<li>Flink 的 SQL 系统如何实现，其能力范围如何？</li>
</ol>
<h3 id="u72B6_u6001_u7BA1_u7406"><a href="#u72B6_u6001_u7BA1_u7406" class="headerlink" title="状态管理"></a>状态管理</h3><p>Apache Flink 实现了所谓的有状态(Stateful)流式处理的模型。它适用了常用于事件驱动开发或反应式设计模式的 Akka
和 Actor 模型实现算子。当一个 Flink 任务进程开始之后，可以托管一个或多个算子。每个算子将会在本地维护自己的状态。
Flink 的状态储存后段可以选用 In-Memory、FileSystem 和 RocksDB 几种。只有 RocksDB 后端支持增量 Checkpoint。</p>
<p>在比较早的流处理系统如 <a href="https://ai.google/research/pubs/pub41378" target="_blank" rel="noopener">MillWheel</a> 中，选择了远程状态储存，
如 HBase、BigTable 等。
而一些新近的系统则声称<a href="https://www.oreilly.com/ideas/why-local-state-is-a-fundamental-primitive-in-stream-processing" target="_blank" rel="noopener">本地储存才是流处理的最佳拍档</a>。
现在，诸如 Apache Flink 和 Apache Samza 的系统都使用本地储存来实现超低延迟的数据处理，
这是因为远程状态由于网络通讯的原因会导致数据处理请求变慢。此外，本地状态也更容易实现并发控制等功能。</p>
<p>不过，本地状态也并非完美，他的主要缺点包括：</p>
<ol>
<li>难以正确实现持久化和容错</li>
<li>容易受到偏斜数据分布的影响，数据难以再平衡(Rebalance)</li>
</ol>
<p>为了实现持久化和容错，Flink 支持 Checkpoint 系统状态。这一过程也很类似 MVCC 的过程。
在两次检查点之间的状态修改将会以增量的方式储存，如果处理管线错误推出，这些中间修改的内容将会一起被丢弃，
因此系统就恢复到上次 Checkpoint 时的一致状态。</p>
<p>由于每个算子不断地和其他算子相交互，Checkpoint 也必须是对系统全局一致的快照，
否则在恢复系统是，不同的算子可能有状态不匹配的问题。Apache Flink 通过
<a href="https://en.wikipedia.org/wiki/Chandy%E2%80%93Lamport_algorithm" target="_blank" rel="noopener">Chandy-Lamport 快照算法</a>
一个变种来实现异步的全局一致 Checkpoint。</p>
<p>Flink 也提供了 Savepoint 的概念，Savepoint 是一种包含更全面信息的 Checkpoint。
虽然需要花费更多时间来构建 Savepoint，它却使得系统状态回滚和迁移变得方便。</p>
<h3 id="u4E25_u683C_u5355_u6B21_u53D1_u9001"><a href="#u4E25_u683C_u5355_u6B21_u53D1_u9001" class="headerlink" title="严格单次发送"></a>严格单次发送</h3><p>严格单次发送对于流式处理系统意义重大。设想我们需要实现一个点赞数量统计的功能，
这时我们显然不希望消息被多发或者少发而导致统计不准确。遗憾的是在现有网络条件下这点不能轻松实现。</p>
<p>Flink 依赖于其强一致的状态管理来实现严格单次发送的语义。在分布式系统当中无法完美发送消息的主要原因是:</p>
<ol>
<li>网络延迟或中断导致无法可靠传递消息</li>
<li>重发协议会可能会导致消息被发送多次</li>
</ol>
<p>通过消息编号、重发和去重，我们可以在一个相对稳定的网络条件下实现副作用意义上的严格单次发送。
所谓副作用意义上的严格单次发送，意思就是指在至少一次发送(At Least Once)发送的前提下，
通过去重消除重复消息对系统状态产生的作用，这样计算得到的结果就根所有消息只发送了一遍相同。</p>
<p>Flink 将记录发送进度的标志一并保存在算子状态中并交由 Checkpoint 定时保存。
这时，当系统崩溃重启，不光系统状态恢复到之前，进度记录也恢复回去了。
因此系统就像那个时候一样重新开始了工作。</p>
<p>为了能真正获得准确的结果，不单需要 Flink 系统内部的保证，外部系统也要符合一些要求:</p>
<ol>
<li>输入的消息队列对消息有编号</li>
<li>消息队列支持重设到某一过去编号的位置开始消费</li>
<li>输出端需要支持事务类型的写入或者写入是幂等的</li>
</ol>
<p>第三条的原因是，当 Flink 因重启恢复到之前状态时，部分工作结果可能已经被写出。
而从恢复的状态开始，这些结果又将会被重复输出一遍。因此，要么输出系统支持 Flink 提供的 2-Phase Commit
协议从而可以撤回未 Commit 的数据，要么程序被设计成重复写入所得结果不变的形式。</p>
<p>值得高兴的是，Kafka 恰好满足上述条件。Flink 也提供了使用 Kafka 实现严格单次发送的 Connector。</p>
<h3 id="Stream_SQL"><a href="#Stream_SQL" class="headerlink" title="Stream SQL"></a>Stream SQL</h3><p>在事件驱动模型上，Flink 实现了流式处理和批量处理，并在这基础上进一步提供了 Table API 和 SQL 的支持。
其 Table API 和 SQL 基本上实现了之前提到的物化视图增量更新算法。特别地，Flink 还使用了 Apache Calcite
提供的 SQL 解析和优化模块来执行相关任务。</p>
<p>从 SQL 的语义上来讲，Flink 的 SQL 也实现了窗口语义，它们分别是:</p>
<ol>
<li><code>TUMBLE</code> 函数提供了固定窗口</li>
<li><code>HOP</code> 函数提供了滑动窗口</li>
<li><code>SESSION</code> 函数提供了会话窗口</li>
</ol>
<p>当这些函数出现在 Group By 当中时，Flink 将会把计算转变为窗口化执行的。</p>
<p>就 Join 而言，通过 <a href="https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/streaming/temporal_tables.html" target="_blank" rel="noopener">Temporal Table</a>
的概念，Flink 提供了覆盖静态表和动态表 Join Stream 的能力(静态表是不会变的动态表)。
由于实现了物化视图的增量更新算法，Flink 的 Table API 理论上可以实现无边界的 Stream 到 Stream 的 Join。
然而由于内部状态大小的限制，Flink 可能会按照 LRU 的 Cache 管理策略清理一些比较老的项目，
因此会导致结果的不准确。</p>
<p>因此，Flink 十分建议使用 Group By 等方法将 Join 处理成窗口内的。在这方面，使用 Java 的 
Table API 要比直接输入 SQL 查询更方便些。这是因为 SQL 解析器需要通过其他方面的语法分析来推断窗口，
这方面实际上非常困难。</p>
<p>此外，Flink 的 SQL 只支持 EquiJoin，也就是说 Join 条件中一定要符合 <code>(T1.a = T2.b) AND (....)</code> 这样的形式。
这里 <code>T1.a</code> 和 <code>T2.b</code> 是来自两个表当中的字段。怀疑 Flink 可能需要利用这个条件进行状态的内部管理和加快查询。</p>
<p>当构造好合适的查询之后，可以将某个查询输出到<code>RetractStreamSink</code>从而转换成附带增加/删除标记的行。
这样就可以把这些行输出到外部系统储存和进一步使用了。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>在本文中，我们介绍了 Stream SQL 查询执行的基本原理。
介绍了物化视图增量维护的算法并指出流式 SQL 处理实际上是物化视图增量维护的子问题。
我们还介绍了一些常见的流式处理的概念并结合 Apache Flink 对这些技术原理的实现进行了描述。</p>
<p>我们可以看到，现阶段大多数 Stream SQL 系统在实现功能和语义上仍然还有局限。
完全实现任意 SQL 查询高效增量执行仍又不可及。尽管如此，针对特定的查询需求和模式引入特别的实现方法和扩展新的语义，
现在的流式 SQL 系统已经可以覆盖相当宽广的需求。</p>
<p>同时我们也看到了好的 SQL 优化器和成本估算模型的重要性。它们在执行方案、
状态管理逻辑和时间空间成本平衡方面都发挥重要的作用，相关的研究更是方兴未艾。
一些研究方向包括:</p>
<ol>
<li>更准确的统计信息搜集</li>
<li>更有效的成本估算模型</li>
<li>有动态适应能力的优化算法和执行模型</li>
</ol>
<p>同时，作为数据集成(Data Integration)应用的一部分，数据输入输出源的管理、用户应用接口和改变查询语句的 DDL
操作等需求的实现也是非常有价值的方向。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在数据仓库应用中，执行 ETL 过程是一种常见的需求。我们希望通过 ETL 过程预处理我们的原始数据，
从而达到抽取有用信息和将数据转换为适合进一步查询的格式等目的。MapReduce 和 Spark
等批数据处理系统已经很好地解决了在高延迟的场景下的需求，目前低延迟的流式处理和增量计算是主要的发展方向。
本文将结合 Apache Flink 系统讨论相关技术课题。</p>]]>
    
    </summary>
    
      <category term="Big Data" scheme="https://io-meter.com/tags/Big-Data/"/>
    
      <category term="SQL" scheme="https://io-meter.com/tags/SQL/"/>
    
      <category term="Stream SQL" scheme="https://io-meter.com/tags/Stream-SQL/"/>
    
      <category term="Incremental SQL" scheme="https://io-meter.com/tags/Incremental-SQL/"/>
    
      <category term="Materialized View" scheme="https://io-meter.com/tags/Materialized-View/"/>
    
      <category term="Flink" scheme="https://io-meter.com/tags/Flink/"/>
    
      <category term="Apache Flink" scheme="https://io-meter.com/tags/Apache-Flink/"/>
    
      <category term="ETL" scheme="https://io-meter.com/tags/ETL/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[SQL 查询优化原理与 Volcano Optimizer 介绍]]></title>
    <link href="https://io-meter.com/2018/11/01/sql-query-optimization-volcano/"/>
    <id>https://io-meter.com/2018/11/01/sql-query-optimization-volcano/</id>
    <published>2018-11-01T09:59:47.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>随着大数据相关技术的发展，SQL 作为一种成熟的查询语言又逐渐回到人们视野的中心来，被称为
NewSQL 的新型关系型数据库更是蓬勃发展。 作为一种声明式编程语言，将 SQL 转化为可以高效执行的任务对于
OLAP 任务来说是至关重要的。 本文将尝试对相关的技术原理进行一次总结。</p>
<a id="more"></a>
<p>本文将重点着眼于对 Volcano(Cascades) Optimizer的详细介绍上，这是因为 Volcano 模型不但十分流行，
更是被 <a href="https://calcite.apache.org/" target="_blank" rel="noopener">Apache Calcite</a> 这一优秀的开源框架所实现了。
我们因此可以通过直接阅读 Calcite 的源码来了解算法执行的内部细节。</p>
<p>尽管 Apache Calcite 这一项目并不是经常出现在人们眼前，但却是 Apache 数据平台技术栈当中及其有价值的组件。
它提供了一套 SQL 的解析与执行接口，包含了 SQL 查询和执行相关的一系列任务的执行代码。
使用者只需要将自己的数据模型 Plugin 到 Calcite 当中，就可以得到 SQL 查询的能力。
包括 Apache Storm, Apache Flink, Apache Kylin 和 Apache Drill 等项目都使用它完成 SQL 解析或执行的操作。</p>
<p>遗憾的是，除了<a href="https://arxiv.org/pdf/1802.10233.pdf" target="_blank" rel="noopener">相关论文之外</a>，其文档等对于内部细节的介绍都不够充分。
本文作为对其部分代码细节进行阅读之后的浅显总结，同时也希望能为各位读者使用 Calcite 有所帮助。</p>
<p>另外值得注意的是，本文使用 Volcano Optimizer 代指 Volcano 和 Cascades 两种算法，
一个是因为二者是一脉相承的关系，很多基本思想是一样的，另外一点是很多有关 Volcano 优化器的相关信息其实是由
<a href="https://15721.courses.cs.cmu.edu/spring2018/papers/15-optimizer1/xu-columbia-thesis1998.pdf" target="_blank" rel="noopener">Cascades 相关的 Paper</a>
 总结和介绍的。</p>
<h2 id="SQL__u67E5_u8BE2_u4F18_u5316_u7684_u76EE_u7684"><a href="#SQL__u67E5_u8BE2_u4F18_u5316_u7684_u76EE_u7684" class="headerlink" title="SQL 查询优化的目的"></a>SQL 查询优化的目的</h2><p>SQL 查询优化在 OLAP 应用当中至关重要的主要原因在于 SQL 是一种声明式(Declarative)的编程语言，
相比一般的编程语言描述的是程序执行的过程，这类编程语言则是描述问题或者需要的结果本身。
具体的执行步骤则交由程序自己决定。</p>
<p>从使用的角度，SQL 作为一种可以被非相关技术人员快速入手的编程语言，
其主要优点就在于即使用户因并不了解数据库内部的实现细节而写出来十分糟糕的查询语句，
只要表达的意思准确清楚，数据库就可以在一定程度上将其转化为合理的执行方案高效的返回结果，
极大的降低了使用门槛。因此一个好的查询优化器，也是关系型数据库重要的卖点之一。</p>
<p>从技术的角度来说，通过对用户输入的查询进行优化，实现更优的执行步骤规划
数据库可以实现更快的执行和更少的 IO 消耗。从而节约资源提高性能。</p>
<h2 id="SQL__u67E5_u8BE2_u4F18_u5316_u7684_u57FA_u672C_u539F_u7406"><a href="#SQL__u67E5_u8BE2_u4F18_u5316_u7684_u57FA_u672C_u539F_u7406" class="headerlink" title="SQL 查询优化的基本原理"></a>SQL 查询优化的基本原理</h2><p>SQL 作为一项图灵奖级别的发明，其重要意义不单单是发明了一种可以用作数据查询的语言，
更重要的一点是发明了<a href="https://en.wikipedia.org/wiki/Relational_algebra" target="_blank" rel="noopener">关系代数(Relation Algebra)</a>这一工具，
使得计算机理解和处理查询的语义更加方便。SQL 查询语句的优化也是基于关系代数这一模型。</p>
<p>所谓关系代数，是 SQL 从语句到执行计划的一种中间表示。首先它不是单纯的抽象语法树(AST)，
而是一种经过进一步处理得到的中间表示(可以类比一般编程语言的 IR)。SQL 优化的本质是对关系代数的优化。</p>
<p>关于关系代数的具体内容这里不再赘述，我们直接来看一个例子。假设我们有如下的 SQL:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> pv.siteId, user.nickame</span><br><span class="line"><span class="keyword">FROM</span> pv <span class="keyword">JOIN</span> <span class="keyword">user</span></span><br><span class="line"><span class="keyword">ON</span> pv.siteId = user.siteId <span class="keyword">AND</span> pv.userId = user.id</span><br><span class="line"><span class="keyword">WHERE</span> pv.siteId = <span class="number">123</span>;</span><br></pre></td></tr></table></figure>
<p>上述 SQL 假定我们有两个数据表<code>pv</code>和<code>user</code>，前者记录了用户的 Pageview 访问，
后者是用户信息表。这两张表可以使用<code>siteId</code>和<code>userId</code>(<code>user.id</code>)连立合并起来，
这样我们就既可以查到用户的 PV 信息，又可以将 PV 信息对应到用户资料。</p>
<p>将上述 SQL 表示成关系代数，可能是如下形式:</p>
<p><img src="/img/sqlopt/relation-algebra.png" alt="Relation Algebra"></p>
<p>可以看到，上述关系代数将 SQL 表示成树形的结构，树形结构的叶子结点是 SCAN 算子，
负责从储存设备将表中的信息读出。之后两个表的数据被输送到 JOIN 算子中实现合并计算。
JOIN 得到的数据又被输入一个 FILTER 算子中执行 WHERE 语句的条件(即过滤操作)。
最后的顶层算子是 PROJECT 算子，这个算子可以将输入数据当中的指定列取出，也可以对这些列进行重命名。</p>
<p>显然，关系代数本身就一定程度上体现了 SQL 查询的计算方案。
一般来说，实际的数据库实现还存在逻辑代数处理阶段和物理实现处理阶段，
这两个阶段使用的算子不同。数据流动也存在 Pull 模式和 Push 模式两种。
在这里我们先略去对这些信息的讨论，单纯研究如何通过关系代数优化执行方案。</p>
<p>观察上述关系代数的表示，我们发现最终的结果只需要使用到<code>pv.siteId</code>、<code>pv.userId</code>
<code>user.id</code>和<code>user.nickname</code>四列数据。即使我们的表有几十列其他的数据，也对最终的结果没有影响。
将这些表的其他列读取出来向上传输和计算是一种浪费。如果我们的表支持高效地只读取需要的列，
那么从一开始就这么做会大大提高性能。下图描述了这种变换:</p>
<p><img src="/img/sqlopt/projection-pushdown.png" alt="Projection Pushdown"></p>
<p>通过只读取特定列来减少 IO 损耗、增加执行性能的技巧正是现今流行的列式储存的优点。</p>
<p>继续观察我们的关系代数树，可以发现对于<code>pv</code>表有一个条件过滤操作。
假设我们的<code>pv</code>表在<code>siteId</code>这一列创建了索引，或者这个表在就是按照这一列的值分散储存的。
在这种情况下，显然我们可以做到在 SCAN 的时候直接找到对应 <code>siteId</code> 所在的区域，
只读取符合匹配条件的数据出来。避免读取不相关<code>siteId</code>的数据可以极大地减少 IO 和提高性能。</p>
<p><img src="/img/sqlopt/predicate-pushdown.png" alt="Predicate Pushdown"></p>
<p>上图描绘了这种变换。实际上，这种变换被称为谓词下推(Predicate Pushdown)，
是普遍应用在各种文件储存格式(ORC、Parquet)和各种 SQL 数据引擎(Hive、Kylin)
上的常见的查询优化方式。</p>
<p>通过上面的几步，我们成功将最初的关系代数模型化简成为一种更为简单高效，
实际效果却完全一样的关系代数。最后的结果是一种相比之前更优的执行方案，
因此也就实现了我们进行查询优化的目的。</p>
<p>总结使用关系代数进行查询优化的要点:</p>
<ol>
<li>SQL 查询可以表示成关系代数</li>
<li>关系代数作为一种树形的结构，实质上也可以表示查询的物理实现方案流程</li>
<li>关系代数可以进行局部的等价变换，变换前后返回的结果不变但执行的成本不同</li>
<li>通过寻找执行成本最低的关系代数表示，我们就可以将一个 SQL 查询优化成更为高效的方案</li>
</ol>
<p>此外，很重要的一点是:
实现关系代数的化简和优化，依赖于数据系统的物理性质，如</p>
<ol>
<li>储存设备的特性(顺序读性能如何？随机读性能如何？吞吐量如何)</li>
<li>储存内容的格式和排列(列式储存？行式储存？是否以某列进行分片？)</li>
<li>包含的元数据和预计算结果(是否存在索引？是否存在物化视图？)</li>
<li>聚合和计算单元的特性(单线程？并发计算？分布式计算？特殊加速硬件？)</li>
</ol>
<p>综上所述，对 SQL 查询进行优化，既要在原先逻辑算子的基础上进行变换，
又要考虑物理实现的特性，这就是为什么很多查询系统存在逻辑方案和物理方案的区别的原因。
在优化时，往往存在一个从逻辑方案到物理方案进行转变的阶段。</p>
<p>事实上，从逻辑方案到物理方案的变换也可以划归为一种关系代数的优化问题。
本质上仍然是按照一定的规则将原模型当中的局部等价地转换成一种可以物理执行的模型或算子。
一个最简单的例子就是 JOIN 方案的选择：</p>
<p><img src="/img/sqlopt/logical-join-to-physical-join.png" alt="Physical Plan"></p>
<p>如上图所示，JOIN 算子只描述了两个表需要进行 JOIN 的逻辑，但是并没有指定 JOIN 的实现方案。
右边的 HASH JOIN 和 SORT JOIN 代表着 JOIN 操作的两种不同的实现方案。
两种方案在不同的场景下各有优劣，需要根据实际输入数据的特点进行选择。
然而尽管是从逻辑算子到物理算子的变换，其基本原理仍然是根据一定的规则进行代换而已，
与逻辑算子之间的代换并无本质差别。</p>
<p>另一种具有代表性的优化方案是 SORT LIMIT 的实现方案。假设一个查询会将数据进行排序，
然后 LIMIT 取最高的几个值。当取得的值比较少的时候，显然可以采取一定的措施避免对全部数据进行排序
(使用堆缓冲等)。鉴于排序是一种耗费很多的操作，对其进行优化很有价值。下图展示了一种优化方法:</p>
<p><img src="/img/sqlopt/sort-limit-to-top-n.png" alt="Top-N"></p>
<p>上述优化证明了进行关系代数的变换时，往往不一定是一对一的关系。很多情况下可以将多个算子合并成一个算子。
实际上将一个算子进行拆分形成多个算子的场景也是有的。</p>
<h2 id="SQL__u67E5_u8BE2_u4F18_u5316_u7684_u57FA_u7840_u7B97_u6CD5"><a href="#SQL__u67E5_u8BE2_u4F18_u5316_u7684_u57FA_u7840_u7B97_u6CD5" class="headerlink" title="SQL 查询优化的基础算法"></a>SQL 查询优化的基础算法</h2><h3 id="u57FA_u4E8E_u89C4_u5219_u7684_u4F18_u5316_u7B97_u6CD5"><a href="#u57FA_u4E8E_u89C4_u5219_u7684_u4F18_u5316_u7B97_u6CD5" class="headerlink" title="基于规则的优化算法"></a>基于规则的优化算法</h3><p>前面的例子探索了 SQL 语句进行优化的过程。
将这一过程形式化的总结出来就得到了基于规则的优化方法。</p>
<p>基于规则的优化方法的要点在于结构<strong>匹配</strong>和<strong>替换</strong>。
应用规则的算法一般需要先在关系代数结构上匹配一部分局部的结构，
再根据结构的特点进行变换乃至替换操作。</p>
<p><img src="/img/sqlopt/pattern-match-rule.png" alt="Pattern Match"></p>
<p>值得注意的是，由于变换规则要保持关系代数语义不变的大前提没有改变，
因此被匹配的部分即使内部结构完全被替换，其跟外部的接口也要保持一致性：</p>
<ol>
<li>向上输出的数据内容和类型不变</li>
<li>下层接受输入的数量和类型不变</li>
</ol>
<h3 id="u57FA_u4E8E_u6210_u672C_u7684_u4F18_u5316_u7B97_u6CD5"><a href="#u57FA_u4E8E_u6210_u672C_u7684_u4F18_u5316_u7B97_u6CD5" class="headerlink" title="基于成本的优化算法"></a>基于成本的优化算法</h3><p>基于规则的优化算法在实际使用中仍然面对很多问题:</p>
<ol>
<li>变换规则的选择问题：哪些规则应该被应用？以什么顺序被使用？</li>
<li>变换效果评价的问题：经过变换的查询性能是否会变好？多种可能的方案哪个更优？</li>
</ol>
<p>对于上述问题，不同的算法给出了不同的答案。最朴素的方法是人工定义一些规则的优先级，
每次按照固定的优先级选择规则进行变换直到最后得到结果。这种方法往往无法得到最优的方法，
灵活性也比较差。</p>
<p>现阶段主流的方法都是基于成本(Cost)估算的方法。也就是说，给定某一关系代数代表的执行方案，
将会对这一方案的执行成本进行估算，最终选择估算成本最低的方案。</p>
<p>尽管被称为基于成本的方法，这类算法仍然往往要结合规则进行方案的探索。也就是说，
基于成本的方法其实是通过不断的应用规则进行变换得到新的执行方案，
然后对比方案的成本优劣进行最终选择。</p>
<p><img src="/img/sqlopt/plan-exploring-tree.png" alt="Plan Exploring"></p>
<p>上图展示了这一过程。其中，每一次关系代数的变换都是由于应用了不同的规则，
应用了某一规则之后还可以接下来应用其他规则，直到所有变化都被穷尽了为止。
对于每一种方案我们都可以计算得到一个估计的成本，如果可以计算出所有可能的变化，
我们就可以得到最优的方案。</p>
<p>显然，要不重复地遍历所有不同的关系代数表示本身就是一项相对棘手的算法问题，
即使实现了这样枚举的功能，其巨大的搜索空间也消耗很多计算力——查询优化本身是为了提高查询性能，
如果优化算法本身的性能堪忧，则执行这一步骤的意义就消失了。</p>
<p>接下来就讨论一种可以较好地解决上述问题的系统: Volcano Optimizer。</p>
<h2 id="Volcano_Optimizer"><a href="#Volcano_Optimizer" class="headerlink" title="Volcano Optimizer"></a>Volcano Optimizer</h2><p>Volcano Optimizer 是一种基于成本的优化算法，其目的是基于一些假设和工程算法的实现，
在获得成本较优的执行方案的同时，可以通过剪枝和缓存中间结果(动态规划)的方法降低计算消耗。
这一章在介绍 Volcano Optimizer 的同时也将会引入很多对 Calcite 当中概念的讨论。</p>
<h3 id="u6210_u672C_u6700_u4F18_u5047_u8BBE"><a href="#u6210_u672C_u6700_u4F18_u5047_u8BBE" class="headerlink" title="成本最优假设"></a>成本最优假设</h3><p>成本最优假设是理解 Volcano Optimizer 实现的要点之一。这一假设认为，
在最优的方案当中，取局部的结构来看其方案也是最优的。</p>
<p>成本最优假设利用了贪心算法的思想，在计算的过程中，
如果一个方案是由几个局部区域组合而成，那么在计算总成本时，
我们只考虑每个局部目前已知的最优方案和成本即可。</p>
<p>换句话说，在 Volcano 优化算法下，下图所表示的关系代数的计算成本，大体上正比于各个部分计算成本的和。
这一假设不仅应用于单个 Operator 节点之间，也应用于子树之间和被规则匹配的区域内外。</p>
<p><img src="/img/sqlopt/cumulative-cost-assumption.png" alt="Cumulative Cost"></p>
<p>对于成本最优假设的另一种更直观的描述是，如果关系代数局部的某个输入的计算成本上升，
那么这一子树的整体成本趋向于上升，反之则会下降。也即是在上图右侧有</p>
<p>$$Cost(A) \sim Cost(B) + Cost(C)$$</p>
<p>上述假设对于大部分关系代数算子都是有效的，但是并非百分之一百准确。
对于部分反例的处理方法将会在后文进一步介绍。</p>
<h3 id="u52A8_u6001_u89C4_u5212_u7B97_u6CD5_u4E0E_u7B49_u4EF7_u96C6_u5408"><a href="#u52A8_u6001_u89C4_u5212_u7B97_u6CD5_u4E0E_u7B49_u4EF7_u96C6_u5408" class="headerlink" title="动态规划算法与等价集合"></a>动态规划算法与等价集合</h3><p>由于引入了成本最优假设，在优化过程中我们就可以对任意子树目前已知的最优方案和最优成本进行缓存。
此后在计算的过程中，如果需要利用这一子树，可以直接使用之前缓存的结果。这里应用了动态规划算法的思想。</p>
<p>要实现这一算法，只需要建立缓存结果到子树双向映射即可。在 Calcite 的实现当中，一颗子树使用其根结点作为代表。
某一棵子树所有可能的变换方案组成的集合被称为等价集合(Equivalent Set)，
等价集合将会维护自身元素当中具有最优成本的方案。</p>
<p><img src="/img/sqlopt/equivalent-set.png" alt="Equivalent Set"></p>
<p>等价集合在 Calcite 当中对应的是<code>RelSet</code>类。</p>
<p>对每一颗子树都枚举其等价集合的内容会十分耗费空间。其实，对于某一棵以 A 为根结点的子树来说，
我们只关心 A 本身和包含 A 了的匹配内的节点。对于 A 和包含 A 的匹配之外的部分，
我们可以直接链接到子树对应的等价集合当中。基于成本最优假设，在计算方案成本的时候，
我们还可以直接从这些部分的等价集合中选取最佳方案。</p>
<p>假设从 A 起，可以应用两种不同的变换规则，如下图所示:</p>
<p><img src="/img/sqlopt/equivalent-set-recursive-build.png" alt="Equivalent Set Building"></p>
<p>则除了 A 本身和规则匹配到的部分，其他部分的计算就可以通过递推的方式实现
具体来说，对应上述三种情况，会计算等价集合的元素：</p>
<ol>
<li>A 节点结合 B、C 节点等价集合的最优元素和成本</li>
<li>A、C 转化后的节点结合 B、E、F 节点对应等价集合当中的最优元素和成本</li>
<li>A、B 转换后的节点结合 C、D、E 节点对应等价集合当中的最优元素和成本</li>
</ol>
<p>A 所代表的子树对应的最优方案也即是从上述三种方案中选取。</p>
<p>通过链接到子树优化方案的技巧，我们的算法缩减了状态空间、节省了计算量和储存空间。
下图展示了链接到子方案的大致思路。</p>
<p><img src="/img/sqlopt/equivalent-set-pointer-structure.png" alt="Equivalent Set Structure"></p>
<p>当然，在关系代数表示中不相邻的部分也可能具有重复的结构，Calcite 在实现的过程中考虑了这种情况，
将会在合适的时候对等价集合进行合并操作，也会出现树中两个不同子树的根指向了同一个等价集合的现象。</p>
<p>要实现树结构的相等计算和查询计算也比较复杂，Calcite 采用了最简单的递归将子树的内容打印成字符串的方法进行 Hash 和比较。
因此在使用 Calcite 时要注意正确实现 <code>RelNode</code> 类的 <code>getDigest</code> 方法。保证将节点的各种属性包含在内，
防止不同的节点被认为等价。</p>
<p>在计算结束后要得到最后的执行方案，只需从根节点开始将原始关系代数当中的结构替换成最优方案当中的即可。</p>
<h3 id="u81EA_u5E95_u5411_u4E0A_vs-__u81EA_u9876_u5411_u4E0B"><a href="#u81EA_u5E95_u5411_u4E0A_vs-__u81EA_u9876_u5411_u4E0B" class="headerlink" title="自底向上 vs. 自顶向下"></a>自底向上 vs. 自顶向下</h3><p>在实现上述动态规划算法的时候存在两种遍历方法，一种是自底向上的动态规划算法，
一种是自顶向下的动态规划算法。</p>
<p>自底向上的算法最为直观：当我们试图计算节点 A 的最优方案时，
其子树上每个节点对应的等价集合和最优方案都已经计算完成了，我们只需要在 A
节点上不断寻找可以应用的规则，并利用已经计算好的子树成本计算出母树的成本，就可以得到最优方案。
事实上，包括 SQL Server 在内的一些成熟的数据库系统都采用这种方法。</p>
<p>然而这种方案存在一些难以解决的问题:</p>
<ol>
<li>不方便应用剪枝技巧，在查询中可能会遇到在父亲节点的某一种方案成本很高，后续完全无需考虑的情况，
尽管如此，需要被利用的子计算都已经完成了，这部分计算因此不可避免</li>
<li>难以实现启发式计算和限制计算层数。由于程序要不断递归到最后才能得到比较好的方案，
因此即使计算量比较大也无法提前得到一个可行的方案并停止运行</li>
</ol>
<p>因此，Volcano Optimizer 采取了自顶向下的计算方法，在计算开始，
每棵子树先按照原先的样子计算成本并作为初始结果。在不断应用规则的过程中，如果出现一种新的结构被加入到当前的等价集合中，
且这种等价集合具有更优的成本，这时需要向上冒泡到所有依赖这一子集合的父亲等价集合，
更新集合里每个元素的成本并得到新的最优成本和方案。</p>
<p>值得注意的是，在向上冒泡的过程中需要遍历父亲集合内的每一个方案，这是因为不同方案对于 Input
成本变化的敏感性不同，不能假设之前的最优方案仍然是最优的。</p>
<p>自顶向下的方法尽管解决了一些问题，但是也带来了对关系代数节点操作十分繁琐、
要不断维护父子等价集合的关系等问题，实现相对比较复杂。</p>
<h3 id="u5E7F_u5EA6_u4F18_u5148_u641C_u7D22_u4E0E_u542F_u53D1_u5F0F_u7B97_u6CD5"><a href="#u5E7F_u5EA6_u4F18_u5148_u641C_u7D22_u4E0E_u542F_u53D1_u5F0F_u7B97_u6CD5" class="headerlink" title="广度优先搜索与启发式算法"></a>广度优先搜索与启发式算法</h3><p>如前文所述，采用自顶向下的方法之后就不需要保证子树的等价集合先被计算出来，
因此可以使用广度优先的顺序自根节点起向下遍历执行搜索任务。
在 Calcite 的实现之中，对于自某一节点开始激发的匹配规则(<code>RuleMatch</code>)，将会先被压入队列(<code>RuleQueue</code>)之中等待执行。
这样就比较方便限制搜索的层数从而提前返回结果。</p>
<p>如同 A* 算法应用在寻路任务当中用来加速执行一样，在引入队列之后的 Volcano Optimizer
当中也可以使用启发式算法——某一匹配规则及其产生的等价集合可以具备一定的 <code>Importance</code>。
用优先队列就可以在使这些规则的搜索按照重要性从高到低的顺序执行。</p>
<p>某一匹配规则也可以将变化后的结果设定为极高优先级，从而直接胜出而不会被其他规则所取代，
另一种个方向是给结果设定 0.0 值作为优先级，此时这一分支在未来几乎不会在被继续探索。
这也是实现自顶向下搜索实现剪枝的一种方法。促进算法收敛也是使用<code>Importance</code>的原因之一。</p>
<p>在这一基础上，Calcite 实现的 Volcano Optimizer 支持如下三种算法终止条件:</p>
<ol>
<li>时钟: 使用最大迭代计数或最大物理执行时间作为限制</li>
<li>成本阈值: 当优化方案的成本低于某个阈值是结束算法(相比原始成本或固定值)</li>
<li>规则穷尽: 当无法再应用规则获得新的关系代数结构的时候结束算法</li>
</ol>
<h3 id="Trait/Physical_properties_vector"><a href="#Trait/Physical_properties_vector" class="headerlink" title="Trait/Physical properties vector"></a>Trait/Physical properties vector</h3><p>前文提到，Volcano Optimizer 大致基于一个“成本最优假设”。
这一假设是在进行动态规划加速计算的基础之一。然而这一假设在一些情况下并不成立。
考虑下面的情况</p>
<p><img src="/img/sqlopt/sort-join-cost-decrease.png" alt="Sort Join with Index"></p>
<p>如图左边是对两个表进行 SORT JOIN 的关系代数。此时从 B 和 C 读入的数据直接按照储存顺序读取，
虽然成本很低但是是乱序的。这时就需要在 SORT JOIN 算子之中进行排序操作从而需要不少的计算量。
而系统如果利用索引进行读取，虽然不是再是顺序读取而有性能损失，
但是可以获得排序好的记录。这时在 SORT JOIN 算子只需进行合并操作即可，
整体的成本由于避免了全表排序反而更优。</p>
<p>也就是说，虽然两个输入的成本都变高了，但是由于引入了新的特性，整体执行反而更快。
这种问题在 Volcano Optimizer 当中使用 Physical properties vector 来解决。</p>
<p>在 Calcite 当中，这个东西称为 Trait。一个 <code>RelNode</code> 可以声明自己的 Trait，
人们也可以编写规则利用输入节点的 Trait 来优化执行。</p>
<p>在 Calcite 当中，具有不同 Trait 的优化方案虽然都在一个<code>RelSet</code>当中，
却按照相同 Trait 一类的方法分别组织在<code>RelSubset</code>对象里。
在进行方案成本估算和匹配规则应用等需要查询等价集合的情况下，不同的<code>RelSubset</code>会分别被处理。
这样的设计一定程度上解决了成本最优假设失效的问题。</p>
<p>典型的 Trait 包括记录是否有序、是否包含 NULL 值、字符串是否都短于某一特定值等。
利用 Trait 进行查询优化的逻辑十分复杂也需要小心处理。下图展示了一个简单却典型的 Trait 的用例:
如果一个子树的输出已经按照某一列被排序，则取消掉上层重复的排序算子。</p>
<p><img src="/img/sqlopt/eliminate-sort.png" alt="Eliminate Sort"></p>
<h3 id="u5176_u4ED6"><a href="#u5176_u4ED6" class="headerlink" title="其他"></a>其他</h3><p>前文分步骤解释了 Volcano Optimizer 的主要算法思想，在这里再结合 Calcite
的实现列举一些值得了解的事项：</p>
<ol>
<li>在最初的 Volcano Optimizer 论文中，算法存在逻辑优化和物理优化两个步骤，
在前者中会尽量将所有逻辑算子变换和展开。这一做法在后续的 Cascades
论文以及 Calcite 的实现中并没有体现。后两者当中，逻辑变换的规则和物理变换的规则没有本质的差别，
两者会在一轮优化当中同时使用，以期待快速从逻辑表示转换为物理执行方案。</li>
<li>在 Calcite 当中，可以覆写<code>RelNode</code>的<code>getCost</code>方法为自行实现的算子指定成本计算的方法，
尽管 Calcite 的 <code>Cost</code> 类包括 <code>rows</code>、<code>IO</code>、<code>CPU</code> 等多个字段，但现阶段只会比较 <code>rows</code> 的大小。
因此需要考虑把其他方面的成本换算为行数。</li>
<li>在关系代数树上查找匹配的结构是优化过程中最频繁的操作。Calcite 实现的匹配方法十分简单：
如果一个节点和某一匹配模式的根结点相互匹配，则从该节点进行一次校验。
从实践来看此方法性能较好。</li>
<li>Calcite 默认并不进行枚举式的优化方案计算，而是结合启发式算法进行有限的搜索，
因此也不一定能返回“成本最优假设”下的最优方案。</li>
</ol>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了基于关系代数对 SQL 查询进行优化的基本原理并结合 Calcite 项目详细介绍了
Volcano Optimizer 的设计思路。笔者认为，Apache Calcite 提供的 SQL 
解析、优化和执行层十分有价值，不单是学习数据库相关逻辑的极好教材，
也足以应用在各种成熟的项目当中。</p>
<p>除了本文介绍的查询优化算法，在查询执行过程中还有很多其他很重要的优化方式，例如</p>
<ol>
<li>Vectorized Execution 通过元素在关系代数节点之间的获取批量化以及利用 SIMD 
指令集优化提高并行性从而优化执行</li>
<li>Query Compilation 通过将优化好的执行方案通过 LLVM 等工具编译成机器码极大地加速了解释速度。
实际上 Calcite 就利用了 Janino 库来将优化后的方案编译成 JVM Bytecode 来执行</li>
<li>利用索引信息和物化视图来加速结果的返回</li>
</ol>
<p>以上每种方式都十分值得研究，希望以后有机会将相关的知识总结出来与大家一起探讨。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>随着大数据相关技术的发展，SQL 作为一种成熟的查询语言又逐渐回到人们视野的中心来，被称为
NewSQL 的新型关系型数据库更是蓬勃发展。 作为一种声明式编程语言，将 SQL 转化为可以高效执行的任务对于
OLAP 任务来说是至关重要的。 本文将尝试对相关的技术原理进行一次总结。</p>]]>
    
    </summary>
    
      <category term="Algorithm" scheme="https://io-meter.com/tags/Algorithm/"/>
    
      <category term="SQL" scheme="https://io-meter.com/tags/SQL/"/>
    
      <category term="Volcano" scheme="https://io-meter.com/tags/Volcano/"/>
    
      <category term="Cascades" scheme="https://io-meter.com/tags/Cascades/"/>
    
      <category term="Optimization" scheme="https://io-meter.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[图解图算法 Pregel: 模型简介与实战案例]]></title>
    <link href="https://io-meter.com/2018/03/23/pregel-in-graphs/"/>
    <id>https://io-meter.com/2018/03/23/pregel-in-graphs/</id>
    <published>2018-03-23T14:29:15.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>这篇文章是对之前在 <a href="https://www.shlug.org/monthly/2018/03/17/monthly-photo.html" target="_blank" rel="noopener">SHLUG</a>
月度分享活动上所作演讲 <a href="https://www.slideshare.net/ChaseZhang3/pregel-in-graphs-models-and-instances" target="_blank" rel="noopener">Pregel in Graphs</a>
的总结。为使分享内容清晰易懂，本人绘制了大量原创示意图，这篇文字版的总结也会尽量以这些图示为主。
除了对 Pregel 算法的简单介绍，本文还附加了一个用户追踪画像的实战案例，用以证明图计算模型的重要意义。</p>
<a id="more"></a>
<h2 id="Pregel__u7B80_u4ECB"><a href="#Pregel__u7B80_u4ECB" class="headerlink" title="Pregel 简介"></a>Pregel 简介</h2><p>Pregel 是 Google 自 2009 年开始对外公开的图计算算法和系统，
主要用于解决无法在单机环境下计算的大规模图论计算问题。与其说 Pregel 是图计算的算法，
不如说它是一系列算法、模型和系统设计组合在一起形成的一套图模型处理方案。</p>
<p>图计算的实际应用非常广泛，因此自 Pregel 公开之后，一些开源的方案也被实现出来，
比如说来自 Spark 的 <a href="http://spark.apache.org/graphx/" target="_blank" rel="noopener">GraphX</a> 就实现了 PregelAPI。
值得注意的是，Pregel 作为一个近十年前起就为人所知的算法，虽然新近也已经提出了不少增强和改进的技术，
但在现实场景下仍然是很有生命力的。</p>
<p>本文假定读者有基本的图论知识。</p>
<h2 id="u6A21_u578B_u7B80_u4ECB"><a href="#u6A21_u578B_u7B80_u4ECB" class="headerlink" title="模型简介"></a>模型简介</h2><p><img src="/img/pregel/pregel-basic-model.png" alt="Pregel 模型的基本要素"></p>
<p>上图展示了 Pregel 计算模型的基本要素，主要包括:</p>
<ol>
<li>节点(Vertex)。在 Pregel 中，每个节点都有全局唯一的 ID</li>
<li>边(Edge)。在 Pregel 中，每个边可以被 Assign 一个属性，这个属性可以是边的权值等信息</li>
<li>消息(Message)。消息是 Pregel 计算模型的核心。每个 Vertex 在初始状态以及之后的每一个计算步骤当中都被 Attach
一个 Message 值作为 Vertex 当前的状态，算法的迭代通过 Vertex 之间互相发送的消息来完成</li>
<li>超迭代(Superstep)。一个 Superstep 是 Pregel 在执行算法过程当中进行的一次迭代。
一次 Pregel 计算过程可能包括多个 Superstep</li>
</ol>
<p>在 Pregel 当中，Edge 一般是有向的。同时节点 Vertex 还存在 Active 和 Inactive 两种状态。
之后可以看到，节点的状态将会决定一些算法是否结束。</p>
<p><img src="/img/pregel/pregel-vertex-oriented-processing.png" alt="Pregel 算法以 Vertex 为中心"></p>
<p>Pregel 的图计算过程与 MapReduce 非常接近：在迭代的每一个步骤当中，
将会以图的节点为中心进行 Map 操作，这意味着在 Map 函数当中我们只有以某一节点为中心的局部信息，
这包括:</p>
<ol>
<li>一个 Vertex 和它当前 Attach 的 Message</li>
<li>当前 Vertex 向外指向的 Edge 和 Edge 上的属性</li>
<li>当前 Vertex 在上一步计算当中所接收到的全部 Message</li>
</ol>
<p>对于图中的每一个 Vertex，在 Pregel 当中的一次 Superstep 包括接收消息、合并消息和发送消息三个步骤。
上图当中，节点 N1 接收到了两条 Message ，加上自己原有的 Message，合并出一个最大值，
在最后它会把这个值以消息的形式发送给与之相邻的 Vertex。</p>
<p><img src="/img/pregel/pregel-vertex-status-transition.png" alt="Vertex 的状态变化"></p>
<p>前面提到 Vertex 会有状态变化，这个概念也十分简单:</p>
<ol>
<li>当一个 Vertex 在上一步当中没有接收到消息，或者算法自己决定不再向外发送消息，它可以被转变为 Inactive 的。
在 Pregel 的术语当中，这被称为 Vote to halt</li>
<li>当一个在之前已经 Inactive 的 Vertex 又接受到一条新的消息，它会在新的计算中转变为 Active 的状态</li>
</ol>
<p>在大多数算法当中，所有的 Vertex 都进入 Inactive 状态就意味着算法结束。</p>
<p>下图给出了节点之间传递消息的一个示意，此时 Pregel 还面临一个比较重要的问题：
通过网络发送大量 Message 的成本较高。</p>
<p><img src="/img/pregel/pregel-without-combiners.png" alt="通过网络传递 Message"></p>
<p>在有些情况下，我们可以在 Message 发送前先对他们进行一步聚合。比方说，
在算法中我们只关心接收到消息的最大值，那么与其把所有消息都发送到目的地再计算，
不如先将最大值求出，这样可以极大地减少需要发送的消息数量。
Pregel 允许用户自定义 Combiner 来实现这一目的。</p>
<p>下图展示了使用 Combiner 聚合左边节点发送的消息的最大值 4 ，之后再发往目标节点的过程。</p>
<p><img src="/img/pregel/pregel-with-combiners.png" alt="使用 Combiner 实现预先聚合"></p>
<p>Pregel 需要解决的另一个问题是部分图论算法无法使用上述 Vertex 状态来判断是否结束。
有些时候我们可能需要全图的所有节点共同提供一些信息，统计出一些指标来进行判断。
在另一些情况下，我们也希望对算法的进展进行衡量和追踪。因此，Pregel 还引入了 Aggregator。</p>
<p><img src="/img/pregel/pregel-aggregator.png" alt="使用 Aggregator 跟踪全局信息"></p>
<p>最后一个需要解决的问题是改变拓扑的问题。有些图算法在迭代过程中需要增删节点和边。
Pregel 并没有中心服务掌控整个图的状态，这一需求也被抽象为 Message 发送机制得以解决。</p>
<p>下图中节点 N1 向节点 N2 发送了删除 E1 的指令和向节点 N3 发送了删除节点的指令。
当 N3 被删除之后，其向外的边也都会被一并删除。</p>
<p><img src="/img/pregel/pregel-topology-mutation-requests.png" alt="通过发送特殊的消息实现图拓扑的修改"></p>
<p>为了防止接收到的拓扑修改的消息相互冲突，这些消息会按照一定的顺序被应用，
用户也可以定义函数用来进行冲突处理。</p>
<h2 id="u7CFB_u7EDF_u8BBE_u8BA1"><a href="#u7CFB_u7EDF_u8BBE_u8BA1" class="headerlink" title="系统设计"></a>系统设计</h2><p>Pregel 的计算模型不单单只有上面介绍的抽象模型而已，为了能在大规模分布式环境下执行这一算法，
Pregel 还包含系统设计上的具体考量，比较重要的四条是:</p>
<ol>
<li>将图分区到不同机器进行计算</li>
<li>使用主从模型进行任务调度和管理</li>
<li>使用 Message 缓冲近一步提高通讯吞吐量</li>
<li>使用 Checkpoint 和 Confined Recovery 实现容错性</li>
</ol>
<p><img src="/img/pregel/pregel-graph-partitions.png" alt="图分区"></p>
<p>图分区的方法十分容易理解，前文提到 Pregel 是以 Vertex 为中心的计算模型，
因此在分区的时候也是以 Vertex 为中心。
当一个节点被划分到一个区，与之相连的局部信息(边、边属性、消息)也都会被分配到这个区上。
由于对图进行分区的函数是全局一致的，各个计算节点对消息的转发并不需要通过某一中心服务进行协调。</p>
<p>默认的分区方法就是对 VertexId 的 Hash 值进行取模操作。用户也可以自定义分区函数以增强分区的局部性(Locality)，
减少计算节点之间的网络流量。</p>
<p><img src="/img/pregel/pregel-master-worker-model.png" alt="图分区"></p>
<p>Pregel 在分布式系统当中的任务调度是简单的主从模型。每个计算任务有一个 Master
进程协调所有计算，在每个 Superstep 当中，Master 会决定图分区、发送 RPC 调用到 Worker
节点激发任务以及监控任务完成。所有图分区都在 Worker 上，Master 不管理任何图分区。
不过，<strong>Pregel 的 Aggregator 运行在 Master 上</strong>。因此 Worker 需要将 Aggregator 所需信息发送到
Master 上进行聚合。</p>
<p><img src="/img/pregel/pregel-message-buffer.png" alt="Message 缓冲"></p>
<p>Message 缓冲是在计算节点(Worker)的层面上提高吞吐量的一个优化。 Message 在 Worker
之间传递时并不是来一个发一个，而是通过缓冲积攒一些 Message，之后以 Batch 的形式批量发送。
这一优化可以减少网络请求的 Overhead。</p>
<p><img src="/img/pregel/pregel-checkpoint.png" alt="Pregel 的容错方法"></p>
<p>Pregel 使用两种方法来实现容错性:</p>
<ol>
<li>Checkpoint 在 Superstep 执行前进行，用来保存当前系统的状态。当某一图分区计算失败但 Worker 仍然可用时，
可以从 Checkpoint 执行快速恢复</li>
<li>当某一 Worker 整体失败当机使得它所记录的全部状态丢失时，新启动的 Worker 可能要重新接收上一步发送出来的消息。
为了避免无限制的递归重新计算之前的步骤，Pregel 将 Worker 将要发送的每一条消息写入 Write Ahead Log。
这种方法被称为 Confined Recovery</li>
</ol>
<p>可以看到，Confined Recovery 的思想和 Spark 等基于 DAG 的计算模型有很多相似的地方。</p>
<h2 id="u7B97_u6CD5_u6848_u4F8B"><a href="#u7B97_u6CD5_u6848_u4F8B" class="headerlink" title="算法案例"></a>算法案例</h2><p>为了使大家对 Pregel 具有更加直观的认识，这一章将介绍一些抽象的算法在 Pregel 之下的运行过程。
<strong>对实战案例更感兴趣的朋友可以直接跳到下一章</strong>。</p>
<h3 id="u8BA1_u7B97_u8FDE_u901A_u5206_u91CF"><a href="#u8BA1_u7B97_u8FDE_u901A_u5206_u91CF" class="headerlink" title="计算连通分量"></a>计算连通分量</h3><p>计算连通分量的经典单机算法是<a href="https://en.wikipedia.org/wiki/Disjoint-set_data_structure" target="_blank" rel="noopener">并查集</a>，
在 Pregel 中，这一算法通过发送消息的方法实现。</p>
<p><img src="/img/pregel/pregel-connected-components.png" alt="Pregel 计算连通分量"></p>
<p>上图提供了 Pregel 计算连通分量的简单过程，其步骤是:</p>
<ol>
<li>为每个节点初始化一个唯一的 Message 值作为初始值</li>
<li>在每一个步骤当中，一个 Vertex 将其本身和接收到的 Message 聚合为它们之中的最大值(最小值)</li>
<li>如果 Attach 在某一个 Vertex 上的 Message 在上一步当中变大(变小)了，
它就会把新的值发送给所有相邻的节点，否则它会执行 Vote to halt 来 Inactivate 自己</li>
<li>算法一直执行直到所有节点都 Inactive 为止</li>
</ol>
<p>上述连通分量的算法假定边都是双向的(可以通过两条相反的边实现)。可以想像，
由于同一连通分量当中的节点都可以互相传播消息，因此最终在同一个连通分量里的 Vertex，
必定都会拥有这一连通分量内 Message 的最大值(最小值)。这个最后的值就可以作为这一连通分量的 Identifier。</p>
<p>值得注意的是，Pregel 实现的连通分量算法在超大规模的图上仍然有可扩展性的瓶颈，
Google 之后发表了论文 <a href="https://research.google.com/pubs/pub43122.html" target="_blank" rel="noopener">Connected Components in MapReduce and Beyond</a>
加以解决。</p>
<h3 id="u8BA1_u7B97_u5355_u6E90_u6700_u77ED_u8DEF"><a href="#u8BA1_u7B97_u5355_u6E90_u6700_u77ED_u8DEF" class="headerlink" title="计算单源最短路"></a>计算单源最短路</h3><p>最短路的经典单机算法包括 <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm" target="_blank" rel="noopener">Dijkstra</a>、
<a href="https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm" target="_blank" rel="noopener">Bellman-Ford</a> 等。
在图规模巨大无法被放入内存的场景下，看到 Pregel 的消息传递模型仍然适用。具体的方法是:</p>
<ol>
<li>初始化 Vertex 的 Message 为 INF (无穷大)</li>
<li>将源点的 Message 设为 0</li>
<li>每次每个节点将自己目前的 Message 加上边的权值发送到相邻节点，每个节点聚合出自身所有消息的最小值</li>
<li>当某一步当中一个节点的 Message 值没有变小，这个节点 Vote to halt</li>
<li>当所有节点都 Inactive 时，算法结束</li>
</ol>
<p><img src="/img/pregel/pregel-shortest-path-step-1.png" alt="Pregel 计算最短路: 步骤1"></p>
<p>上图展示了一个简单的图最短路的第一步计算步骤，在这一步中，N2、N3 接收到 N1 发送的消息，
从而更新了自己的消息为更小的值。执行结束后，N1 因为没有变化而 Inactive</p>
<p><img src="/img/pregel/pregel-shortest-path-step-2.png" alt="Pregel 计算最短路: 步骤2"></p>
<p>在这一步中，N2 和 N3 户想发送消息，由于 N1 -&gt; N3 -&gt; N2 的路径更短，N3 的 Message 被更新，
N2 则变为 Inactive。</p>
<p><img src="/img/pregel/pregel-shortest-path-step-3.png" alt="Pregel 计算最短路: 步骤3"></p>
<p>尽管这时所有的最短距离已经求出，由于 N2 在上一步仍然是 Active 的状态，它将会向 N3 发送最后一次消息。
由于 N3 没有更新自己的值，此时图中三个节点都变味 Inactive，算法结束。</p>
<h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><p><a href="https://en.wikipedia.org/wiki/Pagerank" target="_blank" rel="noopener">PageRank</a> 可能是 Pregel 最典型的应用案例。
因为它本身的原理就是通过不断将自身的权值以消息的形式发送出去而完成计算的。</p>
<p>这里拿 PageRank 作为典型案例的原因在于: PageRank 不能简单的以 Vertex 的状态作为算法终止的条件。
除了设定固定的迭代次数之外，另一个方法就是利用 Pregel 的 Aggregator 来跟踪计算过程。</p>
<p>关于 PageRank 的消息传递方法这里不再赘述，下图给出了在一个简单的图上进行计算过程的前半部分:</p>
<p><img src="/img/pregel/pregel-pagerank.png" alt="PageRank：前半部分"></p>
<p>在上图中，N1 不断地将权值发送给自己和 N2，而 N2 则只会发给自己。
随着逐步的迭代，N1 的权值越来越小，N2 的权值越来越大。我们用 Aggregator
跟踪每个节点上权值变化绝对值的最大值 delta，这个最大值会随着迭代的进程而越变越小。</p>
<p>如果我们设定 delta 小于 0.05 时算法结束，则我们将在接下来的步骤中看到如下过程:</p>
<p><img src="/img/pregel/pregel-pagerank-terminate.png" alt="PageRank：后半部分"></p>
<p>在最后 Aggregator 得到 delta 满足终止条件之后，Master 就可以觉得结束算法了。</p>
<h2 id="u5B9E_u6218_u6848_u4F8B_3A__u7528_u6237_u8FFD_u8E2A_u753B_u50CF"><a href="#u5B9E_u6218_u6848_u4F8B_3A__u7528_u6237_u8FFD_u8E2A_u753B_u50CF" class="headerlink" title="实战案例: 用户追踪画像"></a>实战案例: 用户追踪画像</h2><p>Pregel 算法的普适性非常强，几乎可以应用各类经典图论算法，
然而我们实际使用它时，主要看中的是它可以解决规模超大的图计算问题。
在这一章我们研究一个实战案例以说明其应用价值。</p>
<p><img src="/img/pregel/pregel-user-tracking-problem.png" alt="用户追踪画像问题"></p>
<p>上图是我们实战案例的问题描述，具体来说：</p>
<ol>
<li>我们的网站可以收集到各个用户一系列离散的访问请求</li>
<li>这些请求可以被以 Session 形式组织起来</li>
<li>在一个 Session 的请求当中，我们可能收集到用户各种信息的一个子集</li>
<li>我们希望通过一个用户的多个 Session，尽可能聚合到这个用户完整的信息</li>
</ol>
<p>上面的第三条是我们达成目标的最大阻碍，其原因在于，为了最好的用户体验，
我们不希望在一开始就强迫用户登录或提供定位权限以获得他的全部信息。
设想有一个用户，平时一直匿名访问我们的网站，当有一天他终于认为我们的网站很有价值，
决定注册登陆我们的网站，这时一个典型的需求就是将其之前匿名的访问记录和之后登录的用户联系起来，
从而获得更加有用的信息。</p>
<p>用户追踪画像的基本过程可以分为多个步骤，下图展示了对相互穿插的离散的用户信息的初步处理。</p>
<p><img src="/img/pregel/pregel-user-tracking-sessionize.png" alt="用户离散访问信息的初步处理"></p>
<p>这一出步处理的主要目的是将离散的请求组织成 Session 的形式并提取出特征。
在这一步之后，我们可以得到很多相互独立的 Session，但是我们仍然不知道哪些 Session
是属于同一个用户的。但是依靠每个 Session 之中提取出来的特征，发现 Session 之间相互的关系是可能的。
如果我们将 Session 作为图的节点，将相互匹配的 Session 用边连接起来，
就可以把用户追踪画像的问题转换为寻找无向图连通分量的问题。</p>
<p><img src="/img/pregel/pregel-user-tracking-feature-extraction.png" alt="通过计算无向图连通分量聚合用户信息"></p>
<p>通过联系和聚合多个 Session 包含的特征，我们得到了比仅着眼单个 Session 更全面的用户信息，
这样用户追踪和画像的问题就解决了。由于网站的用户访问可能是海量的，
这一问题可能必须交由大规模分布式系统进行计算，这即是 Pregel 的用武之处。</p>
<p>在这里有一点扩展优化。设想我们有 $O(N)$ 个 Session，要找出它们两两之间的关系，
需要耗费的是 $O(N^2)$ 的时间，这对于仅有 $10^6$ 个 Session 的规模都是相当不可行的。
我所想到的一种优化是：</p>
<ol>
<li>只选择 $n$ 个重要的特征作为参考</li>
<li>定义两个 Session 是匹配的，当有大于等于 $x$ 个特征相匹配</li>
<li>对于收集到的一个 Session 的特征，枚举它恰好 $x$ 个特征的子集合</li>
<li>匹配这些包含恰好 $x$ 个特征的子集合，而不是 Session 本身</li>
</ol>
<p>下图展示了这个过程:</p>
<p><img src="/img/pregel/pregel-user-feature-match.png" alt="枚举固定数量特征子集合进行匹配"></p>
<p>假设 $n=5$ 且 $x=2$，也就是说对于任意两个 Session，我们只考虑它们所拥有的 5 个固定的特征，
当等于或大于 2 个特征匹配，我们就认为两个 Session 匹配。如果我们有 $O(N)$ 个 Session，
因 $\mathtt{C}^2_5=10$ 那么我们将会得到 $O(10\times N)$ 个这样的子集合。</p>
<p>这么做难道不是使得问题的规模上升了么？为什么我们可以算的更快呢？
这是因为这些子集合都恰好包含两个元素，假如我们对这些子集合进行排序，
相同的子集合一定排在一起，这样我们就可以通过在排好序的序列当中，
链接相邻相同子集合所代表的 Session，快速将所有匹配的 Session 连接起来。</p>
<p>对 $O(10\times N)$ 个元素进行排序，将会花费 $O(10\times N\cdot\log (10\times N))$，
最后处理整个序列还需要 $(10\times N)$ 的时间。但是总体的时间复杂度却降低到了 $O(N\log N)$
的级别，对于 $O(N^2)$ 来说是一个巨大的进步。</p>
<p>换句话说，我们利用类似在终端中使用 <code>sort | uniq</code> 的方式，降低了寻找 Session 匹配的复杂度。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文简要介绍了 Pregel 的基本模型和系统设计，给出了一些简单算法案例的执行过程。
在最后使用用户追踪画像这样的实战案例，说明了图计算在现实世界当中的具体应用。</p>
<p>着我们需要处理的问题规模越来越大，像 Pregel 
这样的分布式计算模型的应用价值也会越来越高，甚至有可能会逐渐超过传统的算法。</p>
<p>然而，在实战案例的扩展优化当中可以看到，那些传统和经典的算法技巧，
在大规模分布式数据处理当中仍然可以发挥启发性的作用。我认为，无论统治未来是 AI 还是区块链，
这些基础的算法技能都是非常重要的。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>这篇文章是对之前在 <a href="https://www.shlug.org/monthly/2018/03/17/monthly-photo.html" target="_blank" rel="noopener">SHLUG</a>
月度分享活动上所作演讲 <a href="https://www.slideshare.net/ChaseZhang3/pregel-in-graphs-models-and-instances" target="_blank" rel="noopener">Pregel in Graphs</a>
的总结。为使分享内容清晰易懂，本人绘制了大量原创示意图，这篇文字版的总结也会尽量以这些图示为主。
除了对 Pregel 算法的简单介绍，本文还附加了一个用户追踪画像的实战案例，用以证明图计算模型的重要意义。</p>]]>
    
    </summary>
    
      <category term="Distributed System" scheme="https://io-meter.com/tags/Distributed-System/"/>
    
      <category term="Algorithm" scheme="https://io-meter.com/tags/Algorithm/"/>
    
      <category term="Pregel" scheme="https://io-meter.com/tags/Pregel/"/>
    
      <category term="Google" scheme="https://io-meter.com/tags/Google/"/>
    
      <category term="Graph Computing" scheme="https://io-meter.com/tags/Graph-Computing/"/>
    
      <category term="PageRank" scheme="https://io-meter.com/tags/PageRank/"/>
    
      <category term="Connected Components" scheme="https://io-meter.com/tags/Connected-Components/"/>
    
      <category term="User Tracking" scheme="https://io-meter.com/tags/User-Tracking/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[集群资源调度系统设计架构总结]]></title>
    <link href="https://io-meter.com/2018/02/09/A-summary-of-designing-schedulers/"/>
    <id>https://io-meter.com/2018/02/09/A-summary-of-designing-schedulers/</id>
    <published>2018-02-09T07:45:35.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>之前为完成《<a href="/2017/10/13/kylin-aws-scheduler-system/">AWS 下 Kylin 调度系统的设计</a>》，阅读了大量
集群资源管理和任务调度的资料和论文。了解了如
<a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" target="_blank" rel="noopener">Hadoop YARN</a>、
<a href="http://mesos.apache.org/" target="_blank" rel="noopener">Mesos</a>、
<a href="https://github.com/amplab/drizzle-spark" target="_blank" rel="noopener">Spark Drizzle</a>、
<a href="https://research.google.com/pubs/pub43438.html" target="_blank" rel="noopener">Borg/Kubernetes</a> 和
<a href="https://research.google.com/pubs/pub41684.html" target="_blank" rel="noopener">Omega</a>
等系统的调度器设计架构，在这篇文章里我将试图从这些架构案例中总结出此类系统一般的设计模式。</p>
<a id="more"></a>
<h2 id="u8C03_u5EA6_u5668_u7684_u5B9A_u4E49"><a href="#u8C03_u5EA6_u5668_u7684_u5B9A_u4E49" class="headerlink" title="调度器的定义"></a>调度器的定义</h2><p>无论是在单机系统还是分布式系统当中，调度器其实都是非常核心和普遍的组件，其内涵也比较宽广和模糊。</p>
<p>一般来说，下面提到的几种类型的模块都可以认为是调度器：</p>
<ol>
<li>早期计算机系统当中的批处理调度系统</li>
<li>现代计算机系统当中的抢占式进程调度系统和内存分配系统</li>
<li>某些系统或程序提供或实现的，定时激发某些类型操作的工具(如 crontab、<a href="http://www.quartz-scheduler.org/" target="_blank" rel="noopener">Quartz</a> 等)</li>
<li>某些编程语言的 Runtime 提供的线程/纤程/协程调度器(如 Golang 内置的 Goroutine 调度器)</li>
<li>分布式系统当中的任务关系管理和调度执行系统，(如 Hadoop YARN, <a href="https://airflow.apache.org/" target="_blank" rel="noopener">Airflow</a> 等)</li>
<li>分布式系统当中的资源管理和调度系统(如 Mesos、Borg、Kubernetes 的调度器等)</li>
</ol>
<p>可以被称为调度器的工具涵盖的范围非常广，他们有的提供定时激发任务的能力，有的提供资源管理的能力，
有的负责维护任务的依赖关系和执行顺序。甚至有的系统还集成了任务监控和各种指标度量的工具。</p>
<p>这篇文章主要涉及的是管理系统资源和调度任务执行相关方面的架构和模型，
具体的资源分配策略和任务调度策略不在我们讨论的范围内。</p>
<h2 id="u8C03_u5EA6_u5668_u8BBE_u8BA1_u6982_u8FF0"><a href="#u8C03_u5EA6_u5668_u8BBE_u8BA1_u6982_u8FF0" class="headerlink" title="调度器设计概述"></a>调度器设计概述</h2><p>在系统设计领域研究比较多的朋友可以容易地得出一个结论，那就是我们的系统设计——无论是小到一个嵌入式的系统，
还是大到好几百个机器的集群，在设计抽象上都是在不同的层次上重复自己。比如说，如果我们着眼于一个 CPU，
他包括计算单元和一系列的用来加速数据访问的缓存 L1、L2、L3 等，每种缓存具有不同的访问速度。
当我们的视野扩大到整个机器，CPU 又可以被当成一个单元，我们又有内存和硬盘两个层次的储存系统用于加速数据载入。
而在分布式系统中，如果我们把 HDFS 或 S3 看作硬盘，也存在像 <a href="https://www.alluxio.org/" target="_blank" rel="noopener">Alluxio</a> 
这样发挥着类似内存作用的系统。</p>
<p>既然系统在设计上的基本原则都是类似的，那为什么大规模分布式系统的设计这么困难呢？
这是因为当问题的规模变化了，原先不显著或者容易解决的问题可能会变的难以解决。举例来说，
当我们谈论起进程间通信或者同一个 CPU 不同内核之间的通信时，我们往往不考虑通讯不稳定所带来的问题:
我们无法想象如果一个 CPU 内核无法发送消息到另一个内核的状况。
然而在通过网络通讯的多机机群当中这是无法回避的问题，Paxos、Raft、Zab 等算法被设计出来的原因也在于此。</p>
<p>我们先看一看单机操作系统调度器的发展路线:</p>
<ol>
<li>最早的调度器是批处理调度器，这种调度器批量调度和执行任务，通过对计算机资源的分时复用来增加资源的利用率。
一般具有较高的吞吐量</li>
<li>某些与外界交互次数频繁的系统对响应时间具有较强的要求，因此发展出了实时操作系统。
实时操作系统的调度器具备低延迟相应外部信号的能力</li>
<li>我们常用的操作系统基本上以批处理的方式调度任务，又通过<strong>中断</strong>等机制提供实时性的保证，
通过提供灵活的调度策略，在吞吐量和延迟时间当中获得平衡</li>
</ol>
<p>在分布式系统中的调度器的设计也是相同的。从单机调度器这里我们首先可以总结出调度器设计的三个最基本的需求:</p>
<ol>
<li>资源的有效利用</li>
<li>信号的实时响应</li>
<li>调度策略的灵活配置</li>
</ol>
<p>这三个需求在某种程度上来说是相互矛盾的，在面对不同需求的时候需要做出不一样的取舍。</p>
<p>在上述三个需求的基础上，分布式的调度器设计还需要克服很多其他的困难。这些困难往往在单机系统当中并不显著。
比如说：</p>
<ol>
<li>状态的同步问题。在单机系统中，我们一般使用常规的同步方法，如共享内存和锁机制，就可以很好地保证任务的协调运行了。
这是因为在单机系统上的状态同步比较稳定和容易。然而在分布式系统中，因为网络通讯的不确定性，
使机群中的各个机器对于周围的状态达成一致是非常困难的任务。实际上，在分布式系统中甚至无法通过网络精确同步所有机器的时间！</li>
<li>容错性问题。由于单机系统的处理能力有限，我们运行任务的规模和同时运行任务的数量都比较有限。
出错的概率和成本都比较低。但是在分布式系统中，由于任务规模变大、任务依赖关系变得更加复杂，
出错的概率大大增加，错误恢复的成本可能也比较高，因此可能需要调度器快速地识别错误并进行恢复操作。</li>
<li>可扩展性的问题。当分布式系统的规模到达一定程度，调度器的可扩展性就可能会成为瓶颈。为了提供高可扩展性，
调度器不但要可以应对管理上千台机器的挑战，也要能够处理动态增减节点这样的问题。</li>
</ol>
<p>现阶段比较流行的分布式调度器可以归纳为三种类型，在接下来的文章里将会结合具体的案例进行介绍。</p>
<h2 id="u96C6_u4E2D_u5F0F_u8C03_u5EA6_u5668"><a href="#u96C6_u4E2D_u5F0F_u8C03_u5EA6_u5668" class="headerlink" title="集中式调度器"></a>集中式调度器</h2><p>集中式(Centralized)调度器也可以被称为宏(Monolithic)调度器。指的是使用中心化的方式管理资源和调度任务。
也就是说，调度器本身在系统中只存在单个实例，所有的资源请求和任务调度都通过这一个实例进行。
下图展示了集中式调度器的一般模型。可以看到，在这一模型中，资源的使用状态和任务的执行状态都由中央调度器管理。</p>
<p><img src="/img/scheduler/centralized-scheduler.png" alt="Centralized Scheduler"></p>
<p>按照上面的思路，可以列出集中式调度器在各个方面的表现状况:</p>
<ol>
<li>适合批处理任务和吞吐量较大、运行时间较长的任务</li>
<li>调度算法只能全部内置在核心调度器当中，灵活性和策略的可扩展性不高</li>
<li>状态同步比较容易且稳定，这是因为资源使用和任务执行的状态被统一管理，降低了状态同步和并发控制的难度</li>
<li>由于存在单点故障的可能性，集中式调度器的容错性一般，有些系统通过热备份 Master 的方式提高可用性</li>
<li>由于所有的资源和任务请求都要由中央调度器处理，集中式调度器的可扩展性较差，容易成为分布式系统吞吐量的瓶颈</li>
</ol>
<p>尽管应用场合比较局限，集中式调度器仍然是普遍使用的调度器，可以被广泛应用于中小规模的数据平台应用。</p>
<h3 id="u96C6_u4E2D_u5F0F_u8C03_u5EA6_u5668_u6848_u4F8B1_3A__u5355_u673A_u64CD_u4F5C_u7CFB_u7EDF_u7684_u8C03_u5EA6_u5668"><a href="#u96C6_u4E2D_u5F0F_u8C03_u5EA6_u5668_u6848_u4F8B1_3A__u5355_u673A_u64CD_u4F5C_u7CFB_u7EDF_u7684_u8C03_u5EA6_u5668" class="headerlink" title="集中式调度器案例1: 单机操作系统的调度器"></a>集中式调度器案例1: 单机操作系统的调度器</h3><p>单机操作系统，如 Windows、Linux 和 macOS 的进程调度器是典型的集中式调度器。
当用户请求执行应用之后，由操作系统将进程载入内存。计算机硬件的所有资源，包括 CPU、内存和硬盘等都由操作系统集中式管理。
当进程需要时，通过系统调用请求操作系统分配资源。如果单机环境中的进程使用了系统级多线程，
这些线程的调度也由系统一并控制。</p>
<h3 id="u96C6_u4E2D_u5F0F_u8C03_u5EA6_u5668_u6848_u4F8B2_3A_Hadoop_YARN"><a href="#u96C6_u4E2D_u5F0F_u8C03_u5EA6_u5668_u6848_u4F8B2_3A_Hadoop_YARN" class="headerlink" title="集中式调度器案例2: Hadoop YARN"></a>集中式调度器案例2: Hadoop YARN</h3><p>对于集中式调度器，我们重点介绍 Hadoop YARN 这个案例。下图是将集中式调度器的一般模型替换成 YARN 当中术语之后的示意图:</p>
<p><img src="/img/scheduler/hadoop-yarn-scheduler.png" alt="Hadoop YARN"></p>
<p>Hadoop YARN 的特点可以总结为:</p>
<ol>
<li>集中式的资源管理和调度器被称为 ResourceManager，所有的资源的空闲和使用情况都由 ResourceManager 管理，
ResourceManager 也负责监控任务的执行</li>
<li>集群中的每个节点都运行着一个 NodeManager，这个 NodeManager 管理本地的资源占用和任务执行并将这些状态同步给
ResourceManager</li>
<li>集群中的任务运行在 Container 当中，YARN 使用 Container 作为资源分配的抽象单位，每个 Container
会被分配一些本地资源和运算资源等</li>
</ol>
<p>熟悉 YARN 的朋友可能知道 YARN 存在一个 ApplicationMaster 的概念，当一个应用被启动之后，
一个 ApplicationMaster 会先在集群中被启动，随后 ApplicationMaster 会向 ResourceMaster 
申请新的资源并调度新的任务。这一模型好像看起来和后面介绍的双层调度器特别是 Mesos 的设计有点相似，
但一般仍认为 YARN 是 Monolithic 设计的调度器。这主要是因为:</p>
<ol>
<li>ApplicationMaster 其实也是运行在一个 Container 里的 YARN job</li>
<li>ApplicationMaster 虽然决定 Job 如何被激发，但是仍然需要请求 ResourceMaster 申请资源和启动新的 Job</li>
<li>ApplicationMaster 启动的 Job 也会由 ResourceMaster 进行监控，其启动所需的本地资源和运算资源都由
ResourceMaster 负责分配并通知 NodeManager 具体执行</li>
</ol>
<p>在 YARN 中，为了防止 ResourceManager 出错退出，可以设计多个 Stand-By Master，
Stand-By Master 一直处于运行状态并和 ResourceManager 注册在同一个 ZooKeeper 集群中。</p>
<p>Active 的 ResourceManager 会定期保存自己的状态到 ZooKeeper，当其失败退出后，
一个 Stand-By Master 会被选举出来成为新的 Manager。</p>
<p><img src="/img/scheduler/yarn-standby-master.png" alt="Hadoop YARN: High Availability"></p>
<p>作为一个分布式资源管理和调度器， YARN 与其竞争对手相比功能其实比较薄弱。
譬如默认情况下 YARN 只能对 Memory 资源施加限制(如果一个 Job 使用了超过许可的 Memory，
YARN 会直接杀死进程)。尽管其调度接口提供了对 CPU Cores 的抽象，
但 YARN 默认情况下对任务使用 CPU 核数并没有任何限制。</p>
<p>不过若运行在 Linux 环境下， 在较新版本的 YARN 中可以配置 cgroup 限制资源使用。</p>
<h2 id="u53CC_u5C42_u8C03_u5EA6_u5668"><a href="#u53CC_u5C42_u8C03_u5EA6_u5668" class="headerlink" title="双层调度器"></a>双层调度器</h2><p>前面提到，集中式调度器的主要缺点在于单点模型容错性和可扩展性较差，容易成为性能瓶颈。在一般的数据密集型应用当中，
解决这一问题的主要方法是分区。下图是双层调度器的一般模型:</p>
<p><img src="/img/scheduler/two-level-scheduler.png" alt="2-level Scheduler"></p>
<p>在双层调度器当中，资源的使用状态同时由分区调度器和中央调度器管理，但是中央调度器一般只负责宏观的大规模的资源分配，
因此业务压力较小。分区调度器负责管理自己分区的所有资源和任务，一般只有当所在分区资源无法满足需求时，
才将任务冒泡到中央调度器处理。</p>
<p>相比集中式调度器，双层调度器某一分区内的资源分配和工作安排可以由具体的任务本身进行定制，
因此大大增强了使用的灵活性，可以同时对高吞吐和低延迟的两种场景提供良好的支持。每个分区可以独立运行，
降低了单点故障导致系统崩溃的概率，增加了可用性和可扩展性。但是反过来也导致状态同步和维护变得比较困难。</p>
<p>尽管主要思路是一致的，但双层调度器在实现上的变种比较丰富，本文接下来使用案例进行介绍。</p>
<h3 id="u53CC_u5C42_u8C03_u5EA6_u5668_u6848_u4F8B1_3A__u534F_u7A0B_u8C03_u5EA6_u5668"><a href="#u53CC_u5C42_u8C03_u5EA6_u5668_u6848_u4F8B1_3A__u534F_u7A0B_u8C03_u5EA6_u5668" class="headerlink" title="双层调度器案例1: 协程调度器"></a>双层调度器案例1: 协程调度器</h3><p>单机操作系统的单个进程为了避免系统级多线程上下文切换的成本，可以自行实现进程内的调度器，如 Golang 运行时的 Goroutine
调度器。在这一模型下，一个进程内部的资源就相当于一个分区，分区内的资源由运行时提供的调度器预先申请并自行管理。
运行时环境只有当资源耗尽时才会向系统请求新的资源，从而避免频繁的系统调用。</p>
<p>提出这个例子的主要目的在于说明类似的优化思路其实也被应用于分布式系统，再次证明了系统设计<strong>分层重复的特点</strong>！</p>
<h3 id="u53CC_u5C42_u8C03_u5EA6_u5668_u6848_u4F8B2_3A_Mesos"><a href="#u53CC_u5C42_u8C03_u5EA6_u5668_u6848_u4F8B2_3A_Mesos" class="headerlink" title="双层调度器案例2: Mesos"></a>双层调度器案例2: Mesos</h3><p>Mesos 是和 YARN 几乎同一时间发展起来的任务和资源调度系统。这一调度系统实现了完整的资源调度功能，
并使用 Linux Container 技术对资源的使用进行限制。和 YARN 一样，Mesos 系统也包括一个独立的 Mesos Master
和运行在每个节点上的 Mesos Agent，而后者会管理节点上的资源和任务并将状态同步给 Master。
在 Mesos 里，任务运行在 Executor 里。下图是 Mesos 的主要架构</p>
<p><img src="/img/scheduler/mesos-scheduler.png" alt="Mesos Scheduler"></p>
<p>值得注意的是，Mesos 分区的单位并不是单个节点，是可以将一个节点当中的资源划分到多个区的。
也就是说，在 Mesos 里，分区是逻辑的和动态的。</p>
<p>把 Mesos 看作一种双层的资源调度系统设计主要基于以下几点：</p>
<ol>
<li>与一般通过 Master 请求资源不同，Mesos 提出了 Framework 的概念，每个 Framework 相当于一个独立的调度器，
可以实现自己的调度策略</li>
<li>Master 掌握对整个集群资源的的状态，通过 Offer (而不是被动请求) 的方式通知每个 Framework 可用的资源有哪些</li>
<li>Framework 根据自己的需求决定要不要占有 Master Offer 的资源，如果占有了资源，这些资源接下来将完全由 Framework 管理</li>
<li>Framework 通过灵活分配自己占有的资源调度任务并执行，并不需要通过 Master 完成这一任务</li>
</ol>
<p>同样，Mesos 也可以通过 Stand-By Master 的方法提供 Master 节点的高可用性。
Mesos 已经被广泛应用于各类集群的管理，但是其 Offer-Accept 的资源申请可能不是特别容易理解。
对于想要自行编写调度策略的人，Frameworks 的抽象比较并不容易掌握。由于 Framework 要先占有了资源才能使用，
设计不够良好的 Framework 可能会导致资源浪费和资源竞争/死锁。</p>
<h3 id="u53CC_u5C42_u8C03_u5EA6_u5668_u6848_u4F8B3_3A_Spark__u548C_Spark_Drizzle"><a href="#u53CC_u5C42_u8C03_u5EA6_u5668_u6848_u4F8B3_3A_Spark__u548C_Spark_Drizzle" class="headerlink" title="双层调度器案例3: Spark 和 Spark Drizzle"></a>双层调度器案例3: Spark 和 Spark Drizzle</h3><p>Spark 为了调度和执行自己基于 DAG 模型的计算，自己实现了一个集中式的调度器，
这个调度器的 Master 被称为 Driver，当 Driver 运行起来的之后，会向上层的 Scheduler
申请资源调度起 Executor 进程。Executor 将会一直保持待机，等候 Driver 分配任务并执行，直到任务结束为止。</p>
<p><img src="/img/scheduler/spark-classic-scheduler.png" alt="Spark 传统的调度模型"></p>
<p>Spark 和 YARN 这样的集中式调度器放在一起可以认为是通过迂回的方式实现了双层调度器。
就好像单机进程自己实现协程调度器一样，Spark Driver 预先申请的资源可以认为是在申请分区资源，
申请到的资源将由 Driver 自行管理和使用。</p>
<p>有趣的是，在 2017 年的 SOSP 上，Spark 为了解决流处理计算当中调度延迟较大的问题，
提出了一种新的调度模型 Drizzle，在原来调度模型的基础上，又再次实现了双层调度。
下图是 Spark Drizzle 的设计模型</p>
<p><img src="/img/scheduler/spark-drizzle-scheduler.png" alt="Spark Drizzle 的调度模型"></p>
<p>Drizzle 使得调度 Spark Streaming 任务的延迟由最低 500ms 降低到 200ms 左右，让 Spark Streaming
在低延迟处理的问题上获得了突破性的进展。要搞清楚 Drizzle 提出的目的和解决的问题，
首先要理解以下几点:</p>
<ol>
<li>Spark Streaming 的实现方式实际上是 Micro Batch，也就是说流式输入的数据在这里仍然被切分成一个一个 Batch 进行处理</li>
<li>传统的 Spark 调度器会在前序任务完成之后，根据之前任务输出的规模和分布，通过一定的算法有策略地调度新的任务，
以便于获得更好的处理速度和降低资源浪费</li>
<li>在这一过程中，Exector 需要在前续任务完成后通知 Scheduler，之后由 Scheduler 调度新的任务。
在传统 Batch 处理模式下，这种模型效果很好，但是在 Streaming 的场景下存在很多问题</li>
<li>在 Streaming 场景下，每个 Batch 的数据量较小，因此任务可能会需要频繁与 Scheduler 交互，
因为存在这一交互过程的 Overhead，Streaming 处理的过程中最低的延迟也要 500ms 以上</li>
</ol>
<p>为了得到更低的延迟性且保留 Micro Batch 容错性强且<strong>易于执行 Checkpoint</strong> 的优点，Drizzle 在原来的模型上做了一些优化:</p>
<ol>
<li>在每个节点运行一个 LocalScheduler</li>
<li>中央调度器 Driver 在执行 Streaming 处理任务时，根据计算的 DAG 图模型，预先调度某一个
Job 的后序 Job，后序 Job 会被放置在 LocalScheduler 上</li>
<li>后序 Job 默认在 LocalScheduler 上是沉睡状态，但是前面的 Job 可以知道后序 Job 在哪个节点上，
因此当前面的任务完成后，可以直接激活后序任务</li>
<li>当后序任务被激活之后，前序任务和后序任务可以直接通过网络请求串流结果</li>
</ol>
<p>可以看到 Drizzle 的主要思路就是根据用户程序生成的图模型，预先 Schedule 一些任务，
使得前序任务知道后序任务的位置，在调度时避免再请求中央调度器 Driver。
同时 Drizzle 也采取了其他一些方法，比如将多个 Micro Batch 打包在一起，借由 LocalScheduler 
自行本地调度等等方式减少延迟。</p>
<p>Drizzle 模型可以说是双层模型的又一种另类体现。然而这种模型主要的缺点是必须要预先知道计算任务的图模型和依赖关系，
否则就无法发挥作用。</p>
<h2 id="u5171_u4EAB_u72B6_u6001_u8C03_u5EA6_u5668"><a href="#u5171_u4EAB_u72B6_u6001_u8C03_u5EA6_u5668" class="headerlink" title="共享状态调度器"></a>共享状态调度器</h2><p>通过前面两种模型的介绍，可以发现集群中需要管理的状态主要包括以下两种:</p>
<ol>
<li>系统中资源分配和使用的状态</li>
<li>系统中任务调度和执行的状态</li>
</ol>
<p>在集中式调度器里，这两个状态都由中心调度器管理，并且一并集成了调度等功能。
双层调度器模式里，这两个状态分别由中央调度器和次级调度器管理。
集中式调度器可以容易地保证全局状态的一致性但是可扩展性不够，
双层调度器对共享状态的管理较难达到好的一致性保证，也不容易检测资源竞争和死锁。</p>
<p>为了解决这些问题，一种新的调度器架构被设计出来。
这种架构基本上沿袭了集中式调度器的模式，通过将中央调度器肢解为多个服务以提供更好的伸缩性。
这种调度器的核心是共享的集群状态，因此可以被称为<strong>共享状态调度器</strong>。</p>
<p><img src="/img/scheduler/shared-state-scheduler.png" alt="共享状态调度器"></p>
<p>共享状态调度架构为了提供高可用性和可扩展性，将除共享状态之外的功能剥离出来成为独立的服务。
这种设计可以类比为单机操作系统的微内核设计。在这种设计中，内核只负责提供最核心的资源管理接口，
其他的内核功能都被实现为独立的服务，通过调用内核提供的 API 完成工作。</p>
<p>共享状态调度器的设计近些年来越来越受欢迎，这两年炙手可热的 Kubernetes 和它的原型 Borg
都是采用这种架构。最近由加州大学伯克利分校知名实验室 RISELab 提出的号称要取代 Spark 分布式计算系统 Ray
也是如此。下面将对这些案例进行介绍。</p>
<h3 id="u5171_u4EAB_u72B6_u6001_u8C03_u5EA6_u5668_u6848_u4F8B1_3A_Borg/Kubernetes"><a href="#u5171_u4EAB_u72B6_u6001_u8C03_u5EA6_u5668_u6848_u4F8B1_3A_Borg/Kubernetes" class="headerlink" title="共享状态调度器案例1: Borg/Kubernetes"></a>共享状态调度器案例1: Borg/Kubernetes</h3><p>根据相关论文，Borg 在初期开发的时候使用的是集中式调度器的设计，所有功能都被集中在 BorgMaster
当中，之后随着对灵活性和可扩展性的要求，逐步切换到共享状态模型或者说微内核模型上面去。
Google 的工程师们总结了 Borg 的经验教训，将这些概念集合在 Kubernetes 当中开源出来，
成为了近些年来最炙手可热的资源管理框架。</p>
<p>在这里我们依然以 Borg 为例进行介绍，Kubernetes 在具体的设计上是与 Borg 基本一致的。
下图是 Borg 设计架构示意图:</p>
<p><img src="/img/scheduler/borg-scheduler.png" alt="Borg 资源调度架构"></p>
<p>Borg 资源调度架构的设计可以总结为以下几点:</p>
<ol>
<li>一个数据中心的集群可以被组织成一个 Borg 当中的 Cell</li>
<li>在一个 Borg 的 Cell 当中，资源的管理类似于集中式调度器的设计——集群资源由 BorgMaster 统一管理，
每一个节点上运行着 Borglet 定时将本机器的状态与 BorgMaster 同步</li>
<li>为了增加可用性，BorgMaster 使用了 Stand-By Master 的模式。也就是说同时运行着 BorgMaster 的多个热备份，
当 Active 的 BorgMaster 出现失败，新的 Master 会被选取出来</li>
<li>为了增加可扩展性和灵活性，BorgMaster 的大部分功能被剥离出来成为独立的服务。最终，BorgMaster
只剩下维护集群资源和任务状态这唯一一个功能，包括 Scheduler 在内的所有其他服务都独立运行</li>
<li>独立运行的每个 Scheduler 可以运行自己的调度策略，它们定时从 BorgMaster 同步集群资源状态，
根据自己的需要做出修改，然后通过 API 同步回 BorgMaster，从而实现调度功能</li>
</ol>
<p>可以看到，Borg 的共享状态调度架构其实是集中式调度的改进，由于承载调度逻辑的调度器都运行在独立的服务里，
对于 BorgMaster 的请求压力得到了某种程度的缓解。使用微内核设计模式，BorgMaster 自己包含的逻辑就比较简单了，
系统的鲁棒性、灵活性和可扩展性得到了增强。</p>
<p>在 Borg 中，任务的隔离和资源限制使用了 Linux 的 cgroup 机制。在 Kubernetes 当中，这一机制被 Container 技术替代，
实际上的功能是等价的。</p>
<p>Borg 的共享状态设计看似简单，其实具体实现仍然比较复杂。事实上，集中式的状态管理仍然会成为瓶颈。
随着集群规模的扩展和状态的规模扩大，State Storage 必须使用分布式数据储存机制来保证可用性和低延迟。</p>
<p>共享状态架构的设计和双层设计的最大区别是，
共享状态被抽取出来由一个统一的组件管理。从其他的各种服务的角度来看，
共享状态提供的调用接口和集中式调度的状态管理是一样的。
这种设计通过封装内部细节的方式降低了外部服务编写的复杂度，体现了系统设计里<strong>封装复杂模块</strong>的思想。</p>
<h3 id="u5171_u4EAB_u72B6_u6001_u8C03_u5EA6_u5668_u6848_u4F8B2_3A_Omega"><a href="#u5171_u4EAB_u72B6_u6001_u8C03_u5EA6_u5668_u6848_u4F8B2_3A_Omega" class="headerlink" title="共享状态调度器案例2: Omega"></a>共享状态调度器案例2: Omega</h3><p>上面介绍的 Borg 是共享状态最典型的一个示例。尽管 BorgMaster 已经为其他服务的编程提供了简单的接口，
但是仍然没有降低状态一致性同步的难度——BorgMaster 和服务的编写着仍然需要考虑很多并发控制的方法，
防止对共享状态的修改出现 Race Condition 或死锁的现象。如何为其他服务和调度策略提供一层简单的抽象，
使得任务的调度能兼顾吞吐量、延迟和并发安全呢？</p>
<p><strong>Omega 使用事务(Transaction)解决共享状态一致性管理的问题</strong>。这一思路非常直观——如果将数据库储存的数据看作共享状态，
那么数据库就是是共享状态管理的最成熟、最通用的解决方案！事务更是早已被开发者们熟悉而且证明非常成熟和好用的并发抽象。</p>
<p><img src="/img/scheduler/transaction-scheduler.png" alt="事务调度策略"></p>
<p>Omega 将集群中资源的使用和任务的调度看作数据库中的条目，在一个应用执行的过程当中，
调度器可以分步请求多种资源，当所有资源依次被占用并使任务执行完成，这个 Transaction 就会被成功 Commit。</p>
<p>Omega 的设计借鉴了很多数据库设计的思路，比如:</p>
<ol>
<li>Transaction 设计保留了一般事务的诸多特性，如嵌套 Transaction 或者 Checkpoint。
当资源无法获取或任务执行失败，事务将会被回滚到上一个 Checkpoint 那里</li>
<li>Omega 可以实现传统数据库的死锁检测机制，如果检测到死锁，可以安全地撤销一个任务或其中的一些步骤</li>
<li>Omega 使用了乐观锁，也就是说申请的资源<strong>不会立刻被加上排他锁</strong>，只有需要真正分配资源或进行事务提交的时候才会检查锁的状态，
如果发现出现了 Race Condition 或其他错误，相关事务可以被回滚</li>
<li>Omega 可以像主流数据库一样定义 Procedure ，这些 Procedure 可以实现一些简单的逻辑，
用于对用户的资源请求进行合法性的验证(如优先级保证、一致性校验、资源请求权限管理等)</li>
</ol>
<p>Omega 使用事务管理状态的想法非常新颖，这一设计随着分布式数据库以及分布式事务的逐渐发展和成熟而逐渐变得可行，
它一度被认为将成为 Google 的下一代调度系统。</p>
<p>然而近期的一些消息表明为了达到设计目标，Omega 的实现逻辑变得越来越复杂。
在原有的 Borg 共享状态模型已经能满足绝大部分需要的情况下，Omega 的前景似乎没有那么乐观。</p>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>这篇文章介绍了多种调度器结构设计的模型并讨论了在相关模型下进行任务调度的一些特点。
通过这些模型的对比，我想提出自己对调度系统设计的几点看法：</p>
<ol>
<li>在小规模的应用和需要自己设计调度器的场景，我们应该尽量采取中心化的调度模型。这是因为这种模型设计和使用都比较简单，
调度器容易对整个系统的状态有全面的把握，状态同步的困难也不高</li>
<li>在机群和应用规模继续扩大或者对调度算法有定制要求的情况下，可以考虑使用双层调度器设计。
双层调度器调度策略的编写较为复杂，随着新一代共享状态调度器的发展，在未来可能会慢慢退出主流</li>
<li>共享状态调度器因为其较为简单的编程接口以及适应多种需要的特点，正随着 Kubernetes 的流行而渐渐变成主流。
如果应用规模比较大或需要在一个集群上运行多种定制调度策略，这种调度器架构设计是最有前景的</li>
</ol>
<p>最后，通过学习和亲自设计一套调度系统，我深刻的领会到一些个人在编程的时候非常重要的经验：</p>
<ol>
<li>Keep things simple 。在实现任何程序的时候，简单的设计往往比复杂的设计更好。
比如说尽量减少系统中相互独立的各种模块，尽量统一编程语言，尽量减少相互隔离的系统状态。
这样的设计可以减少 Bug 出现的概率，降低维护状态同步的难度</li>
<li>Move fast。在设计复杂系统的时候很容易陷入对细节的不必要追究上，从而导致需要管理的细节越来越多，
增加了很多心智压力。最后系统完成的进度也是难上加难。更好的办法是先从宏观上进行大概的设计，
在进行实现的时候忽略具体的细节(比如代码如何组织、函数如何相互调用、代码如何写得好看等)，
快速迭代并实现功能。当然，在这个过程中也仍然要把握好功能和质量的平衡</li>
<li>技术发展的循环上升轨迹。 回忆起当初 Linux 和 Minix 在宏内核和微内核之间的世纪论战，
尽管以 Linux 这种 Monolithic 内核设计的胜出而告终，但是 Minix
的作者在其著述的《<a href="https://book.douban.com/subject/3017583/" target="_blank" rel="noopener">Modern Operating System</a>》
教科书上指出了这种循环上升的轨迹，预言了微内核设计的归来。看一看共享状态调度系统的设计就会发现，
这一预言已经应验在了分布式系统上</li>
</ol>
<h1 id="u5C55_u671B"><a href="#u5C55_u671B" class="headerlink" title="展望"></a>展望</h1><p>在本文中，并没有特别涉及到任务调度的具体算法，比如如何准确地定时激发任务，如何更高效地分配资源等等。
调度算法所要解决的问题本质上只有两个：</p>
<ol>
<li>全面掌握当前系统的状态</li>
<li>准确预测未来的任务需求</li>
</ol>
<p>很多调度器模型在设计上已经对这两方面有所考量，但调度器算法本身可以说又是一个巨大的主题，
笔者本身对其了解也非常有限，因此不敢在这篇文章中继续展开。从直觉上讲，上述需求二可能是一个和 AI
技术相结合很好的切入点，在未来可能会有很多研究。</p>
<p>在前文还提到了很多调度器也会附带管理本地文件资源的分发，比如像 Kubernetes 启动任务的时候需要将 Docker
镜像分发到各个宿主机上。作为其原型，Borg 在这一过程中甚至利用了 P2P 技术加快分发速度和充分利用带宽。
在开源世界中似乎还没有类似的解决方案。当然，这一需求也只有在机群规模非常大的时候才有价值，
但未来仍可能成为一个不错的发展方向。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>之前为完成《<a href="/2017/10/13/kylin-aws-scheduler-system/">AWS 下 Kylin 调度系统的设计</a>》，阅读了大量
集群资源管理和任务调度的资料和论文。了解了如
<a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" target="_blank" rel="noopener">Hadoop YARN</a>、
<a href="http://mesos.apache.org/" target="_blank" rel="noopener">Mesos</a>、
<a href="https://github.com/amplab/drizzle-spark" target="_blank" rel="noopener">Spark Drizzle</a>、
<a href="https://research.google.com/pubs/pub43438.html" target="_blank" rel="noopener">Borg/Kubernetes</a> 和
<a href="https://research.google.com/pubs/pub41684.html" target="_blank" rel="noopener">Omega</a>
等系统的调度器设计架构，在这篇文章里我将试图从这些架构案例中总结出此类系统一般的设计模式。</p>]]>
    
    </summary>
    
      <category term="Scheduler" scheme="https://io-meter.com/tags/Scheduler/"/>
    
      <category term="Distributed System" scheme="https://io-meter.com/tags/Distributed-System/"/>
    
      <category term="Designing Data-Intensive Applications" scheme="https://io-meter.com/tags/Designing-Data-Intensive-Applications/"/>
    
      <category term="Summary" scheme="https://io-meter.com/tags/Summary/"/>
    
      <category term="Designing Paradigm" scheme="https://io-meter.com/tags/Designing-Paradigm/"/>
    
      <category term="kubernetes" scheme="https://io-meter.com/tags/kubernetes/"/>
    
      <category term="borg" scheme="https://io-meter.com/tags/borg/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[记 2017 年的三次日本之旅]]></title>
    <link href="https://io-meter.com/2018/02/06/travelling-in-japan/"/>
    <id>https://io-meter.com/2018/02/06/travelling-in-japan/</id>
    <published>2018-02-06T14:43:23.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>在今年樱花季第一次前往日本游玩的时候，我绝没想到今年竟然有机会访问这一与中国渊源颇深的国家三次。
狗年将至，也许是时候把这篇拖延已久的游记发表出来总结一下了。</p>
<a id="more"></a>
<h2 id="3__u6708_31__u65E5_u81F3_4__u6708_11__u65E5_u2014_u2014_u6A31_u82B1_u5B63"><a href="#3__u6708_31__u65E5_u81F3_4__u6708_11__u65E5_u2014_u2014_u6A31_u82B1_u5B63" class="headerlink" title="3 月 31 日至 4 月 11 日——樱花季"></a>3 月 31 日至 4 月 11 日——樱花季</h2><p>第一次日本之行选在日本旅游最热的季节——樱花季。选择樱花季访日的时机是一个困难的问题，
一方面需要提早预定机票和住宿以控制成本，一方面樱花的到来又是有一定的窗口期的。
如果安排的过早或者过晚，就有可能错误最佳的观赏时机。</p>
<p>尽管我们事先关注了各种预测，并且将行程安排成由南到北，期望在一次行程当中遍览早樱、盛樱和晚樱。
然而事实情况是在关西的我们恰好错过早樱，到了东京又只看到一些樱花的尾巴，不得不说是一种遗憾。
好在当我们到访北陆的金泽时，恰好遇到樱花的盛放，也算是不虚此行。</p>
<p>作为我的第一次日本之行，这次安排的时间比较长，访问的地点也比较多。
内容主要分为关西、北陆和东京三大块，预先安排的旅行重点主要是：</p>
<ol>
<li>关西：大阪、京都方面的城市风情以及文物古迹之旅</li>
<li>北陆：动漫场景朝圣之旅+温泉旅馆体验</li>
<li>东京：购物活动</li>
</ol>
<h3 id="u5173_u897F"><a href="#u5173_u897F" class="headerlink" title="关西"></a>关西</h3><p>日本关西的热门旅游目的地包括大阪、京都、奈良等。我们从大阪关西机场入境，
在第一天走马观花似的游览了道顿堀和大阪城公园。</p>
<p><img src="/img/japan/daodunku.jpg" alt="道顿堀"></p>
<p>道顿堀是大阪这一日本第二大中心城市商业最繁华的地区。知名的蟹道乐在这里有至少三家主店。
而我们在这里找到了一家米其林星级的大阪烧店解决了中午饭。</p>
<p><img src="/img/japan/dabanshao.jpg" alt="大阪烧"></p>
<p>大阪城公园是大阪另一个必去的地方。尽管现今的城楼是在废墟原址上重建的现代产品，仍然很值得上楼远眺一下风景。</p>
<p><img src="/img/japan/dabancheng.jpg" alt="大阪城"></p>
<p>在大阪，我第一次吃到了传说中的和牛烧肉。作为一个吃货从此无法忘怀，之后两次访日都特地去品尝了。</p>
<p><img src="/img/japan/shaorou.jpg" alt="烧肉"></p>
<p>在大阪一天多的行程结束后我们来到了日本最热门的旅游目的地——京都。
京都火车站也是经常出现在影视动漫作品里的地点。</p>
<p><img src="/img/japan/kyoto_station.jpg" alt="京都站"></p>
<p>京都另一个必去之处就是在近郊的伏见稻荷大社，这里的千本鸟居颜色鲜艳，是拍照游览的好去处。
另外，在日本访问神社，别忘记准备 5 日元的硬币用来祈愿以及可以买一些御守赠送亲朋好友。</p>
<p><img src="/img/japan/qianbenniaoju.jpg" alt="千本鸟居"></p>
<p>京都其他值得去的地方还有六条乌丸、锦市场、清水寺、金阁寺、岚山和祇园等。
这里值得一提的是在祇园的八坂神社在晚上会像动漫当中一样有各种夜市小吃，这是白天游览不会遇到的特别体验。
此外我们还见到了日本社会人常去类似大排档的小吃店（日本人在吃大排档的时候也是跪坐呢！）</p>
<p><img src="/img/japan/liutiao.jpg" alt="六条"></p>
<p><img src="/img/japan/yeshi.jpg" alt="祇园夜市"></p>
<p>京都是中国人来得最多的日本城市，在路上乘坐公交以及在各个旅游景点都可以听见汉语交谈的声音，
让人有一种亲切的感觉。由于京都的地铁交通很多时候并不方便，因此建议购买500日元的单日公交票方便游览</p>
<p><img src="/img/japan/qingshuisi.jpg" alt="清水寺"></p>
<h3 id="u5317_u9646"><a href="#u5317_u9646" class="headerlink" title="北陆"></a>北陆</h3><p>起了一个大早，我们自京都乘坐列车经过漫长的旅途到达了飞驒和高山。
这两个地方分别是《你的名字。》和《冰菓》巡礼的地方。
除此之外，飞驒牛也是日本有名日本牛种。而我们在高山的最大亮点就是住宿安排了温泉旅馆。
在一天的玩耍之后泡一泡酒店的日式温泉汤，也是特别享受的经历（不过花费可是不菲）。</p>
<p><img src="/img/japan/bingguo.jpg" alt="《冰菓》主人公就读的学校"></p>
<p><img src="/img/japan/nidemingzi.jpg" alt="《你的名字。》中图书馆的纪念专柜"></p>
<p>晚上，在和式的房间当中品尝欧吉桑摆盘的日式晚餐，可能是我终生难忘的一段经历了。</p>
<p><img src="/img/japan/wancan.jpg" alt="和式晚餐"></p>
<p>不得不说日本的乡下地方都十分干净而有风味。可能是因为少子化和东京的虹吸作用，
在像高山这样的地方年轻人相当少。比如我们租用自行车的租车店，
就是一位年近七十的老爷爷在经营。老爷爷也不求赚钱，租车费收的很大方，
每次最开心的事情就是我们在借车和还车的时候跟我们聊聊天。</p>
<p><img src="/img/japan/jiedao.jpg" alt="街道"></p>
<p>在高山还有两段类似的经历：我们在路上寻找目的地的过程中一位开车的老爷爷很热心的给我们指路，
以至于开车带领我们过去。此外在当地的社区中心上厕所（当时肚子吃坏了）出来的时候，
社区中心的一位大叔也很热心的跟我们聊了很久。</p>
<p><img src="/img/japan/yinghua1.jpg" alt="樱花"></p>
<p>北陆的最后一站是北陆最大的城市金泽。诚如前面提到的，没能在京都看到樱花的我们本来心灰意冷，
把金泽当作休整和休息的地方。万万没想到这里会成为北陆之行的最大亮点。</p>
<p><img src="/img/japan/yinghua2.jpg" alt="兼六园入口前的樱花"></p>
<p>在金泽，我们不但遇见樱花最茂盛的时刻，本地最著名的园林兼六园还应季免费开放。</p>
<p><img src="/img/japan/jianliuyuan.jpg" alt="兼六园"></p>
<p>此外金泽美术馆也是极大的亮点。在全天多云的情况下片刻出现的晴朗让我抓拍到了令人印象深刻的照片。
金泽美术馆独特建筑设计以及周边映照的樱花带来了难忘的构图和色彩！</p>
<p><img src="/img/japan/meishuguan_yinghua.jpg" alt="金泽美术馆的樱花"></p>
<p><img src="/img/japan/meishuguan_jianzhu.jpg" alt="金泽美术馆的建筑"></p>
<p>此外，到了金泽还必须要去近江町市场品尝新鲜的海产，特别推荐门口的一家全国大赏获奖的海鲜饭
（我们竟然一下吃了三次）。</p>
<p><img src="/img/japan/haixianfan.jpg" alt="海鲜盖饭"></p>
<h3 id="u4E1C_u4EAC"><a href="#u4E1C_u4EAC" class="headerlink" title="东京"></a>东京</h3><p>结束了北陆的风光之旅，最后一站是安排在东京购物。在东京恰逢阴雨天气，出行十分不便，
不过我们一行人还是抽空拜访了 Google 在东京的办公室。</p>
<p><img src="/img/japan/google_tokyo.jpg" alt="Google Tokyo"></p>
<p>总所周知，Google 的办公室以环境舒适而著称。其东京的办公室在繁华的六本木地区，
在楼里可以看到著名的东京塔。</p>
<p><img src="/img/japan/tokyo_tower.jpg" alt="Tokyo Tower"></p>
<p>我个人在第一天下午脱离对我，造访了上野公园和日本的国立博物馆和美术馆地区。
这一天，上野公园来赏樱的人络绎不绝，在公园附近神社的夜市小吃街也给让人流连忘返。</p>
<p><img src="/img/japan/shangyegongyuan.jpg" alt="上野公园"></p>
<p><img src="/img/japan/xiaochijie.jpg" alt="小吃街"></p>
<h2 id="9__u6708_25__u65E5_u81F3_28__u65E5_u2014_u2014_u4E00_u4E2A_u4EBA_u7684_u4E1C_u4EAC"><a href="#9__u6708_25__u65E5_u81F3_28__u65E5_u2014_u2014_u4E00_u4E2A_u4EBA_u7684_u4E1C_u4EAC" class="headerlink" title="9 月 25 日至 28 日——一个人的东京"></a>9 月 25 日至 28 日——一个人的东京</h2><p>第二次日本之旅比较特别，因为种种原因，这次旅行只有我一个人成行。
不得不说，独自一人前往异国他乡驻留三天，即是一种具有挑战性的活动，
又是一段难忘的经历。</p>
<p><img src="/img/japan/huangju.jpg" alt="皇居"></p>
<p>这次旅行只安排在东京游览，为了节约成本选择了廉价机票和红眼航班。来回的旅程对于体力有相当的要求。
凌晨到达东京后，我先访问了东京皇居，并在河边远眺了二重桥。皇居还有东御院等开放的经典，但是开放时间不确定，
偶尔可能会关闭。皇居内苑也是可以访问的，但是需要提前预约。</p>
<p><img src="/img/japan/youyiku.jpg" alt="优衣库"></p>
<p>第一天因为体力的原因，只抽了一小部分时间在商场购物，
尤其是前往全球最大的优衣库银座店免税购买了不少东西。第一天晚上最幸福的事情是一个人在住所附近品尝和牛烧肉。
完全不会日语的我和听不懂英语的电源线小哥通过 Google Translate 艰难的交流之后竟然成功的完成了点单。
这又是一段十分有趣的经历。</p>
<p><img src="/img/japan/yigerendekaorou.jpg" alt="一个人在异国他乡吃烤肉"></p>
<p>第二天大早就出发前往东京最具盛名的浅草寺。虽然恰逢雷门维修没有能够留下完整的影像，
但是随大流地祈福和抽幸运签也是挺有趣的。</p>
<p><img src="/img/japan/leimen.jpg" alt="雷门"></p>
<p>下午的时候重新细致地游览了第一次没能好好观光的国立博物馆和美术馆等。
又在晚上乘坐轻轨远眺了彩虹大桥。这一天的游览算是圆满的结束了。</p>
<p><img src="/img/japan/guolibowuguan.jpg" alt="国立博物馆"></p>
<p><img src="/img/japan/guolimeishuguan.jpg" alt="国立美术馆"></p>
<p>第三天也是这次行程最大的重点，那就是让我心心念念许久了的吉卜力美术馆啦！
前往吉卜力美术馆乘坐铁路自市中心到达吉祥寺站，之后搭乘公交就可以到达了。
这一天天气清凉，微风和煦，可以说是完美的一天。
而吉卜力美术馆的展品确实惊艳，让人流连忘返。</p>
<p><img src="/img/japan/jixiangsi.jpg" alt="吉祥寺"></p>
<p>要去吉卜力美术馆值得注意的是千万要提前一个月预定好门票。
美术馆的门票需要使用护照名实名预订，且要按照时段入馆。
这个门票的难抢程度堪比春运的火车票，实在不行就只能求助淘宝黄牛咯！
此外美术馆禁止在馆内拍摄，只能在室外留影。</p>
<p><img src="/img/japan/jibulimeishuguan-tiankongzhicheng.jpg" alt="吉卜力美术馆-天空之城"></p>
<p><img src="/img/japan/jibulimeishuguan-longmao.jpg" alt="吉卜力美术馆-龙猫"></p>
<p>在乘机返回之前，顺便还去 Indeed 在东京的办公室访问了一下。
Indeed 算是少数在日本具有硅谷风格办公室的企业了。这里的办公环境也很不错哦！</p>
<p><img src="/img/japan/indeed-tokyo.jpg" alt="Indeed Tokyo"></p>
<p><img src="/img/japan/indeed-tokyo-2.jpg" alt="Indeed Tokyo 外景"></p>
<h2 id="11__u6708_23__u65E5__u81F3_26__u65E5_u2014_u2014_u7EA2_u53F6_u5B63"><a href="#11__u6708_23__u65E5__u81F3_26__u65E5_u2014_u2014_u7EA2_u53F6_u5B63" class="headerlink" title="11 月 23 日 至 26 日——红叶季"></a>11 月 23 日 至 26 日——红叶季</h2><p>第三次里最精彩的一次日本之行，应该算红叶季这次了吧。这一次因为有一个颇为老司机的朋友同行，
各方面的安排都比较妥当。因为机票预订的早，这次旅行全程都是乘坐颇有口碑的全日空航空公司的航班。
航班的服务质量不愧为日本良心，机上饮食也很不错。</p>
<p><img src="/img/japan/huangye.jpg" alt="银杏黄叶"></p>
<p>这次旅行的第一站在大阪。在这里我们看到了弥漫在整个城市街道两旁的金黄色，
这些都是银杏！在灿烂的阳光和晴朗的天气中重访大阪城公园真是令人心旷神怡。</p>
<p><img src="/img/japan/hongyehuangye.jpg" alt="银杏黄叶"></p>
<p><img src="/img/japan/dabancheng-yangguang.jpg" alt="大阪城"></p>
<p>观赏银杏，最好的地点就是在京都岚山了。行走在望月桥上或前往常寂光寺等地，
可以欣赏到大片姹紫嫣红的红叶树。这光景真是令人窒息的美。</p>
<p><img src="/img/japan/lanshan-hongye.jpg" alt="望月桥边"></p>
<p><img src="/img/japan/hongye-wuyan.jpg" alt="屋檐"></p>
<p><img src="/img/japan/hongye-san.jpg" alt="红叶与伞"></p>
<p><img src="/img/japan/hongye-shenshe.jpg" alt="红叶与神社"></p>
<p>岚山之后另一个值得访问的地方是世界文化遗产姬路城。这座城池不像大阪城那样属于重建，
而是真的古物，因此也格外吸引人。游览完姬路城，顺便游览一下附近的园林，
也可以欣赏到五彩缤纷的园景。</p>
<p><img src="/img/japan/jilucheng.jpg" alt="姬路城"></p>
<p><img src="/img/japan/jilucheng-yuanlin.jpg" alt="园林"></p>
<p>这次行程，我们还顺道前往了知名牛肉产地神户。
在这里幸运地品尝到了美味的神户牛烧肉。晚上前往神户港拍摄夜景也是很好的！</p>
<p><img src="/img/japan/shenhugang.jpg" alt="神户港"></p>
<p>最后一天回到东京，迎接我们的事绚烂的东大的银杏，虽然已经在大阪欣赏过，
东大这里的银杏还是震惊了我们。那密密麻麻的黄叶在秋日清爽的蓝天的映衬下显得格外地闪耀逼人。</p>
<p><img src="/img/japan/dongda-yinxing.jpg" alt="东大的银杏"></p>
<p><img src="/img/japan/dongda-yinxing-2.jpg" alt="东大的银杏之二"></p>
<p>下午，经过几天劳累的我们尽量缩减了行程，但是仍然访问了新宿地区以及那里的知名咖啡连锁店
Blue Bottle。在蓝瓶子这边品尝的卡布奇诺可能是我迄今为止品尝过的最好的了。</p>
<p><img src="/img/japan/xinsuzhan.jpg" alt="新宿站"></p>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>日本作为我们的邻国，经常被我们描述为”一衣带水”。这个国家和他的国民与我们的纠葛可能再过几十年也解不开。当我暂且将这些芥蒂放在一边，单纯地去欣赏它的风光，感觉自己好像真的沉浸在这美景之中，忘却了很多烦恼。</p>
<p>2017年对我来说是人生中相当重要的一年，这一年遇到很多困难，也获得很多收获。能在这一年当中三次前往日本，在旅行的过程中思考人生，不得不说是极大的幸运啊！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在今年樱花季第一次前往日本游玩的时候，我绝没想到今年竟然有机会访问这一与中国渊源颇深的国家三次。
狗年将至，也许是时候把这篇拖延已久的游记发表出来总结一下了。</p>]]>
    
    </summary>
    
      <category term="Travel" scheme="https://io-meter.com/tags/Travel/"/>
    
      <category term="Japan" scheme="https://io-meter.com/tags/Japan/"/>
    
      <category term="Tokyo" scheme="https://io-meter.com/tags/Tokyo/"/>
    
      <category term="Osaka" scheme="https://io-meter.com/tags/Osaka/"/>
    
      <category term="Kyoto" scheme="https://io-meter.com/tags/Kyoto/"/>
    
      <category term="Gourmet" scheme="https://io-meter.com/tags/Gourmet/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[AWS 上 Kylin 调度系统的设计]]></title>
    <link href="https://io-meter.com/2017/10/13/kylin-aws-scheduler-system/"/>
    <id>https://io-meter.com/2017/10/13/kylin-aws-scheduler-system/</id>
    <published>2017-10-13T06:18:26.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>最近加入 <a href="https://strikingly.com" target="_blank" rel="noopener">Strikingly</a> / <a href="https://sxl.cn" target="_blank" rel="noopener">上线了</a> 光荣地成为了一名数据平台工程师，
投身于大数据平台开发的工作当中。这两个月来，通过设计和实现一个 AWS 的 Kylin 数据仓库调度系统，
收获很多，借此机会总结一下。</p>
<a id="more"></a>
<h2 id="u80CC_u666F_u4ECB_u7ECD"><a href="#u80CC_u666F_u4ECB_u7ECD" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>Strikingly 是一家为用户提供建站服务的初创企业，目前的数据平台主要处理的是用户所建立网站的访问者信息统计，
可以认为是一套简单的 <a href="https://analytics.google.com" target="_blank" rel="noopener">Google Analytics</a> 服务。这套系统使用 <a href="https://keen.io/" target="_blank" rel="noopener">Keen IO</a>
收集访问者信息，使用 Kylin、Hadoop、Hive 等技术处理海量数据，整套系统都部署在 <a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a> 上，
深度使用了 EC2、ECS、ELB、EMR 等 AWS 服务。除了收集访问者的 Page View 信息，
这套系统还会处理一些用户付费行为相关的 e-commerce 信息等。</p>
<h3 id="u6570_u636E_u5904_u7406_u6D41_u7A0B"><a href="#u6570_u636E_u5904_u7406_u6D41_u7A0B" class="headerlink" title="数据处理流程"></a>数据处理流程</h3><p>下图是目前系统的数据处理流程的一个简化版本:</p>
<p><img src="/img/kylin-scheduler/data-processing-pipeline.png" alt="Data Processing Pipeline"></p>
<p>以用户的 Page View 数据处理为例，主要有以下几个步骤：</p>
<ol>
<li>数据首先由内嵌在页面当中的 JS 脚本收集到第三方服务 Keen IO 那里</li>
<li>通过 Keen IO 的数据导出功能，将 Page View 数据以五分钟为单位，使用 JSON 格式打包放置在 AWS S3 上的指定目录</li>
<li>通过为 Hive 配置 <a href="https://github.com/rcongiu/Hive-JSON-Serde" target="_blank" rel="noopener">JsonSerDe</a>，我们可以将第二步当中的指定目录直接虚拟成一个
Hive 表，从而可以在 Hive 上使用 SQL 语句进行查询操作</li>
<li>Kylin 控制 EMR 上的各种组件，如 Hive、Hadoop 等进行处理，将数据处理的结果保存在 HBase 表当中，以备之后取用</li>
</ol>
<p>当数据被处理好保存在 HBase 上之后，我们就可以调用 Kylin 所提供的 API 对这些数据进行远超过以往的速度的访问，
从而支撑每个 Strikingly 或上线了用户对自己网站统计数据的查询要求。</p>
<h3 id="Kylin__u7B80_u4ECB"><a href="#Kylin__u7B80_u4ECB" class="headerlink" title="Kylin 简介"></a>Kylin 简介</h3><p>从上面的数据处理流程当中可以看出，Kylin 无疑是整套系统的核心: 一方面它控制了对 Hive 当中原始的数据进行处理并缓存到 HBase
的全过程，另一方面它还要服务用户对处理后的数据大量的查询请求。在这里有必要对 Kylin 及其基本概念进行一个简单的介绍。</p>
<p><a href="http://kylin.apache.org/" target="_blank" rel="noopener">Apache Kylin</a> 是一个开源的分布式数据分析系统，它和 Hadoop、Spark 等一样，
都是 Apache 基金会的顶级项目。Kylin 可以被认为是一种 <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load" target="_blank" rel="noopener">ETL</a>
工具，我把它主要完成的任务概括为以下几点:</p>
<ol>
<li>根据预先定义好的模型，将保存在 Hive 表或其他来源的数据提取出来</li>
<li>根据预先定义好的模型关系，将数据按照一定的算法进行变换处理，使得数据以一种易于查询的方法存在</li>
<li>当用户请求到来时，通过分析用户请求，将查询分解成可以作用于变换后数据格式的任务，从而快速的得到处理结果</li>
</ol>
<p>在第 2 点当中 Kylin 使用的技术被称为 Cubiod。 这一技术有点像根据模型的定义，预先穷举用户查询的所有可能结果，
然后将这些结果以合适的方式组织起来。当然，在实际实现当中，为了更加有效地执行这一任务并将其抽象为可以运行在 Hadoop
集群上的 MapReduce 任务，Kylin 所实现的算法要复杂很多。在此我们不对 Kylin 的技术实现进行深入的介绍，
但是为了继续之后的内容，必须要了解 Kylin 当中四个重要的概念: Model、Cube、Job 和 Segment。</p>
<p><img src="/img/kylin-scheduler/kylin-model-cube-segment-job.png" alt="Model, Cube, Segment, Job"></p>
<p>上图给出了这四个概念的一个关系说明，简单来讲：</p>
<ul>
<li>Model 是对数据来源的描述，比如说我们想要进行查询的数据表的主表是什么，想要和主表 Join 起来的辅助表是什么等等。
值得注意的是，在 Model 里，我们要为模型指定一个列(或者称为维度)作为这个模型的 Range Key(或者称为 Partition Key)。
所谓 Range Key，就是说根据这个维度，可以比较好地将数据划分为多个不相交的部分。这个 Key 在之后 Segment 的部分也会用到</li>
<li>Cube 是对转化和处理数据的方法的描述。在 Kylin 里，我们并不需要手动编写转化的程序，而是通过指定需要进行操作的 Model，
提供一些用户可能进行的查询和统计的指标(比如用户可能在哪些字段上使用 <code>GROUP BY</code>，在哪些字段上进行 <code>COUNT</code> 或
<code>COUNT_DISTINCT</code> 统计等)，Kylin 会自动根据这些定义和数据模型本身的特点，构造出合理的执行流程</li>
<li>Job 是在 Cube 的控制下，Kylin 执行的一次任务处理。它包括了数据处理过程当中，数据抽取、数据变换、数据储存、
垃圾清理等的全过程。Job 的类型包括 <code>BUILD</code>、 <code>REFRESH</code>、 <code>MERGE</code> 等</li>
<li>Segment 是一个 Job 执行的结果。对于一个 Cube 来说，他的 Segment 可以根据 Range Key 划分为多个区间分别构建，
当某一区间的 Segment 构建成功之后，Kylin 就可以实现对这一区间当中数据的快速查询。而构建当中或者构建失败的 Segment
无法提供查询服务。对于横跨多个 Segment 的查询，Kylin 会分别执行对各个 Segment 的查询，再将结果合并起来。
我们可以 <code>REFRESH</code> 一个 Segment 以更新其中的数据，或者 <code>MERGE</code> 多个 Segment 以避免跨 Segment 查询带来的性能损失</li>
</ul>
<p>当我们根据上述模型构建了 Segment 之后，Kylin 就可以通过 SQL 接口对 Model 指定的数据表进行快速的查询和分析了。
值得注意的是，我们还可以以集群的方式部署 Kylin。一个 Kylin 集群可以有一个 Job 节点和若干个 Query 节点组成，
其中 Job 节点单独用来做 Cube 构建的编排控制操作，Query 节点则用来承载用户的查询请求。</p>
<h3 id="u5BF9_u8C03_u5EA6_u7CFB_u7EDF_u7684_u9700_u6C42"><a href="#u5BF9_u8C03_u5EA6_u7CFB_u7EDF_u7684_u9700_u6C42" class="headerlink" title="对调度系统的需求"></a>对调度系统的需求</h3><p>尽管 Kylin 的存在使得我们承载用户 Page View 查询的数据处理平台成为可能，在系统的开发和部署当中仍然遇到一些问题，
导致开发一个集中式的调度系统成为必要。在实践当中遇到的需求可以总结为以下几条:</p>
<p><strong>定制化的任务调度</strong>，在很多情况下，Kylin 自带的调度系统不能很好的满足我们的需求，
这是我们自行实现调度系统最本质的原因。我们遇到的问题主要包括以下几点:</p>
<ol>
<li>由于数据从收集到导入 Kylin 之间的步骤比较多，每个步骤都需要调度控制协调运行。
比如说，由于历史设计的原因，在激发 Kylin 构建一段时间区间内的数据时，我们需要先对应的 Hive 表进行一次刷新的操作，
这个操作不能由 Kylin 来控制</li>
<li>在构建的时候，我们希望不同 Cube 的任务可以并行运行，但是同一个 Cube 的任务必须串行执行。
这是因为，在我们的系统设计中，有一类调度任务需要获取当前 Cube 的各项状态，用于规划之后的构建工作，
允许同一 Cube 的任务并行可能导致这类任务获取到的当前状态无效，简便起见我们希望避免这样的情况</li>
<li>有一些特别的任务，如元数据的备份、HBase 表的清理等需要 Block 所有其他的任务。
这是因为在这些任务执行的时候需要对系统整体的元信息做一个查询或变更，
如果在这一过程中有其他任务正在执行会产生并发一致性问题，不但可能导致所得数据不完整，还可能损坏整个系统</li>
<li>之前提到，横跨多个 Segment 的查询速度可能比较慢，一个可能的优化思路就是根据用户请求的特点，
对某一 Cube 的 Segment 实行更有针对性更积极的 Merge 策略。截至目前 Kylin 本身还没有提供对这一需求良好的支持。
因此自己实现 Merge 任务的调度也就比较有必要了</li>
</ol>
<p><strong>运维自动化</strong>，在 Strikingly，我们不但重度使用 AWS 的服务，还使用 <a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>
和 <a href="https://www.docker.com/" target="_blank" rel="noopener">Docker 容器</a>等工具来实现运维自动化，
这些自动化工具要求我们系统的每个部分尽可能地无状态和可配置。尽管 Kylin 本身将自己的元数据保存在 HBase 上，
但是仍然有一些对运维自动化的挑战:</p>
<ol>
<li>包括 Kylin 在内的 Hadoop 组件深度依赖 XML 或 Java Properties 配置文件进行定义，
这对容器镜像的复用造成了一定的阻碍。比如说我们需要将这套系统分别部署在 AWS 的两个不同的 Region 中，
理想的情况是可以使用环境变量来定义 IP 地址等的变化，而不用构建不同的容器镜像</li>
<li>Kylin 目前集群部署的设计对于 Auto Scale 不友好。这主要是由于 Kylin 需要在集群的 Job 节点硬编码 Query
节点的 IP 地址和端口，并在 Cube 构建任务结束或者元信息变化之后通知 Query 节点，以便清理缓存更新数据。
这一点大大地限制了 ECS 服务在进行容器编排和 Auto Scale 时的灵活性。</li>
<li>在实际中需要使用的一些 Kylin 功能(如元信息备份工具等)只能通过命令行调用，
而在在容器中使用简单的 crontab 脚本调度这些命令既笨重又容易出故障。</li>
</ol>
<p><strong>系统的健壮性</strong>，我们的数据平台系统在遇到故障或需要上线新的版本的时候不可避免的需要重启。
这样的情况下就可能出现本应被调度的一个事件不幸错过的现象。在以前，
我们需要人工地辨识这种情况并手动应用这些事件，但是在一个动态运行的系统当中，
手动的工作往往是费事且令人手忙脚乱的。理想状态下我们的调度系统应该具备一定的自我恢复能力，
能够在重启之后自主地发现错过的任务从而恢复他们。</p>
<p>综上所述，实现一个集中式、功能丰富的调度系统势在必行。</p>
<h2 id="u8C03_u5EA6_u7CFB_u7EDF_u7684_u8BBE_u8BA1"><a href="#u8C03_u5EA6_u7CFB_u7EDF_u7684_u8BBE_u8BA1" class="headerlink" title="调度系统的设计"></a>调度系统的设计</h2><p>调度系统的整体设计如下图所示:</p>
<p><img src="/img/kylin-scheduler/scheduler-overall-design.png" alt="Scheduler Overall Design"></p>
<p>图中箭头的方向指示了数据流动的方向和调度器控制组件的方向。为了满足前文提到的各种需求，
我们的调度系统有如下的特点:</p>
<ol>
<li>调度器集中地调度和控制除 Keen IO 之外的各个组件。在激发任务后监控并等待任务完成，以便使所有任务协调有序执行</li>
<li>Kylin 集群中，Job 节点不再与 Query 节点进行直接的交互，而是由 Scheduler 通过 AWS SDK 获得存在于指定 Target Group
中 Kylin 节点的地址信息，直接控制 Cache 刷新等工作</li>
<li>调度器使用 DynamoDB 保存运行状态，因故重启之后自动读取记录恢复，从而获得更强的健壮性。保存在 DynamoDB
当中的记录还可以用来弥补任务调度当中出现的缺口</li>
<li>调度器直接通过查询 Kylin Job 节点获得 Cube 和 Segment 的完整信息，自行连接 HBase 完成 Kylin
元信息表的备份和数据表的清理工作，从而避免执行命令行工具。备份数据将会被直接放置在 S3 上</li>
<li>调度器和 Kylin 节点都使用 Docker 容器部署。对于 Kylin 节点来说，我们使用 Python 脚本自行编写了启动器，
这一脚本可以在启动时通过环境变量和预先提供好的配置模板，先进行字符串替换生成由环境变量定制过的配置文件，
再启动 Kylin 和其他 Hadoop 组件，从而可以在不同场合使用单个容器镜像</li>
</ol>
<h2 id="u8C03_u5EA6_u7CFB_u7EDF_u7684_u5B9E_u73B0"><a href="#u8C03_u5EA6_u7CFB_u7EDF_u7684_u5B9E_u73B0" class="headerlink" title="调度系统的实现"></a>调度系统的实现</h2><p>我们决定使用 Scala 编写和实现调度器，以便利用 Java/JVM 上的各种工具和库连接和管理包括 AWS、HBase 和 Hive 在内的各个组件。
除了 <a href="https://github.com/seratch/AWScala" target="_blank" rel="noopener">AWScala</a>、<a href="http://www.joda.org/joda-time/" target="_blank" rel="noopener">Joda-Time</a>、
<a href="https://github.com/spray/spray-json" target="_blank" rel="noopener">Spray-JSON</a> 等工具库之外，我们使用的最重要的框架是 <a href="https://akka.io/" target="_blank" rel="noopener">Akka</a>。</p>
<p>Akka 是一个 Scala/Java 下 <a href="https://en.wikipedia.org/wiki/Actor_model" target="_blank" rel="noopener">Actor 并发模型</a>的一个开源实现。
Akka 实现的 Actor 模型受 <a href="https://www.erlang.org/" target="_blank" rel="noopener">Erlang</a> 编程语言的启发，每个 Actor 相当于一个可以执行任务的对象，
这个对象执行的具体任务由它接收到的消息(Message)决定。这些对象都包含一个并发安全的队列作为信箱，
信箱中的每条消息将会被 Actor 串行地处理，Actor 接受到消息之后也可以再转发给其他的 Actor。
我们的调度器将会利用这些特性实现并发任务调度和管理。</p>
<p>Akka 还提供了一种名为<code>ConsistentHashingRouter</code>的组件。它本质上是一个专门用来分发消息的 Actor。
<code>ConsistentHashingRouter</code>可以利用消息本身提供的哈希键来分发消息到下游的 Actor，
它可以保证具有相同哈希键消息一定会被分发到同一个 Actor 上。我们可以利用这一特点来保证我们对于某一 Cube
的调度操作都是串行的。Akka 的 <code>ConsistentHashingRouter</code> 还支持包括 Auto Scale 在内更多丰富的功能，
在此不再赘述，下面是调度器的 Actor 系统的架构图:</p>
<p><img src="/img/kylin-scheduler/scheduler-actor-message-flow.png" alt="Actor System Structure"></p>
<p>调度器的执行模块主要包括 5 个部分:</p>
<ol>
<li><code>ControlActor</code> 是调度器的重要组成部分，每个任务消息都会首先到达 <code>ControlActor</code>。<code>ControlActor</code>
会对消息进行一些预处理。所有的 <code>ControlMessage</code> 都会由 <code>ControlActor</code> 直接执行，不会被传递给下游</li>
<li><code>ConsistentHashingRouter</code> 是一个分发器，它将接收到的 <code>TaskMessage</code> 以一致性哈希的方式分发给下游的 Actor。
这种分发保证同一个 Cube 的消息一定会在同一个 Actor 当中串行执行，同时也具备一定的并行性</li>
<li><code>TaskActor</code> 是真正执行调度任务的 Actor。所有的 <code>TaskActor</code> 都是相同的，它们接收到消息之后也会进行一些预处理，
然后根据消息指定的 <code>Executor</code> 名称，选择正确的执行器进行执行。如果执行失败，<code>TaskActor</code>
也负责捕捉错误并进行一些错误恢复和 Log 的处理</li>
<li><code>Executor</code> 是具体执行调度任务的代码逻辑所在的地方。一般来讲所有的 <code>Executor</code> 都是单例，
接收到对应的消息后，它们对消息的内容进行解析然后调用各种 <code>Service</code> 进行执行。<code>Executor</code>
根据自己的需要还可以进一步生成新的 <code>TaskMessage</code> 传输给 <code>ControlActor</code>， 从而 Spawn 出新的任务</li>
<li><code>Scheduler</code> 是定时器，它定时地生成一些消息传递给 <code>ControlActor</code> 从而达到定期执行任务的目的</li>
</ol>
<p>除了以上的几个部分，调度器还有一类模块称为 <code>Service</code>，用来抽象一些共享的代码逻辑(比如对 AWS 常用操作的整合等)。</p>
<p>首先可以看到，在调度器当中流动的任务消息有两种: <code>ControlMessage</code> 和 <code>TaskMessage</code>。</p>
<h3 id="ControlMessage"><a href="#ControlMessage" class="headerlink" title="ControlMessage"></a>ControlMessage</h3><p><code>ControlMessage</code> 是一类用来维护和管理调度器状态的消息，它指示 <code>ControlActor</code> 执行一些消息的维护过程。
比如说 <code>Recover</code> 消息指示 <code>ControlActor</code> 从 DynamoDB 当中抽取任务消息的状态以查看是否有需要恢复的任务。
如果有，它会将这些任务分发给下游执行。<code>ControlMessage</code> 只会由 <code>ControlActor</code> 执行且不会被记录到 DynamoDB 上。</p>
<p><code>ControlMessage</code> 在 Scala 被定义为一系列的 Case Class。</p>
<h3 id="TaskMessage"><a href="#TaskMessage" class="headerlink" title="TaskMessage"></a>TaskMessage</h3><p><code>TaskMessage</code> 是描述实际调度任务的消息(如指示 Kylin 进行一次 Cube 构建等)。它的 Scala 类定义如下:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">TaskMessage</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">  uid: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  hashKey: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">  data: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]</span></span></span><br><span class="line"><span class="class"><span class="params"></span>) <span class="keyword">extends</span> <span class="title">ConsistentHashable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">blocking</span> </span>= hashKey == <span class="literal">null</span> || hashKey.isEmpty</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">consistentHashKey</span> </span>= <span class="keyword">if</span> (hashKey == <span class="literal">null</span>) <span class="string">""</span> <span class="keyword">else</span> hashKey</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>TaskMessage</code> 包含一个 <code>uid</code> 用来全局唯一地标记一个消息，<code>name</code> 字段指定了 <code>Executor</code> 的名称，
<code>hashKey</code> 字段用来提供给 <code>ConsistentHashingRouter</code> 作为哈希的参考，一般是相关 Cube 的名称。
如果<code>hashKey</code> 的值是空的，我们就认为这个这个任务是阻塞的，也就是说在执行它之前，所有其他的任务都要结束，
在它执行完成之前，其他任务都需要等待。<code>data</code> 字段是一个 <code>Map[String, String]</code> 类型的字典，
用来保存一个任务消息的具体参数。</p>
<p>受函数式编程思想的影响，所有的 <code>TaskMessage</code> 都是 Immutable 的。也就是说一旦被构建出来，
一个 <code>TaskMessage</code> 所包含的任何字段都不会改变，因此可以保证在整个处理流程当中任务消息本身不存在副作用。</p>
<p>然而 <code>TaskMessage</code> 在运行过程中为了记录和恢复的需要，存在一个生命周期的概念。也就是说这类消息在生成之后，
会经历 <code>init</code>、<code>running</code>、<code>finish</code> 或 <code>error</code> 等几个生命周期。<code>ControlActor</code>
通过查询一个任务消息的生命周期状态来决定在重启恢复时是否需要恢复一个任务。下图展示了一个 <code>TaskMessage</code>
在处理流程各个部分生命周期的变化:</p>
<p><img src="/img/kylin-scheduler/task-message-life-cycle.png" alt="Task Message Life Cycle"></p>
<p>简单来说，一个任务消息在进入 <code>ControlActor</code> 后会被转化为 <code>init</code> 状态，经过分发到达 <code>TaskActor</code> 后，
会在实际执行前被修改为 <code>running</code> 状态，在执行结束后根据执行状况可能被标记为 <code>finish</code> 或 <code>error</code> 状态。
这些状态会和消息定义本身一起被直接更新到 DynamoDB 当中以备之后查询利用。在这里，我们没有使用
<a href="https://en.wikipedia.org/wiki/Write-ahead_logging" target="_blank" rel="noopener">Write Ahead Logging</a> 的方式记录这些消息状态的变化，
因此在某些情况下仍然可能出现记录丢失等问题。但是考虑到实现的简洁性和实际需要，目前的解决方案应该足够稳定了。</p>
<p>在 <code>TaskMessage</code> 进入执行状态之前会先利用 <code>GlobalLockService</code> 获得执行锁。我们目前使用一个简单的读写锁实现我们的需求:
非阻塞任务将会尝试获得读锁，因此非阻塞任务可以并行执行。阻塞任务将会试图获得写锁，
因此阻塞任务和任何其他任务都是互斥的。</p>
<h3 id="u4EFB_u52A1_u7C7B_u578B_u548C_Executor"><a href="#u4EFB_u52A1_u7C7B_u578B_u548C_Executor" class="headerlink" title="任务类型和 Executor"></a>任务类型和 Executor</h3><p><code>TaskMessage</code> 的类型一一对应于不同的 <code>Executor</code>。接下来我们结合不同的 <code>Executor</code> 来介绍不同调度任务的类型。</p>
<p>任务调度最重要的两个类型是 <code>PlanDataRefresh</code> 和 <code>PlanCubeMaintenance</code>。
这两个任务并不具体执行需要完成的调度目标，而是通过请求 Kylin、AWS 等 <code>Service</code> 获得对当前系统状态的了解，
通过这些信息决定如何执行真正的调度任务。这两个任务在执行之后将会 Spawn 出新的消息任务导回 <code>ControlActor</code> 等待执行。</p>
<p><code>PlanDataRefresh</code> 用来规划数据的刷新，它会先生成 <code>HiveTableRefresh</code> 任务用于刷新上一个小时进来数据的 Hive 表，
之后会根据当前时间片段覆盖的 Segment 来决定激发什么类型的 Cube 构建任务:</p>
<ol>
<li>当前处理的时间片段没有 Segment 覆盖，将会生成一个长度为 4 个小时的时间片段并在之上激发一个 <code>KylinCubeBuild</code> 任务</li>
<li>当前处理的时间片段已经有 Segment 完全覆盖，将会针对覆盖这一时间片段所有的 Segment 执行 <code>KylinCubeRefresh</code> 任务</li>
<li>在上一种情况之外，如果处理的时间片段有一部分没有被覆盖，将会在没有覆盖的部分激发 <code>KylinCubeBuild</code> 任务 </li>
</ol>
<p><code>PlanDataMaintenance</code> 任务用来扫描指定 Cube 的 Segment 和 <code>HiveTableRefresh</code> 任务执行的情况，
根据所得信息决定是否进行一系列的维护操作。主要进行的操作有:</p>
<ol>
<li>通过 Kylin API 获得 Cube 所有 Segment 的覆盖情况。如果存在没有被覆盖到的缺口，则激发 <code>KylinCubeBuild</code> 任务弥补缺口</li>
<li>通过查询 DynamoDB 当中 <code>HiveTableRefresh</code> 任务近期执行的状况。如果发现没有执行过 Hive 表刷新的时间窗口，
则在这些窗口上执行 <code>HiveTableRefresh</code> 和 <code>KylinCubeRefresh</code> 等任务</li>
<li>根据 Cube 所有 Segment 的时间片段分布情况，决定是否进行 Segment 的 <code>MERGE</code> 操作。如果需要进行合并，
则激发 <code>KylinCubeMerge</code> 任务</li>
</ol>
<p>根据观察，Strikingly 的用户最常查询的数据为最近一周左右的，我们可以根据这一特点，按照过去距今时间的长短设定 Segment
数量的大小，以使得密集查询区间内的 Segment 比较少，又不至于过于频繁地激发合并操作。
Cube 的 Segment 数量采用如下的策略进行分配，以使得每一个 Cube 的 Segment 数量维持在 10 个左右。</p>
<p><img src="/img/kylin-scheduler/segment-merge-strategy.png" alt="Segment Merge Strategy"></p>
<p>在每一个时间段内，决定如何合并 Segment 则是通过一个简单的贪心算法实现的。我们首先将时间段均匀划分为三个桶，
按照时间顺序尽可能多地向一个桶里放置 Segment，如果一个 Segment 不能被放进前面的桶，再将其放到新的桶中。
下图展示了这一过程:</p>
<p><img src="/img/kylin-scheduler/segment-merge-algorithm.png" alt="Segment Merge Algorithm"></p>
<p>值得注意的是，像 <code>KylinCubeBuild</code>、<code>KylinCubeRefresh</code> 这样的任务会监控对应任务的执行状态，只有当 Kylin
当中对应的任务执行完成之后才会结束。由于 Kylin 的 API 是异步的，我们通过循环等待的方法等待任务的结束。
这样也可以保证任务在并行状态下的有序协调执行。同时，这些任务在结束时也会通过 AWS SDK 获得 Kylin 的 Query 节点的地址信息，
通过调用 Kylin 有关 Cache 管理的 API 直接广播通知状态的改变，从而取消了在 Kylin 的 Job 节点对 Query 节点地址信息的依赖，
使得 Query 节点可以 Auto Scale。</p>
<p>另外两个值得介绍的任务是 <code>KylinMetadataBackup</code> 和 <code>KylinHBaseTableCleanup</code>。这两个任务之前只能通过调用 Kylin
的命令行工具执行。通过查看 Kylin 的源代码，我们发现这两个任务较为简单，可以直接在我们的调度器当中实现。</p>
<p><code>KylinMetadataBackup</code> 任务用于备份 Kylin 的元信息。Kylin 的元信息除了一些基本配置之外，还包括每一个 Cube、
Segment 和 Job 等的定义和构建信息等。默认情况下 Kylin 将所有的元信息保存在 HBase 上的 <code>kylin_metadata</code> 表中，
在调度器当中实现备份功能的原理是直接将 HBase 的 Client 集成进来，通过 Scan 这一 HBase 表，将每一条记录 Dump
下来。Kylin 的元信息都是以文件路径和 JSON 内容的形式存在的。我们直接以文件目录的方式将这些数据打包成 GZ 包。
最后生成的 GZ 包将会直接被上传到 S3。 </p>
<p><code>KylinHBaseTableCleanup</code> 任务用于清理多余的 HBase 表。这是因为在某些情况下(如 Cube Refresh、系统故障退出等)
Kylin 构建任务产生的中间表或过期的表会遗留在 HBase 当中。而 HBase 存在表数过多会拖慢访问速度的问题，
因此必须定期清理这些表。Kylin 清理这些表的逻辑也很简单。那就是在没有任务执行的情况下扫描所有 Cube 和 Segment 等，
过滤出没有被任何 Cube、Segment 或 Job 引用的 Kylin 数据表，然后将这些表清理掉。我们在调度器当中实现了类似的功能，
通过 <code>HBaseAdmin</code> 和 Kylin API ，我们找出所有没有用的表，在第一次清理时先将这些表 Disable，第二次再删除。
这样可以留出一段时间作为缓冲，防止错误的数据删除。</p>
<p>显而易见，上述两个任务都需要阻塞所有其他任务的执行。因此它们的 <code>hashKey</code> 都为空。</p>
<p>有关任务类型方面最后值得一提的是，只有前面提到的 Plan 类型的任务和两个 Kylin 相关的 Backup 和 Cleanup
以及 <code>ControlMessage</code> 会被 <code>Scheduler</code> 定期生成。其他的任务都是由这些任务产生的衍生任务。</p>
<h3 id="u5176_u4ED6"><a href="#u5176_u4ED6" class="headerlink" title="其他"></a>其他</h3><p>除了调度器本身的实现，我们还使用了 <a href="https://newrelic.com/" target="_blank" rel="noopener">New Relic</a> 的 Application Performance Monitor 服务。
通过使用 New Relic 提供的 Java Agent，可以在云上对我们运行的 JVM 实例进行监控和 Profiling，
大大方便了我们搜集线上服务运行信息的效率。通过 New Relic 收集的数据，可以对各个任务执行的时间和代码执行瓶颈进行分析，
从而指导进一步的策略设计和代码优化工作。</p>
<h2 id="u603B_u7ED3_u4E0E_u5C55_u671B"><a href="#u603B_u7ED3_u4E0E_u5C55_u671B" class="headerlink" title="总结与展望"></a>总结与展望</h2><p>上面就是我们为 Kylin 数据处理平台全新设计的集中式任务调度系统。它满足了我们对数据平台调度器定制化、
自动化和健壮性的需求，现在已经开始进行局部上线和测试。目前来看，
我们的调度系统和数据平台还有以下一些需要提高的地方:</p>
<ol>
<li>调度器目前无法手动提交任务。虽然新的调度器引入了对任务并发更好的控制，保证了相同和不同 Cube 的任务可以协调执行，
但有时手动执行任务仍然无法避免。更好的实践显然是将调度器作为提交任务的唯一入口。
一种可能的解决方案是为调度器实现 Web 接口，从而使得人工的操作也可以通过调度器执行</li>
<li>目前使用 Keen IO 和 Hive 协调工作的解决方案过于复杂且健壮性差。由于网络延迟等原因，数据从 Keen IO
到达数据平台再到构建结束仍然具有很大的延迟和不确定性，晚到的数据本身也增加了系统实现的难度。
可能的解决方案包括精简 Hive 表流程、利用 <a href="https://kafka.apache.org/" target="_blank" rel="noopener">Kafka</a> 或
<a href="https://aws.amazon.com/kinesis/" target="_blank" rel="noopener">AWS Kinesis</a> 等消息队列服务传输信息以及自行收集用户访问数据等</li>
<li>以 Kylin 为基础的数据平台虽然很好的解决了用户海量查询的问题，但是实时性较差。即使使用 Kylin 的 Kafka 
构建模式仍然无法实现亚分钟级别的实时数据查询。
为了解决这一问题，一种思路是引进 <a href="https://github.com/Netflix/atlas" target="_blank" rel="noopener">Netflix Atlas</a>、
<a href="https://github.com/facebookincubator/beringei" target="_blank" rel="noopener">Facebook Beringei</a> 或 <a href="https://clickhouse.yandex/" target="_blank" rel="noopener">Yandex ClickHouse</a>
这样的时间序列数据库，用于取代 Kylin 满足对短时数据的实时查询需求</li>
</ol>
<p>就我个人来讲，在加入 Strikingly 转向数据平台相关的工作之后，接触并深入学习了 Scala、Hadoop、Kylin、HBase、Akka、AWS
等多种技术和工具，可谓是收获颇丰。希望以后能继续在数据平台这一方向取得更多进步。</p>
<p>最后，我司的数据平台工程师仍然有职位空缺，
可以点击<a href="https://github.com/strikingly/hiring/blob/master/job-descriptions/data-platform-engineer.md" target="_blank" rel="noopener">这里</a>查看 JD
和投递简历。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最近加入 <a href="https://strikingly.com" target="_blank" rel="noopener">Strikingly</a> / <a href="https://sxl.cn" target="_blank" rel="noopener">上线了</a> 光荣地成为了一名数据平台工程师，
投身于大数据平台开发的工作当中。这两个月来，通过设计和实现一个 AWS 的 Kylin 数据仓库调度系统，
收获很多，借此机会总结一下。</p>]]>
    
    </summary>
    
      <category term="Scheduler" scheme="https://io-meter.com/tags/Scheduler/"/>
    
      <category term="Kylin" scheme="https://io-meter.com/tags/Kylin/"/>
    
      <category term="AWS" scheme="https://io-meter.com/tags/AWS/"/>
    
      <category term="Scala" scheme="https://io-meter.com/tags/Scala/"/>
    
      <category term="Cloud" scheme="https://io-meter.com/tags/Cloud/"/>
    
      <category term="Big Data" scheme="https://io-meter.com/tags/Big-Data/"/>
    
      <category term="Hadoop" scheme="https://io-meter.com/tags/Hadoop/"/>
    
      <category term="EMR" scheme="https://io-meter.com/tags/EMR/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[从 Immutable 到 Log-Structured Merge Tree]]></title>
    <link href="https://io-meter.com/2017/08/06/from-immutable-to-lsmt/"/>
    <id>https://io-meter.com/2017/08/06/from-immutable-to-lsmt/</id>
    <published>2017-08-06T04:49:25.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>说起 Immutable Data Structure，浮现在人们脑海里的可能是 Scala 和 Clojure 或者 ImmutableJS
等语言和库所提供的数据结构。不过，今天这篇文章则是想要通过介绍实现不可变数据结构的一些思路，
带领大家了解另一种具有巨大应用价值的数据结构：Log-Structured Merge Tree。</p>
<a id="more"></a>
<h2 id="Immutable_Data_Structure"><a href="#Immutable_Data_Structure" class="headerlink" title="Immutable Data Structure"></a>Immutable Data Structure</h2><p>在很多编程语言当中，都包含一些不可以被修改的数据结构，比如 Python 里的字符串和元组类型等。
这些数据类型都不能进行修改操作。或者说，每次修改这类对象，都会得到一个新的对象，
而原来的对象不会被改变。这样的数据结构我们称为不可变数据结构(Immutable Data Structure)。</p>
<p>不可变数据结构在很多方面都拥有重要的应用价值，比如说：</p>
<ol>
<li>实现撤销功能。由于不可变数据结构每次操作都产生新的对象，那么一个简单的想法就是我们可以将多个修改产生的对象组织起来，
在实现撤销时直接通过调出之前的对象来恢复原来的状态</li>
<li>在函数式编程的范畴里，因为对不可变数据结构的操作都会产生新的对象，因此以它们为参数调用函数不会产生副作用，
这样的特性既满足了函数式编程的要求，也降低了程序因副作用产生难以调试的 Bug 的可能性</li>
<li>在并发编程中，得益于不可变数据结构的稳定性，避免了共享访问时的互斥问题，在很大程度上可以降低并行程序设计的难度。
稍后我们还会看到，不可变数据结构还是无锁数据结构实现的一种重要思路</li>
<li>不可变数据结构因其不可变的特性，在进行树形比较的时候可以简化比较操作的次数，提高比较的性能。
适用于 React 应用的 ImmutableJS 就利用了这一点</li>
</ol>
<p>Python 中的字符串和元组类型在每次修改时都会复制自身从而产生新的对象。
这种实现方法虽然比较简单，但是在时间和内存空间的消耗上都比较大。像 Scala 和 Clojure
这样的编程语言实现了更为复杂的数据结构(如 Vector Trie 或 HAMT)，从而使得修改之后的对象可以节约很多内存空间，
在性能上也不会有太大的损失。</p>
<p>在这里我们不讨论 Immutable 数据结构具体的实现细节，而是通过两个简单的例子来介绍这类数据结构实现的简单思路。
稍后我们还会看到，版本控制工具 Git 的内部实现中就恰好应用了这两个技巧。</p>
<h3 id="Immutable_Stack"><a href="#Immutable_Stack" class="headerlink" title="Immutable Stack"></a>Immutable Stack</h3><p>首先来看第一个例子。我们知道 Stack (栈)是一种先进后出的容器，它支持两种基本操作:</p>
<ol>
<li>在栈顶插入一个元素</li>
<li>从栈顶取出一个元素</li>
</ol>
<p>在这个基础上，我们想要实现另外两个功能，从而使得我们的栈具有实现撤销功能(或者说快速查询之前版本的能力)。
具体来说就是：</p>
<ol>
<li>每一次插入和删除操作之后，可以为当前栈中元素的内容指定一个 History ID</li>
<li>指定之前的某一个 History ID，可以快速的恢复栈在那一时刻包含元素的状态</li>
</ol>
<p>这一问题看似不好下手，其实在采用链表来实现栈的情况下，有很优雅的解决方案。
下图展示了一个由链表表示的空栈:</p>
<p><img src="/img/immutable/immutable-stack-head-0.png" alt="Empty Stack"></p>
<p>接下来我们向栈中压入几个元素，得到的栈的状态如下:</p>
<p><img src="/img/immutable/immutable-stack-head-1.png" alt="Push"></p>
<p>那么出栈操作怎么实现呢？我们把指向栈顶的头向后移动几个元素就可以了:</p>
<p><img src="/img/immutable/immutable-stack-head-2.png" alt="Pop"></p>
<p>从新的位置开始插入其它的元素呢？其实只是在栈中开启一个新的分支:</p>
<p><img src="/img/immutable/immutable-stack-head-3.png" alt="Push"></p>
<p>可以看到，我们的 Immutable Stack 相比传统链栈的实现，唯一的区别就是每次改变 HEAD 指针的时候，
我们都用构造一个新的指针来代替，这样通过原来的 HEAD 指针，我们访问到的总是栈在原来时刻的状态，
而从新的指针开始，得到的就是新的状态了。</p>
<p>这一实现方案可以说是相当优雅的。为了实现纪录历史的功能，我们每次操作只多消耗一个 HEAD 指针的空间。
我们把这些 HEAD 指针保存在某一容器中，未来就可以通过其与 History ID 的对应关系来查找它们，
而恢复一个 History ID 所指代的状态快照，只需要从对应的 HEAD 指针开始访问就好了，是一个非常省时且简单的操作。</p>
<h3 id="Immutable_Tree"><a href="#Immutable_Tree" class="headerlink" title="Immutable Tree"></a>Immutable Tree</h3><p>接下来研究第二个例子。树结构可以说是计算机程序当中非常常用的一种数据结构，文件系统、数据层级等等的表示都依赖于树的实现。
下图展示了一棵用于表示文件系统的树。</p>
<p><img src="/img/immutable/tree-structure.png" alt="Tree Structure"></p>
<p>为简便起见，我们假定树的基本操作是如下的三种：</p>
<ol>
<li>在树的某个位置添加一个新的节点</li>
<li>删除树的某个叶子节点</li>
<li>修改树的某个节点</li>
</ol>
<p>在很多应用中，除了上面的三种操作，撤销功能也是非常重要的。也就是说，我们有时候想要容易地将树的状态恢复到之前的一个纪录。
如前文所述，由于不可变数据结构每次都会产生新的对象，它的一大应用就是实现撤销的功能。但是对于一棵树来说，
如果每次都把每个节点复制并保存下来，在时间和空间花费上都非常不经济。这个问题就是我们的 Immutable Tree
数据结构要解决的问题。</p>
<p>下图展示了解决空间消耗问题的一种思路:</p>
<p><img src="/img/immutable/immutable-tree.png" alt="Immutable Tree"></p>
<p>可以看到，当左边树的一个叶子节点被修改之后，我们既不全盘复制所有的节点，也不在原来的节点上进行修改，
而是仅仅将被修改位置一直到根节点的一条路径复制出来再进行修改。在右边虚线圈中的几个节点就是新生成的节点，
这些节点仍然会有指向原来节点的指针，只有被修改路径上的指针是指向新的节点。</p>
<p>使用这种技巧，每次我们只会复制一条路径上的几个节点，比复制全部节点已经有很大提高了。
新产生的对象和原来的对象共享了绝大部分内部节点，而每次修改一定会产生一个新的根节点。
使用不同的根节点作为开始，我们访问到的就是树在不同时刻的状态。</p>
<p>这种利用树形结构的特点来共享内部节点是绝大部分不可变数据结构的基本原理，譬如 Scala、Clojure 和
ImmutableJS 实现的 Vector Trie 和 HAMT 本质上就是树形结构。</p>
<h3 id="u6848_u4F8B_u7814_u7A76_3A_Git__u7684_u5BF9_u8C61_u6A21_u578B"><a href="#u6848_u4F8B_u7814_u7A76_3A_Git__u7684_u5BF9_u8C61_u6A21_u578B" class="headerlink" title="案例研究: Git 的对象模型"></a>案例研究: Git 的对象模型</h3><p>在看完上面的文章之后，对 Git 比较熟悉的朋友可能已经发现了这两个数据结构和 Git 的相似之处。
诚然，Git 这样的版本控制系统恰巧需要实现的就是文件系统历史状态的纪录和恢复。</p>
<p>打开任意一个 Git 仓库，我们会发现仓库下有一个名为 <code>.git</code> 目录，这个目录的简单结构如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.git</span><br><span class="line">├── HEAD</span><br><span class="line">├── objects</span><br><span class="line">│   ├── 0c</span><br><span class="line">│   ├── 0d</span><br><span class="line">│   ├── info</span><br><span class="line">│   └── pack</span><br><span class="line">├── refs</span><br><span class="line">│   ├── heads</span><br><span class="line">│   └── tags</span><br></pre></td></tr></table></figure>
<p>其中的<code>objects</code>目录就是 Git 储存自己的内部数据对象的位置。无论是被 Commit 过的文件、一个 Commit
对象还是对目录结构的描述都存放在这个地方。在执行 Git 的版本切换和查询操作的时候，Git
就是从这个目录当中读取数据重建历史状态的。</p>
<p>如果直接读取这个目录下面文件的内容，会发现它们都是二进制，这是因为 Git 对这些内容进行了压缩。
我们可以使用下面的命令快速地获取某个 Hash 值所代表的对象的内容:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git cat-file -p 5b67fd90081</span><br></pre></td></tr></table></figure>
<p>接下来我们来看一个非常简单的 Git 仓库，它的提交历史如下图所示:</p>
<p><img src="/img/immutable/git-repo-history.png" alt="Git Repo History"></p>
<p>在第一个 Commit 里我们添加了一个文件<code>hello.txt</code>和一个文件夹<code>foo</code>，
文件夹<code>foo</code>下面还有两个文件<code>bar</code>和<code>lorem</code>。在第二个 Commit 当中，我们修改了文件<code>foo/lorem</code>。</p>
<p>接下来如果我们使用<code>git cat-file -p 29fa657b6dd65a6</code>命令来查看最新的 Commit，将会得到如下的内容:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tree b0b36b9811c2bd5a208a263236518628972ed32a</span><br><span class="line">parent 3a90366280491ada2d1d56f46e9120ae63c2d945</span><br><span class="line">author chase &lt;i@chasezhang.me&gt; 1502006619 +0800</span><br><span class="line">committer chase &lt;i@chasezhang.me&gt; 1502006619 +0800</span><br><span class="line"></span><br><span class="line">Fill lorem</span><br></pre></td></tr></table></figure>
<p>从上面的内容可以看出，一个 Commit 除了纪录作者和 Commit Message 之外还有两个重要的字段，
<code>tree</code>和<code>parent</code>。其中<code>parent</code>字段给出的 Hash 值恰好和这个 Commit 前一个Commit 的值相同，
它就是每个 Commit 指向上一个 Commit 的指针。那么<code>tree</code>字段的作用是什么呢？
我们使用<code>git cat-file -p b0b36b9811c2</code>来查看一下他的内容:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">040000 tree 91288d89327ac71ad84fa4eb08586b2b78d8cafb    foo</span><br><span class="line">100644 blob 980a0d5f19a64b4b30a87d4206aade58726b60e3    hello.txt</span><br></pre></td></tr></table></figure>
<p>可以看出这个对象给出了当前文件目录的一个描述，其中子目录<code>foo</code>仍然是一棵树，而<code>hello.txt</code>是一个文件。
前面提到，第一个 Commit 和第二个 Commit 只有<code>foo/lorem</code>这个文件修改了，那么 Git 是如何纪录这个修改的呢？
我们来看第一个 Commit 的 tree 字段的内容:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">040000 tree 2c90d818605361f15a66019953e13fdf86aacf6c    foo</span><br><span class="line">100644 blob 980a0d5f19a64b4b30a87d4206aade58726b60e3    hello.txt</span><br></pre></td></tr></table></figure>
<p>两相对比，没有改动的<code>hello.txt</code>在两个 Commit 对应的 Tree 里指向的都是同一个对象，
而<code>foo</code>文件夹则指向了新的对象(Hash 值不同)。如果近一步查看<code>foo</code>目录，也会观察到类似的现象。
也就是说，Git 的内部对象的组织，就是利用了前面介绍的两个简单的算法。Git 的 Commits 就对应于 Immutable Stack，
而 Git 的文件系统就是使用 Immutable Tree 来纪录的。</p>
<p><img src="/img/immutable/git-object-model.png" alt="Git Object Model"></p>
<h2 id="Lock-free_Data_Structure"><a href="#Lock-free_Data_Structure" class="headerlink" title="Lock-free Data Structure"></a>Lock-free Data Structure</h2><p>为了讨论我们最终的主题，关于无锁数据结构(Lock-free Data Structure)的一些知识是必要的。</p>
<p>简单来说，无锁数据结构是一类可以安全地使用多线程并发访问和修改的数据结构，
而它们从设计上避免使用锁这一同步工具，在某些应用场合下相比使用加锁的数据结构具有更好的访问性能，
也避免了因为锁的存在而产生的死锁和 CPU 停顿问题，因此被广泛应用于强并发、高实时性要求的领域。</p>
<p>无锁数据结构是一个非常大的主题，有多种多样的实现方法，在这里无法详尽的叙述。
在本文的语境下，主要关注的是一类通过结合不可变数据结构和编程语言当中原子操作这种同步工具的实现方法。</p>
<p>原子操作是由编程语言或者操作系统提供的一系列同步元语。一个原子操作在执行的时候被认为是原子的，
也就是说它要么能够成功之行，要么执行失败。一个典型的例子是<code>CompareAndSet</code>元语，
这个原子操作将一个变量的当前值和某一指定值进行比较，如果结果相同，则将这个变量设为另一个值。
很显然，如果是简单地使用判断语句进行判断，在并发执行的时候并不能保证结果的有效性。
这是因为比较操作和赋值操作是两个独立的操作，另外一个线程可能恰好在比较成功之后、变量赋值之前修改了目标变量的值。
因此，提供一个原子操作来实现这一功能是很有价值的。</p>
<p>那么，原子操作是怎么和不可变数据结构结合起来的呢？以前文的 Immutable Tree 为例，
首先我们使用一个原子引用类型的指针指向一个 Immutable Tree 的对象，使得所有对这一对象的访问都要通过这一引用，
如下图所示:</p>
<p><img src="/img/immutable/lock-free-data-structure-initial.png" alt="Lock-free Data Structure"></p>
<p>由于对于 Immutable Tree 的任何修改操作都不会改变原来的节点。
因此，如果有一个对树的修改操作到来，我们可以安全地开始对树的操作而不需要对整个数据结构加锁，
这一修改完全是平行于原来的数据结构，因此对于读操作没有任何阻塞。</p>
<p>当修改完成之后，我们可以对我们的引用执行一个原子的交换操作，从而使他指向新的根节点，如下图所示:</p>
<p><img src="/img/immutable/lock-free-data-structure-transit.png" alt="Lock-free Data Structure: Reference Transition"></p>
<p>由于对于引用的操作是原子的，因此在原子操作成功之前，任意线程发起的读请求仍然获得的是老的内容，
而一旦这一操作在瞬间完成，所有新的访问都将获得新的内容。不会有任何一个线程会获得中间状态，
这也就保证了多线程环境下的数据安全。</p>
<p><img src="/img/immutable/lock-free-data-structure-finished.png" alt="Lock-free Data Structure: Tranistion Finished"></p>
<p>当原子操作执行结束之后，我们可以再清理老的数据结构遗留下来的内存，这一操作也完全可以异步地在后台执行。</p>
<p>由上面几个步骤的示意图我们可以看到，使用原子操作的无锁数据类型的一些基本的思路是:</p>
<ol>
<li>在进行数据修改操作时尽量不改动之前的部分，因此在修改进行的同时对象仍然是可读的，
而一般的加锁数据结构，在修改的同时往往也要阻塞读操作</li>
<li>当修改操作完成之后，使用一个单一的原子操作提交修改，从而使修改生效。这样，
即使修改操作十分复杂，最后是否能够成功完成还是取决于一个单一的操作，
这种四两拨千斤的方法消除了因为意外情况导致操作中断而产生的不可知的结果</li>
<li>改变引用的原子操作几乎是瞬时的，修改以及修改之后进行清理工作这两部份内容都可以异步地执行，
不影响对数据结构的访问</li>
</ol>
<p>有的读者可能会想到，如果有两个修改操作同时进行从而导致了结果的相互覆盖该怎么办？
在实践当中，修改的提交操作往往需要通过<code>CompareAndSet</code>这一元语检查对象有没有在自己进行修改的期间被别人修改过。
如果检查失败，修改操作需要被重复地执行。实际上，在写入压力非常大的情况下，有的线程可能一直无法提交自己的修改。
因此，实际上还有一种被称为 Wait-free 的数据结构被研究出来解决这一类问题。</p>
<h2 id="Log-Structured_Merge_Tree"><a href="#Log-Structured_Merge_Tree" class="headerlink" title="Log-Structured Merge Tree"></a>Log-Structured Merge Tree</h2><p>在本文的最后一个部分要讨论一个比较复杂的数据结构，Log-Structured Merge Tree (简称 LSMT)。
为了更好的介绍它的价值，我们先提出一个非常困难的课题: 如何设计实现一个大数据仓库的储存系统。</p>
<p>设计一个这样的一个储存系统是非常困难的，原因在于要实现以下设计目标:</p>
<ol>
<li>支持对数据字段的增删改查，数据字段的长度可以是变长的</li>
<li>支持安全的并发读写，并发的读写操作必须可以高性能地执行</li>
<li>超高的稳定性，即使在数据写入的中途因故障中断，也不可以丢失、损坏已有的数据</li>
</ol>
<p>我们的储存系统在实现的过程当中面临以下挑战:</p>
<ol>
<li>储存空间的组织问题: 由于数据的长度是可变的，如果一个字段的值一开始只有10个字节长，随后要被扩展到数百个字节，
而前后已经没有空闲的空间要怎么办？由于数据支持删除，如果经过一段时间，储存空间当中存在出现了很多空洞该怎么回收？</li>
<li>并发实现的问题，因为所有这些增删改查的操作都是并发执行的，怎样才能保证这些并发有序地执行从而不会破坏数据？
结合上一个问题，我们怎么样才能安全的回收空闲空间而不会干扰其他操作的执行？</li>
<li>在数据库设计的语境里，即使是单一的一个写硬盘操作也不一定能够被认为是原子的。由于缓冲区的存在和硬件的具体实现不同，
几块数据可能不是以期待的顺序被写入硬盘。此外，即使只有一条记录，也可能在写入一半的时候被断电等因素打断。
我们的数据仓库要具备能在这种情况下也不损坏和丢失已有数据，尽量降低损失的能力</li>
</ol>
<p>LSMT 就是为了解决这一些问题而被设计出来的。首先，LSMT 基于一个假设: 我们的数据可以在逻辑上以树形组织起来，
就比如在数据库当中，数据可能按照主键以 B+ 树的形式组织起来。其次，LSMT
还吸收了不可变数据结构和无锁数据结构的一些思想，用来保证并发安全性和稳定性。
下图展示了一个 LSMT 数据结构的组织框架:</p>
<p><img src="/img/immutable/log-structure-merge-tree.png" alt="Log-Structured Merge Tree"></p>
<p>可以看到 LSMT 把所有的数据组织成大小接近的文件块，每个文件块内的记录通过指针引用形成树状的结构，
从而把原始的树形数据结构表示出来。最后 LSMT 还会在外部储存一个指向 Root 节点的指针。
从图中可以看出，LSMT 的写入操作只会有追加一种，对于很多储存介质来说，追加操作要比随机写入快很多，
这也是 LSMT 的优点之一。</p>
<p>接下来我们来看如何把对逻辑树进行的一次修改操作写入到储存中，下图展示了这一操作的基本原理:</p>
<p><img src="/img/immutable/log-structure-merge-tree-append-path.png" alt="Log-Structured Merge Tree: Append Modification"></p>
<p>如上图所示，借用 Immutable Tree 的实现思想，当操作执行时，我们会生成一条新的修改路径，
而原来的节点仍然在原来的位置不会被修改。之后我们所做的只是将新产生的节点一个接一个追加到文件的结尾。
追加结束之后的状态如下图所示:</p>
<p><img src="/img/immutable/log-structure-merge-tree-append-finish.png" alt="Log-Structured Merge Tree: Append Finished"></p>
<p>在上图所示的状态时，新的修改其实还没有在储存中生效，新的访问请求到来之后看到的仍然是原来的状态。
这是因为我们的 Root 指针仍然指向原来的根节点。这时就是无锁数据结构实现的思路应用的地方了。
我们可以使用一个接近原子的操作将 Root 指针改向新的根节点。</p>
<p><img src="/img/immutable/log-structure-merge-tree-change-root.png" alt="Log-Structured Merge Tree: Change Root"></p>
<p>在硬盘等储存介质上进行原子的写入并非十分容易，如果写入 Root 新值的过程被打断怎么办？
其实我们可以把 Root 指针做成类似 Log 的结构，每次只将新值追加到 Log 里，这样之前写成功的值还会得以保留，
如果有一个新值写入中断，我们还可以利用 Log 中之前记录的值恢复到一个有效的状态。
这样移动 Root 指针的操作就可以被认为是原子地执行了。</p>
<p><img src="/img/immutable/log-structure-merge-tree-change-root-finish.png" alt="Log-Structured Merge Tree: Commited"></p>
<p>可以看到，新的修改提交成功之后，老的一些记录就变成失效的了，为了清理这些失效的记录，
LSMT 还设计在后台执行清理操作，清理的操作逻辑也很简单:</p>
<p><img src="/img/immutable/log-structure-merge-tree-block-clean.png" alt="Log-Structured Merge Tree: Clean"></p>
<p>对于一个只包含失效记录的文件，将其直接删除自然是安全的。对于仍然包含有效记录但是已经存在大量失效块的文件，
我们可以采用的策略是将两个这样的文件当中的有效记录取出来合并成一个新的文件。值得注意的是，
在这一步可以重复地利用了 Immutable 和 Lock-free 的实现技巧，在不改变原来文件的情况下先生成新的合并文件，
待合并文件生成完成且生效之后，原来的两个文件就变成了只包含失效记录的文件，可以被安全的删除。</p>
<p>通过执行这样的流程和策略，即使是在高强度的并发条件下，空间的回收操作也可以较为容易地实现。
而且在回收过程当中对数据的读写都不会产生影响。</p>
<p>通过以上的介绍，我们可以看出 LSMT 很好地解决了我们所面临的储存空间组织、并发控制和稳定性等问题，
可以说是实现大数据仓库储存系统的理想数据结构和算法。实际上，包括 BigTable、Apache Cassandra 和 InfluxDB
等产品都利用了 LSMT。</p>
<p>值得注意的是，本文所介绍的只是 LSMT 最简略和基础的一些思想，和真正的 LSMT还有很大的差别。
LSMT 的完整实现还需要解决很多复杂的问题。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文从对不可变数据结构和无锁数据结构的一些简单思路的介绍开始，最终引入了在数据储存方面非常有价值的一种数据结构
Log-Structured Merge Tree 的介绍。可以看出，即使是一些非常简单的算法技巧，经过巧妙地组合之后也可以发挥非常巨大的作用。</p>
<p>同时，本文也希望通过对这些简单算法的介绍，使得各位读者能够发现和认可算法本身的价值。 
算法并不是什么“不会在工作中使用到的东西”。算法是可以为个人和社会都创造巨大收益的重要知识。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>说起 Immutable Data Structure，浮现在人们脑海里的可能是 Scala 和 Clojure 或者 ImmutableJS
等语言和库所提供的数据结构。不过，今天这篇文章则是想要通过介绍实现不可变数据结构的一些思路，
带领大家了解另一种具有巨大应用价值的数据结构：Log-Structured Merge Tree。</p>]]>
    
    </summary>
    
      <category term="Immutable" scheme="https://io-meter.com/tags/Immutable/"/>
    
      <category term="Log-Structured Merge Tree" scheme="https://io-meter.com/tags/Log-Structured-Merge-Tree/"/>
    
      <category term="Algorithm" scheme="https://io-meter.com/tags/Algorithm/"/>
    
      <category term="Data structure" scheme="https://io-meter.com/tags/Data-structure/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[A Brief Intro to Functional Programming]]></title>
    <link href="https://io-meter.com/2017/05/29/A-Brief-Intro-to-Functional-Programming/"/>
    <id>https://io-meter.com/2017/05/29/A-Brief-Intro-to-Functional-Programming/</id>
    <published>2017-05-29T07:52:34.000Z</published>
    <updated>2020-12-12T04:21:10.087Z</updated>
    <content type="html"><![CDATA[<p>近期受邀在 VMWare 上海的一个公开活动里做了一个技术分享介绍 Functional Programming，
在准备 Slides 的过程中又重新审视了一下自己对函数式编程这个主题的了解深度，
感觉又有一些收获。</p>
<a id="more"></a>
<p>这次趁着端午假期的空闲，将讲座的内容尤其是 slides 当中使用的一些容易理解的配图整理出来，
形成这么一篇博客，希望能对读者有所帮助。</p>
<h1 id="u6982_u89C8"><a href="#u6982_u89C8" class="headerlink" title="概览"></a>概览</h1><p>一开始让我去讲函数式编程，其实我是拒绝的。老实说，科技界的很多术语的内涵其实一直比较模糊。
就拿函数式编程来说，它到底是什么、涵盖了多少内容其实不是一件容易界定的事情。况且，
函数式编程尽管已经有多年的发展历史，普通的程序员们对它的认识却还是参差不齐或深有误解。</p>
<p>其中可能是最大的误解之一可能就是认为函数式编程主要是前端届在使用的范式，在其它领域没有用武之地。
就连邀请我进行讲座的主办方，也是以这样一种认知为基础，想要我在前端的语境下来准备主题。
这是我使用 ES6 作为讲座中使用的编程语言的主要原因。尽管如此，
我准备的内容绝大部分其实跟前端技术的联系并不紧密，主要的内容有两个：</p>
<ol>
<li>函数式编程的一些“奇技淫巧”，主要是闭包、惰性求值和 Y-Combinator</li>
<li>根据关于函数式编程在网络上最新的一些讨论，尤其是 Haoyi Li 老师的
《<a href="http://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html" target="_blank" rel="noopener">What’s functional programming all about</a>》
这篇文章，浅谈了一些关于函数式编程本质的东西</li>
</ol>
<p>在我准备的讲座当中还有一个有关 FP 在 React 当中体现的章节，因个人觉得不是特别重要，
在这篇文章当中就不赘述了。</p>
<h1 id="Closure"><a href="#Closure" class="headerlink" title="Closure"></a>Closure</h1><p>Closure，也就是闭包，可以说是函数式编程基础当中的基础。闭包的存在体现了函数式编程的几个重要特点：
函数是编程语言的一等成员以及高阶函数的存在。</p>
<p>关于闭包，在圈内有两句著名的格言：</p>
<blockquote>
<p>Objects are a poor man’s closures</p>
</blockquote>
<p>以及</p>
<blockquote>
<p>Closures are a poor man’s objects</p>
</blockquote>
<p>这两句话据信都出自 MIT 早期的邮件列表当中一个著名的 Thread
《<a href="http://people.csail.mit.edu/gregs/ll1-discuss-archive-html/msg03277.html" target="_blank" rel="noopener">What’s so cool about Scheme?</a>》。
肤浅地理解的话，这两句加起来其实表达了闭包和对象两种模型在某种程度上是同一的。</p>
<p>我们来看一下闭包是如何实现对象可以完成的工作的。一个最简单的例子可能是使用闭包来实现链表：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> getNode = <span class="function">(<span class="params">value , next</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="function">(<span class="params">x</span>) =&gt;</span> x ? value : next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">let</span> value = <span class="function">(<span class="params">node</span>) =&gt;</span> node(<span class="literal">true</span>);</span><br><span class="line"><span class="keyword">let</span> next = <span class="function">(<span class="params">node</span>) =&gt;</span> node(<span class="literal">false</span>);</span><br></pre></td></tr></table></figure>
<p><code>getNode</code> 函数返回了一个闭包，我们知道，闭包是一个保存了上层函数调用时的环境上下文的函数。
因此，我们传给<code>getNode</code>函数的两个参数<code>value</code>和<code>next</code>会被保存在闭包中。如下图所示:</p>
<p><img src="/img/fp/closure-as-nodes.png" alt="Closure as a node"></p>
<p>比如 C 的 <code>struct</code> 和 Java 的 <code>class</code> 中，获得一个对象的成员变量，往往是取内存地址的操作，
然而在使用闭包作为对象的时候，因为闭包本身就是个函数，我们是通过使用不同的参数调用闭包来获得不同的字段的。
譬如在这个例子里，传给闭包 <code>true</code>，函数会返回 <code>value</code>，反之则会返回 <code>next</code>。下图展示了这个过程：</p>
<p><img src="/img/fp/closures-get-value.png" alt="Closure: get value and next"> </p>
<p>可以使用闭包获得值和指向下一个节点的指针之后，这个闭包就跟普通的链表节点没什么不同了。
我们可以像使用结构体那样使用它，只不过在取值和指针的时候是通过函数调用而不是直接的取字段的方法来完成的。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> a = getNode(<span class="number">1</span>, getNode(<span class="number">2</span>, getNode(<span class="number">3</span>, <span class="literal">null</span>)));</span><br><span class="line"><span class="comment">/*  1 -&gt; 2 -&gt; 3 -&gt; null  */</span></span><br><span class="line"></span><br><span class="line">value(a); <span class="comment">// 1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> b = next(a); value(b); <span class="comment">// 2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> c = next(b); value(c); <span class="comment">// 3</span></span><br><span class="line">next(c) <span class="comment">// null</span></span><br></pre></td></tr></table></figure>
<p>一个更复杂的例子是实现链表反转，我们首先实现了一个 <code>append</code> 函数用来将一个节点追加到一个链表当中，
之后的 <code>reverse</code> 函数其实就是通过不断对自己递归地调用而完成工作的——尽管从时间复杂度上来看这个解决方案并不怎么有效，
然而它却是在完全没有对象系统和循环的前提下而实现的。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> append = <span class="function">(<span class="params">n, v</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (n === <span class="literal">null</span>) <span class="keyword">return</span> getNode(v, <span class="literal">null</span>);</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> getNode(value(n), append(next(n), v));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> reverse = <span class="function">(<span class="params">list</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (list === <span class="literal">null</span>) <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> append(reverse(next(list)), value(list));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">reverse(a) <span class="comment">// 3 -&gt; 2 -&gt; 1</span></span><br></pre></td></tr></table></figure>
<p>其实，在很多 Lisp 里面的 <code>cons</code>、 <code>car</code>、 <code>cdr</code> 等函数，实际上就对应于上面例子当中的
<code>getNode</code>、 <code>value</code>、 <code>next</code> 三个函数。在一些实现里，更是直接用闭包来实现列表的。</p>
<h1 id="Lazy_Evaluation"><a href="#Lazy_Evaluation" class="headerlink" title="Lazy Evaluation"></a>Lazy Evaluation</h1><p>在上面链表的例子之后，我们可以来看一下惰性求值的实现方法。譬如说，
我们想得到一个表示自然数这一个无穷序列的闭包。那么可能可以有如下代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> naturalNumber = <span class="function">(<span class="params">n</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">x</span>) =&gt;</span> x ? n : naturalNumber(n + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>表面上这个函数会无穷地递归自己，但是考虑到 <code>a ? b : c</code> 这样一个判断表达式当中，<code>b</code> 和 <code>c</code> 
都只有当对应的条件满足之后才会被编译器求解，无限递归的情况并不会发生。
要理解上述函数如何产生自然数的序列。我们先参照上一章的形式，展示我们所得到的闭包的结构。
如下图所示，可以看到只有一个字段<code>n</code>被保存在上下文环境中：</p>
<p><img src="/img/fp/lazy-eval-node.png" alt="Lazy Evaluation: Node"></p>
<p>在取字段方面，使用 <code>true</code> 调用函数还是可以得到当前的值<code>n</code>，那么如果我们使用 <code>false</code>
来调用函数试图获得下一个节点会发生什么呢？</p>
<p><img src="/img/fp/lazy-eval-get-value.png" alt="Lazy Evaluation: get value and next"></p>
<p>为了方便期间，我们将之前的整个闭包表示成一个小圆，把唯一的字段<code>n</code>填在小圆的中央。
下图展示了试图获取 <code>next</code> 的结果。可以看到，对包含字段<code>n</code> 的闭包取 <code>next</code> 会获得一个类似的闭包，
唯一的区别是字段的值变成了 <code>n + 1</code>。这个新的闭包实际上是对自己的递归调用，
也就是说，上述的函数通过<em>递归定义</em>的方式定义了自然数：</p>
<p><img src="/img/fp/lazy-eval-recursive-def.png" alt="Lazy Evaluation: Recusive Definition"></p>
<p>这样，我们就得到了一个惰性求值的表，这个链表虽然表示了无穷多数的序列，
但是并不会直接耗尽内存——新的值只有在需要的时候才被求解出来。上面的例子同样体现了接口或者鸭子类型的思想。
对于原来链表的<code>value</code>和<code>next</code>函数，因为我们新的<code>naturalNumbers</code>会返回同样接口的闭包，
因此我们不需要对这个惰性求值的表定义新的函数来取值和后继节点。原来的函数是直接可用的。</p>
<p>为了体现惰性求值方式的威力，我们来用 ES6 快速实现很多函数式编程语言都会给出的一个案例：
<a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes" target="_blank" rel="noopener">Sieve of Eratosthenes</a>，
也就是素数的筛法。很多语言在给出的相关例子对于初学者来说可能很难理解，
在这篇文章的稍后部分会使用图示的方法来辅助说明到底发生了什么。现在还是先看代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> nextMatch = <span class="function">(<span class="params">seq, fn</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fn(value(seq)) ? seq : nextMatch(next(seq), fn);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> filter = <span class="function">(<span class="params">seq, fn</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> mseq = nextMatch(seq, fn);</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">x</span>) =&gt;</span> x ? value(mseq) : filter(next(mseq), fn);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> sieve = <span class="function">(<span class="params">seq</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">let</span> aPrime = value(seq);</span><br><span class="line">  <span class="keyword">let</span> nextSeq = filter(next(seq), (v) =&gt; v % aPrime != <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">x</span>) =&gt;</span> x ? aPrime : sieve(nextSeq);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里我们定义了三个方法，第一个函数找到当前序列当中第一个符合函数的匹配，
第二个函数将序列中不符合条件的元素过滤掉，最后一个函数就是我们的素数筛法实现。
可以看到，后两个方法采用了和 <code>naturalNumbers</code> 一样的惰性求值的方法。
他们会返回一个新的闭包，这个闭包服从我们之前的取值和取后继节点的接口，
因此我们可以像操作链表节点一样操作他们。</p>
<p>我们定义如下的<code>take</code>方法来从这样的一个惰性的表里取出若干的元素转换成普通链表，
这样我们就可以查看这些元素的内容。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> take = <span class="function">(<span class="params">n, count</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (n == <span class="literal">null</span> || count &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> getNode(value(n), take(next(n), count - <span class="number">1</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>像下面这样调用<code>sieve</code>函数，我们就得到了所有素数的一种表示，
使用<code>take</code>来查看前五个元素，就会得到前五个素数的值。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> primes = sieve(naturalNumber(<span class="number">2</span>));</span><br><span class="line">take(primes, <span class="number">5</span>); <span class="comment">// 2, 3, 5, 7, 11</span></span><br></pre></td></tr></table></figure>
<p>这到底是如何做到的呢？作为筛法，在这里是如何把之前筛出的素数保留下来从而再反过来用于筛选后面的素数的呢？
我们先来看函数第一次调用的时候的情况。因为我们将从 2 开始的自然数的惰性序列传给了 <code>sieve</code> 函数，
所以我们第一个得到的素数显然是 2:</p>
<p><img src="/img/fp/lazy-eval-get-2.png" alt="Primes: Get 2"></p>
<p>在这里，我们用在最外层的蓝色圆圈表示一层未求解的 <code>sieve</code> 函数，用<code>filter(n)</code>表示将<code>n</code>及其倍数都过滤掉的过滤函数。
可以看到，在最初的状态下，右边代表<code>next</code>的部分，<code>sieve</code>函数只求解了一层。这种情况下我们的自然数序列现在在<code>n=3</code>的状态，
<code>filter</code>也只有一层。</p>
<p>当我们试图取<code>next</code>从而使得右边的<code>sieve</code>函数被求值一层之后，返回的仍然是一个惰性求值的<code>sieve</code>函数，
只不过发生了两个变化：</p>
<ol>
<li><code>3</code> 被从自然数序列当中取出</li>
<li><code>filter(3)</code>被叠加在<code>filter(2)</code>之上，形成了两层 filter 的情况</li>
</ol>
<p>如下图所示:</p>
<p><img src="/img/fp/lazy-eval-get-3.png" alt="Primes: Get 3"></p>
<p>接下来再次取<code>next</code>情况也是类似的，譬如我们取出了一个数 <code>p</code> ，那么就会有一层新的<code>filter(p)</code>被加入到新的<code>next</code>表示当中。
当我们取出一个和数，因为他会被之前的某一层filter过滤掉，因此每次取出的<code>p</code>一定是素数。下面是取出5的时候的情况，
可以看到，之所以4没有被取出是因为被<code>filter(2)</code>过滤掉了。</p>
<p><img src="/img/fp/lazy-eval-get-5.png" alt="Primes: Get 5"></p>
<p>以上就是通过惰性求值实现素数筛法的原理。</p>
<p>可以看到，即使是使用 JavaScript，通过一些简单的定义和纯函数的构造方法，
我们只需要很少量的代码就可以实现惰性求值的列表。这也是将闭包作为对象的威力所在。
值得一提得是，《<a href="https://mitpress.mit.edu/sicp/full-text/book/book.html" target="_blank" rel="noopener">计算机程序的构造与解释</a>》
一书中指出，Stream 其实就是惰性求值的表。
因此现在流行的很多流处理框架，如 <a href="http://reactivex.io/" target="_blank" rel="noopener">ReactiveX</a>、<a href="https://spark.apache.org/" target="_blank" rel="noopener">Spark</a>
等实现的模型，其实就是从这里开始的。有些编程语言如 Haskell 等，默认就全局地使用惰性求值来处理列表。</p>
<h1 id="Y-Combinator"><a href="#Y-Combinator" class="headerlink" title="Y-Combinator"></a>Y-Combinator</h1><p>提到 Y-Combinator，对于不了解函数式编程历史的人来讲，可能第一个想到的是硅谷著名的天使投资机构
<a href="http://www.ycombinator.com/" target="_blank" rel="noopener">YC</a>和<a href="https://news.ycombinator.com/" target="_blank" rel="noopener">Hacker News</a>。
其实，Y-Combinator 最早是由 Haskel Brooks Curry 提出的一个可以用于实现递归的组合子。</p>
<p>虽然Y-Combinator 在实际当中没有什么使用场景，但在网上有些人认为，
是否解了 Y-Combinator 是判断一个人对函数式编程是否真正入门的依据。
我觉得，了解 Y-Combinator 至少对理解计算理论和函数式编程的早期发展有很大帮助。
这反过来也会加深一个人对函数式编程本身内涵的理解。</p>
<p>我们从一个有趣的问题开始：<strong>如何只通过匿名函数实现递归？</strong>。</p>
<p>这个问题看似简单，其实却需要一些技巧才能解决。
如果你想要递归调用的函数没有名字，那么你又如何调用它呢？我们来看下面求阶乘的递归函数的例子。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> fact = <span class="function">(<span class="params">n</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">return</span> n * fact(n - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，<code>fact</code>要递归调用自己，必须要有一个名字<code>fact</code>存在。容易想到，虽然函数本身是匿名的，
但是如果我把它传给另一个函数，让他作为另一个函数的参数存在，由于参数是有名字的，那这个函数是不是就是有名字的了呢？</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> F = <span class="function">(<span class="params">f</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="function">(<span class="params">n</span>) =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">1</span>) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> n * f(n - <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里，我们得到了一个函数</p>
<p>$$F:f\rightarrow f’$$</p>
<p>这个函数接收一个函数 $f$ 作为参数，返回另一个函数 $f’$。因为 $f’$ 是一个在内部调用 $f$ 的函数，
如果 $f’=f$，那么 $f’$ 就是一个自己递归调用自己的函数，也就是我们需要的求阶乘的递归函数。
给定一个$F$，我们怎么得到我们想要的 $f’$ 呢？在数学上，使得 $F(f)=f$ (即 $f=f’$)
的参数 $f$ 被称为 $F$ 的不动点。而下面的函数 $Y$ “恰好”总是能返回这样一个 $F$ 的不动点(即 $Y(F)=F(Y(F))$)：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> Y = <span class="function">(<span class="params">F</span>) =&gt;</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> (<span class="function"><span class="params">x</span> =&gt;</span> F(<span class="function"><span class="params">v</span> =&gt;</span> x(x)(v)))(<span class="function"><span class="params">x</span> =&gt;</span> F(<span class="function"><span class="params">v</span> =&gt;</span> x(x)(v)))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样的 $Y$ 就被称为 Y-Combinator，它是由 Haskell Brooks Curry 最早发现的。</p>
<p>值得注意的是这个不动点 $f$ 是指 $F(f)$ 和 $f$ 这两个函数在他们所有参数的取值范围内每一个点的值都相同。
在数学上符合这个定义的两个函数是同一的，然而在我们的程序的执行过程当中 $F(f)$ 相较 $f$ 其实是一个新的函数。
接下来我们就可以使用一个表达式来调用我们的匿名递归函数了：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="function"><span class="params">F</span> =&gt;</span> (<span class="function"><span class="params">x</span> =&gt;</span> F(<span class="function"><span class="params">v</span> =&gt;</span> x(x)(v)))(<span class="function"><span class="params">x</span> =&gt;</span> F(<span class="function"><span class="params">v</span> =&gt;</span> x(x)(v))))(<span class="function"><span class="params">f</span> =&gt;</span> (<span class="function"><span class="params">n</span> =&gt;</span> n == <span class="number">1</span> ? <span class="number">1</span> : n * f(n - <span class="number">1</span>)))(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>Y-Combinator 是建立在最早由 Alonzo Church 提出的 <a href="https://en.wikipedia.org/wiki/Lambda_calculus" target="_blank" rel="noopener">λ−calculus</a>
的框架上的。λ−calculus 是一种和<a href="https://en.wikipedia.org/wiki/Turing_machine" target="_blank" rel="noopener">图灵机</a>等价的计算模型。
最早作为解决可计算性问题的一个模型提出。Church 同时还提出了 Church Numerals (邱奇计数)
这种使用函数来表示自然数的表示方法。</p>
<p>此外，有三门编程语言以 <a href="https://en.wikipedia.org/wiki/Haskell" target="_blank" rel="noopener">Haskell</a>
<a href="https://en.wikipedia.org/wiki/Brooks_(programming_language" target="_blank" rel="noopener">Brooks</a>
<a href="https://en.wikipedia.org/wiki/Curry" target="_blank" rel="noopener">Curry</a> 命名，Curry 用作动词得到的
<a href="https://en.wikipedia.org/wiki/Currying" target="_blank" rel="noopener">Currying</a> 同时又翻译作柯里化，
也是在函数式编程当中非常重要的一个概念。</p>
<p>下面是函数式编程相比于命令式编程发展的历史示意图：</p>
<p><img src="/img/fp/history.png" alt="History"></p>
<p>可以看到，从源头来说，函数式编程的起源非常早，第一门函数式编程语言 LISP 直接受到了 λ−calculus 的影响，
而 LISP 实际上是历史上第二门高级编程语言，早于 C 语言十几年。结合 Y-Combinator 的理论，我们其实可以看到：</p>
<ol>
<li>函数式编程和计算数学理论联系非常紧密</li>
<li>函数式编程不光是把函数作为 First Class Member，实际上我们还可以把函数作为原料进行组合和变换，从而实现各种功能</li>
<li>函数式编程的起源非常早，也从来没有“最近”才火起来，更不是只可以应用于少量特定领域</li>
</ol>
<h1 id="The_Core_of_Functional_Programming"><a href="#The_Core_of_Functional_Programming" class="headerlink" title="The Core of Functional Programming"></a>The Core of Functional Programming</h1><p>这一部分的内容主要是对 
《<a href="http://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html" target="_blank" rel="noopener">What’s functional programming all about</a>》
这篇文章的简单总结，建议各位读者尽量阅读原文。</p>
<p>谈到函数式编程，一个绕不过的话题还是函数式编程到底是什么？我们可以有如下观察：</p>
<ol>
<li>从类型系统上来说，函数式编程语言既有静态类型(Haskell, Scala 等)又有动态类型(Scheme 等)，
因此这一点并不是主要的判断标准</li>
<li>现在大多数编程语言都是多范式的，很多语言都支持高阶函数、闭包等特性，很有很多库实现了类似的范式，
而在所谓的函数式编程语言中，也可以写出命令式的风格，因此是否使用函数式编程语言编写代码不是函数式编程的判断标准</li>
</ol>
<p>目前的一种我比较认同的观点是：</p>
<blockquote>
<p>The core of Functional Programming is thinking about <em>data-flow</em> rather than <em>control-flow</em></p>
</blockquote>
<p>怎么理解上面这句话呢？一个例子是烘焙蛋糕，如果我们以控制流(Control-flow)的方式思考，大约就是像下图这样的一个菜谱</p>
<p><img src="/img/fp/fp-core-recipe.png" alt="Control Flow"></p>
<p>菜谱告诉了你要怎么一步一步地工作，从而制作出目标的产品。但是存在以下一些问题：</p>
<ol>
<li>哪些步骤是可以并行的？如果由多个人同时参与，如何才能分工合作加快进度？</li>
<li>在这些步骤当中，哪些工具是共享的？如果想要互不干扰地分工合作，每种工具要准备多少？</li>
<li>如何从这个菜谱出发，设计可以应用于工厂批量处理的生产流程？每种原料应该以多少比例配置？</li>
</ol>
<p>上面三个问题其实体现了现在的软件工程面临的几个重要的问题：并行性、并发同步和工程规模的膨胀。
读者可能在其他地方了解到，函数式编程在这几个方面都提供了较好的解决方案，因此越来越受这些领域的工程师的关注。
原因是什么呢？我们首先将上面的菜谱的每一条指令以输入、操作、输出三个部分着色</p>
<p><img src="/img/fp/fp-core-recipe-colored.png" alt="Colored control flow"></p>
<p>可以看到，每条指令其实都可以看作一次函数的调用。如果我们把最初的原料列出来，
并以这些原料在所有这些步骤所代表的函数当中流动的角度看问题，我们大抵可以得到下面这样的流程图</p>
<p><img src="/img/fp/fp-core-dataflow.png" alt="Data-flow"></p>
<p>如果把蛋糕的原料看作数据，那么这种思考问题的角度就是以数据流(Data-flow)为中心的思考方式。
可以看到，这种方式恰好是函数式编程提倡的方式，它隐含的一些思想包括：</p>
<ol>
<li>函数应该是没有副作用的， 函数的作用总是接收参数并返回结果，同样的参数应该返回同样的结果。
符合这样方式的函数调用很大程度上解决了函数的同步的问题(因为没有共享变量，函数的调用可以快速并发)</li>
<li>通过将函数串联起来实现功能，而不是维护一个对象的状态。在这种方式下，
所有的数据像水流一样在程序的各个部分快速流动，而不是存在某个对象来维护系统当前的状态</li>
<li>可以通过惰性求值将各个模块以 Flow 的形式组织起来，每个模块是一个功能单一且无状态的过程(服务)，
从而可以实现大规模的软件工程</li>
</ol>
<p>可以看到，目前比较热门的数据实时流处理(Spark Streaming, ReactiveX)、微服务架构、Docker
等技术都或多或少受到了这种思想的影响。</p>
<p>也许把所有这些 Dataflow 为中心思考问题的方法都归结到函数式编程的范畴当中有些夸张了，
但是函数式编程本身确实比其它地方更加强调这种思想。这也是我认为学习函数式编程最重要的意义：
通过应用函数式编程的思想来组织和架构软件，可以得到更加接近数据流思维方式的结构，
从而获得更好的并发性、鲁棒性和可扩展性。</p>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>在这篇文章中，把我之前所做的 FP 分享的主要内容总结了一下。在准备这个分享的过程当中，
我自己收益良多。包括理清一些函数式编程语言的相互影响和继承关系，了解了从最早的计算理论开始的 FP 发展历史，
对一些函数式的常见范式如惰性求值的实现的理解也更加清晰了。</p>
<p>另外还需要总结的一点是进行公开技术分享方面的经验。那就是在准备内容的时候一定要确认好听众的接受能力和平均水平，
尽管这次我觉得自己准备的内容已经算是相当入门的水准了，然而绝大部分听众接受起来还是有点困难。
这一方面表明了 FP 在平均的程序员当中的普及水平还是比较初级的，另一方面也是自己立意太高导致的。</p>
<p>近期我还在 <a href="http://www.shlug.org" target="_blank" rel="noopener">SHLUG</a> 的月度分享当中进行了一次 Git 中级知识的技术讲座，
跟着次讲座恰好相反——我准备的内容略显浅显。关于这次 Git 的讲座也有很多有意思的知识，回来也将会再总结为一篇博客。
敬请期待。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>近期受邀在 VMWare 上海的一个公开活动里做了一个技术分享介绍 Functional Programming，
在准备 Slides 的过程中又重新审视了一下自己对函数式编程这个主题的了解深度，
感觉又有一些收获。</p>]]>
    
    </summary>
    
      <category term="Functional Programming" scheme="https://io-meter.com/tags/Functional-Programming/"/>
    
      <category term="ES6" scheme="https://io-meter.com/tags/ES6/"/>
    
      <category term="React" scheme="https://io-meter.com/tags/React/"/>
    
      <category term="JavaScript" scheme="https://io-meter.com/tags/JavaScript/"/>
    
      <category term="Y-Combinator" scheme="https://io-meter.com/tags/Y-Combinator/"/>
    
      <category term="Closure" scheme="https://io-meter.com/tags/Closure/"/>
    
      <category term="Lazy Evaluation" scheme="https://io-meter.com/tags/Lazy-Evaluation/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Functional Go: HAMT 简介]]></title>
    <link href="https://io-meter.com/2016/11/06/functional-go-intro-to-hamt/"/>
    <id>https://io-meter.com/2016/11/06/functional-go-intro-to-hamt/</id>
    <published>2016-11-06T07:36:17.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>在之前的一个系列的文章里，我们从基本原理开始，一步步实现了基于 Vector Trie 的持久化 List 数据结构。
接下来将要研究的是使用 HAMT 这一数据结构实现持久化 Hash Table。</p>
<a id="more"></a>
<p><a href="https://io-meter.com/2016/09/03/Functional-Go-persist-datastructure-intro/">持久化数据结构简介</a> 这篇文章里，
我们对比各种可以用来实现持久化数据结构的方案，详细介绍了 Vector Trie 这种数据结构，说明了用它实现 List 优势。
HAMT 的全称是 Hash Array Mapped Trie，它和 Vector Trie 一样，都利用了前缀树(Trie)这种数据结构作为底层数据结构，
但是由于 Map 本身和 List 之间性质的差别，HAMT 在很多方面进行了特别的处理。接下来我们先从原始 Hash Table 数据结构谈起，
逐步引出 HAMT 的设计原理。</p>
<h2 id="Hash_Table"><a href="#Hash_Table" class="headerlink" title="Hash Table"></a>Hash Table</h2><p>Hash Table 是利用对象的 Hash 值对所储存的键进行散列从而实现快速的插入、删除和访问的数据结构。
在 Go 语言中的 <code>map</code>、Java 中的 <code>HashTable</code> 和 <code>HashMap</code> 和 Python 当中的 <code>dict</code> 都是 HashTable 的一种。
其基本原理是通过某一 Hash 函数将对象映射在某一虚拟空间上的一个点，并以此为依据将对象保存在内存上的固定位置上。
这样当需要访问这一对象时，依然使用同一 Hash 函数先计算出对象可能存在的位置，并尝试取出。</p>
<p>关于 <a href="https://en.wikipedia.org/wiki/Hash_function" target="_blank" rel="noopener">Hash</a> 和 <a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank" rel="noopener">Hash Table</a>
的概念不再赘述，在这里我们主要需要着眼的是设计实现 Hash Table 所需要处理的几个关键问题:</p>
<ol>
<li>Hash 碰撞问题: 由于 Hash 函数是通过将对象映射到某一数值的方式获得对对象的一个快速的描摹，
因此尽管我们可以断言 Hash 值不同的的对象一定不同，但是并不能保证具有相同 Hash 值的对象一定相同。
因此，在实际应用中遇到 Hash 碰撞的问题，就需要进行处理。</li>
<li>时间效率问题: 对于所有数据结构来说，时间效率都是非常重要的考量因素。Hash Table 从理论上来说的均摊时间复杂度很好，
但是仍然需要考虑在某些极端条件下面的执行性能，以保证在各种情况下算法的时间效率不会退化。</li>
<li>空间效率问题: 一般来说，我们不能将 Hash 函数值域整个在内存中一次分配出来。一来这样做在存入元素很少的情况下非常浪费，
二来我们构造的 Hash 函数值域范围很大，一般无法直接分配。因此需要一种方法将空间使用压缩到合理的范围，
同时保持一定的空间效率。</li>
<li>并发同步问题: 和 List 一样，在现代多核盛行的计算环境内，Hash Table 实现的并发安全性也是一个重要的考虑因素。
Hash Table 的插入、访问和删除操作往往包含好连续的几步，如果不能保证这些步骤在一起原子的完成就可能会产生无法预计的结果。</li>
</ol>
<p>以上四点在实现 Hash Table 的过程当中是互相联系的。比如说 Hash 碰撞问题就与时间效率和空间效率两个方面紧密相连。
一般来说，Hash 碰撞越多，Hash Table 的时间效率越差。根据碰撞处理策略的不同，还有可能影响空间效率。
反过来，如果空间分配的比较多，尽管空间效率下降，但是往往可以缓解 Hash 碰撞的概率，因此改善时间效率。
并发同步问题也与上述问题紧密相连，譬如说有的 Hash Table 实现在空间不足时需要重新分配空间，
这一操作既耗时，又包含很多的指令，对于并发安全提出了很高的要求。</p>
<p>HAMT 在以上四个方面都给出了自己的极佳的解决方案，很多学者将其称为理想(Ideal)的 Hash Table 实现。
在接下来介绍 HAMT 的原理之前，我们先给出在本文中对 Hash 函数的一些假定:</p>
<ol>
<li>Hash 函数的值是 <code>int32</code> 类型</li>
<li>Hash 函数的值域 <code>int32</code> 类型的范围</li>
<li>对于两个不同的对象，总可以找到一个 Hash 函数使二者 Hash 值不同</li>
</ol>
<h2 id="HAMT__u539F_u7406_u7B80_u4ECB"><a href="#HAMT__u539F_u7406_u7B80_u4ECB" class="headerlink" title="HAMT 原理简介"></a>HAMT 原理简介</h2><p>之前介绍了 Vector Trie 实现的持久化 List，如果将这种 List 作为基础，直接套用传统 Hash Table 的实现方法，
其实就可以实现持久化的 HashMap 了。但是这种解决方案在时间效率、空间效率上都比较差。Hash Table 和 List
的一个区别在于 Hash Table 当中保存的元素是散列和稀疏的，不像 List 那样从下标 <code>0</code> 一直排列到 <code>n</code>。</p>
<p>然而只要把 List 当中下标必须连续的限制条件去掉，Vector Trie 本身就变成了一种相对传统 Array 更好的容器。
下图表示的 Vector Trie 说明了这一点:</p>
<p><img src="/img/posts/variant-of-vector-trie.png" alt="Variant of Vector Trie"></p>
<p>由上图可见，在 Vector Trie 表示的 Hash Table 中，每个元素的 Hash 值的范围是 0 (<code>00 00 00 00</code>) 到 255 (<code>11 11 11 11</code>)。
此时 Hash Table 当中只有两个元素，其中一个 hash 值是 0，另一个为 255。在传统 Array 实现的 Hash Table
当中我们需要分配一个长度 256 的数组来保存。而使用 Trie 只需要 7 个节点，共计 28 个单位的空间。
其它位置因为没有元素存在，那些节点可以直接节省掉。</p>
<p>这说明应用 Trie 树可以在节约空间效率方面具有很好的表现。事实上依靠 Trie 树我们可以直接把 0 到 $2^{32} - 1$ (既<code>int32</code>)
范围的空间表示出来而不用直接分配全部内存——只有存在元素的分支会被按需地分配出来。事实上，Trie
树是线性空间上稀疏数组的一种很好的表示形式。</p>
<p>在引入 Trie 树作为数组的稀疏表示之后，我们已经大幅地提高空间效率并得到了不错的时间效率。尽管查询 Trie
树比直接访问数组更慢一些，但是由于我们表示的 Hash 空间足够宽广，在实际应用中遇见碰撞的概率极低，
因此在时间效率上还是很有竞争力的。</p>
<p>至此，在 Vector Trie 的基础上我们得到了通往 HAMT 的第一步：将元素的 Hash 值按位分割成固定宽度的序列，在 Trie
树上以这些序列按顺序查找元素应该存放的位置。然而 HAMT 并不止步于此，从图中容易看出，
我们还有两种优化方案可以达到更好的空间时间效率:</p>
<ol>
<li>节约单个节点当中空间的浪费: 许多 Trie 节点中仍然有非常多的空位，设法将这些空位清除可以节省很多空间。</li>
<li>削减 Trie 树的高度: 保存在树中的两个元素的 Hash 值从第一位开始就不相同，理论上只需要检查最前面的几位就可以区分。
只使用 Hash 值中较高的比特位既可以节约空间，又可以提高时间效率。</li>
</ol>
<p>在这两个方向，HAMT 都提出了不错的优化方案。</p>
<h2 id="u8282_u70B9_u5185_u90E8_u7A7A_u95F4_u7684_u538B_u7F29"><a href="#u8282_u70B9_u5185_u90E8_u7A7A_u95F4_u7684_u538B_u7F29" class="headerlink" title="节点内部空间的压缩"></a>节点内部空间的压缩</h2><p>如果我们依然使用固定 32 个元素宽度的 Trie 树节点，那么必然可能出现由于存入的元素比较稀疏而存在大量空位的现象，
为此我们要对节点内部空间进行压缩。压缩的方法是：</p>
<ol>
<li>为每一个节点添加一个 <code>int32</code> 类型的 Bit Map 字段，当这个字段某一比特位值为<code>1</code>代表在当前节点上对应的自节点出现了，
否则则代表没有出现</li>
<li>我们保存子元素时不再保留空间的空闲位置，而是将所有的子元素一个挨一个的紧密放置，
在存取时利用上一步添加的字段计算出所需的是哪一个子节点。</li>
</ol>
<p>为了更清楚地解释上述做法，下面的示意图来描绘了进行节点内部压缩前后的节点内部结构:</p>
<p><img src="/img/posts/trie-node-compression.png" alt="Trie Node Compression"></p>
<p>由上图可以看到，虽然压缩后的节点多增加了一个用于保存 Bit Map 的字段，但是由于省略了6个空置空间，
所以整体的内存消耗大大降低了。</p>
<p>要在压缩过的节点当中完成跟原来一样的查询逻辑，我们要建立压缩前后节点之间的对应关系。
在未压缩的节点中，由于每个自节点就在它序号所指定的内存位置，所以我们可以直接用下标访问它，
在压缩过的节点中这一性质不再有效，我们需要使用新增的 Bit Map 字段将节点的内存位置计算出来。</p>
<p>由上图可以看到，压缩前后子元素的相对顺序并没有改变，仍然是按照从小到大的顺序排列起来的，
这一点非常重要。根据这个性质，我们可以给出如下的算法：</p>
<ol>
<li>如果指定序号在 Bit Map 字段中对应的比特位为<code>0</code>，表明并不存在给定序号的子元素，因此可以立刻返回空值</li>
<li>如果指定序号在 Bit Map 字段中对应比特位为<code>1</code>，则元素存在且它在压缩后节点中的位置下标等于在其之前出现的子元素的数量</li>
</ol>
<p>第二条其实很好理解，因为压缩后元素的相对顺序不变，只是将空余空间剔除，因此如果从零开始编号，
设在所查询子元素之前出现的元素数量为<code>n</code>，那么所查询子元素就是第<code>n+1</code>个元素。因此其下标恰好是<code>n</code>。
利用 Bit Map 和位运算我们可以快速的计算出<code>n</code>的值。</p>
<p>譬如说，我们要查询在原节点中下标为<code>i</code>的元素，首先我们看一下 Bit Map 第 <code>i</code> 位的值是否为 <code>1</code>。
方法是使用位运算 <code>(B &gt;&gt; i) &amp; 1</code>，其中 <code>B</code> 是 Bit Map 字段的值。如果检查结果为
<code>1</code>，说明元素存在，我们进一步计算它的位置。</p>
<p>显然，当前元素之前的元素数量<code>n</code>，就等于 Bit Map 当中从 <code>0</code> 到 <code>i - 1</code> (包含两端)位比特位当中 <code>1</code> 的数量，
我们首先用 <code>B &amp; ((1 &lt;&lt; i) - 1)</code> 将那些位单独取出来并将其他位置设为<code>0</code>。其中，<code>(i &lt;&lt; i) - 1</code>
得到的是 <code>0</code> 到 <code>i - 1</code> 位全为 <code>1</code>，其他位全为 <code>0</code> 的一个整型值。</p>
<p>得到这个结果之后，我们还需要把其中的 <code>1</code> 的数量计算出来。这一操作在计算机科学当中被称为 Pop Count，
进行这样的计算所得到的值又称为<a href="https://en.wikipedia.org/wiki/Hamming_weight" target="_blank" rel="noopener">Hamming Weight</a>。
Pop Count 是一种非常常用的操作，因此存在很多相关研究，有的 CPU 指令集(如 x86)还添加了专门的指令用于执行这一操作。</p>
<p>除了直接使用指令集或者简单地逐个计数，Hamming Weight 的快速计算有很多方法，下面的代码给出了在 <code>int32</code> 
类型上快速计算 Pop Count 的一种实现方法。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">uint32_t</span> m1  = <span class="number">0x55555555</span>; <span class="comment">//binary: 0101...</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">uint32_t</span> m2  = <span class="number">0x33333333</span>; <span class="comment">//binary: 00110011..</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">uint32_t</span> m4  = <span class="number">0x0f0f0f0f</span>; <span class="comment">//binary:  4 zeros,  4 ones ...</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">uint32_t</span> m8  = <span class="number">0x00ff00ff</span>; <span class="comment">//binary:  8 zeros,  8 ones ...</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">uint32_t</span> m16 = <span class="number">0x0000ffff</span>; <span class="comment">//binary: 16 zeros, 16 ones ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//This uses fewer arithmetic operations than any other known  </span></span><br><span class="line"><span class="comment">//implementation on machines with slow multiplication.</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">popcount32</span><span class="params">(<span class="keyword">uint32_t</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x -= (x &gt;&gt; <span class="number">1</span>) &amp; m1;             <span class="comment">//put count of each 2 bits into those 2 bits</span></span><br><span class="line">    x = (x &amp; m2) + ((x &gt;&gt; <span class="number">2</span>) &amp; m2); <span class="comment">//put count of each 4 bits into those 4 bits </span></span><br><span class="line">    x = (x + (x &gt;&gt; <span class="number">4</span>)) &amp; m4;        <span class="comment">//put count of each 8 bits into those 8 bits </span></span><br><span class="line">    x += x &gt;&gt;  <span class="number">8</span>;  <span class="comment">//put count of each 16 bits into their lowest 8 bits</span></span><br><span class="line">    x += x &gt;&gt; <span class="number">16</span>;  <span class="comment">//put count of each 32 bits into their lowest 8 bits</span></span><br><span class="line">    <span class="keyword">return</span> x &amp; <span class="number">0x7f</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于 Pop Count 的计算本文不再赘述，相关内容可以参考 <a href="https://en.wikipedia.org/wiki/Hamming_weight" target="_blank" rel="noopener">Wikipedia</a>
上详细的介绍和计算方法的对比。由于在 HAMT 当中 Pop Count 是一个非常常用的操作，因此他的性能对最终实现的 Hash Table
的性能有显著的影响，在实现 HAMT 时，一定要根据目标平台的特点，选择合适的实现方法，可能的话应该直接使用 CPU
指令集支持的指令进行计算。</p>
<p>在获得到子元素在压缩后节点的内存下标之后，我们就可以像原来一样对节点进行查询访问了。</p>
<h2 id="u538B_u7F29_Trie__u9AD8_u5EA6"><a href="#u538B_u7F29_Trie__u9AD8_u5EA6" class="headerlink" title="压缩 Trie 高度"></a>压缩 Trie 高度</h2><p>在节点内部空间之外另一个可以节省空间的地方是 Trie 树的高度。
前面在利用这个 <code>int32</code> 宽的 Hash 值构造 Trie 树将我们的对象放置在内存中索引起来，
那么一个容易想到的优化就是在不产生混淆的情况下，我们没有必要一定使用 Hash 值的每一个二进制位。
也就是说，如果 Hash 值的较高的一部分二进制位已经可以在我们的 Hash Table 中唯一地标记这个对象了，
我们就不再利用后面的比特位。</p>
<p>下图展示了对 Trie 树高度的压缩。在左边的原始 Trie 树中存放了 Hash 值为
<code>0</code>(<code>00 00 00 00</code>) 和 <code>127</code>(<code>01 11 11 11</code>)的两个对象，中间是压缩高度的 Trie 树，
我们看到，由于当前 Hash Table 中只有两个元素，而这两个元素的 Hash 值从最开始就是不一样的，
所以在压缩之后，从高位开始第二位之后的 Hash 值不再被使用。</p>
<p><img src="/img/posts/trie-height-compression.png" alt="Trie Height Compression"></p>
<p>同理，在添加和删除新的对象的时候，我们还需要动态地维护树的高度，在合适的时候增加或者减少树的高度。
最右边的图展示了在 Hash Table 中插入 <code>79</code>(<code>01 00 11 11</code>)之后 Trie 树的结构。可以看到，
因为新的节点插入，最高位<code>01</code>两个比特位指代的对象出现了混淆，不能唯一地确定一个对象，
因此我们要进一步地利用剩下的比特位来构造无混淆的树。</p>
<p>由于对 Trie 的各种操作都是基于树上节点的访问，对 Trie 高度进行的压缩不单节约了内存空间，
也提高了查询和访问的性能。</p>
<h2 id="u57FA_u672C_u64CD_u4F5C_u7684_u5B9E_u73B0"><a href="#u57FA_u672C_u64CD_u4F5C_u7684_u5B9E_u73B0" class="headerlink" title="基本操作的实现"></a>基本操作的实现</h2><p>在熟悉了 HAMT 在原始的 Trie 表示上做了哪些优化之后，我们就可以给出在 HAMT 实现的 Hash Table 
上进行各种操作的基本思路了。</p>
<h3 id="u67E5_u8BE2_u64CD_u4F5C"><a href="#u67E5_u8BE2_u64CD_u4F5C" class="headerlink" title="查询操作"></a>查询操作</h3><p>查询操作和在 Trie 上进行查询没有太大的改变，只是因为节点的空间被压缩之后，需要先通过 Bit Map 字段
判断对应的位置是否存在子元素，如果存在，再通过 Pop Count 计算得到子元素所在的实际位置。
在获得到子元素之后，鉴于 HAMT 对 Trie 的高度进行了压缩，我们要先判断这个子元素是 Trie
的子节点还是值元素本身。对于 Hash Table，我们将值包装成<code>&lt;Key, Value&gt;</code>这样的一个值节点存放进去。
这样取出时就可以先判断 <code>Key</code> 的值是否相同，以此决定是否真的取到了对象。</p>
<h3 id="u52A0_u5165_u64CD_u4F5C"><a href="#u52A0_u5165_u64CD_u4F5C" class="headerlink" title="加入操作"></a>加入操作</h3><p>加入操作类似于查询操作，对于给定的键值对，我们先计算键的 Hash 值，然后从高位开始利用 Hash 值。
沿着 Trie 树向下查找，此时存在四种情况：</p>
<ol>
<li>查找到一个位置，这个位置所保存的值对象代表的键和新插入的键相同，则用新插入的值代替原来的值</li>
<li>查找到一个子节点，这个子节点再向下目标对象应该所在的位置没有元素，此时只需申请一个新的宽度比当前子节点多1的节点，
将原来子节点上的所有元素连带当前对象一一设置到新的子节点上，维护好元素的顺序和 Bit Map 的值即可</li>
<li>查找到一个子节点，这个子节点再向下目标对象所应该在的位置是一个值对象，这时，为这个值对象连带当前对象分配一个宽度为2
的子节点，将原来的值对象和当前对象放置在新的节点中，最后用新的节点在当前子节点中替换掉对应位置</li>
<li>查找到一个子节点，这个节点再向下目标对象所应该在的位置是另一个子节点，则在那个子节点上递归进行上述操作</li>
</ol>
<p>在以上三种情况外，还有一种情况即为出现 Hash 值碰撞。也就是说，当前想要插入的值和 Hash Table 当中某一个对象的 Hash
值完全一样，这样即使两个对象的 Hash 值全部用尽，也无法不混淆地存放两个对象。这时就需要进行碰撞处理。
对于 HAMT 来说，常见的碰撞处理有些类似于加盐 Hash 的过程。理论上来说，一个良好设计的 Hash 函数本身的碰撞概率就极小，
如果两个元素确实在某次计算中 Hash 碰撞，在两个元素上追加某段已知的固定数据，再进行 Hash 所得的结果极有可能不再碰撞。
因此我们可以利用这一特点，当两个对象 Hash 值相同，我们追加一个值，再进行一次 Hash，利用得到的新 Hash
值接着在 Trie 上执行插入即可。</p>
<p>如果出现了两个不同的对象，无论怎么 Hash ，都得到一样的值，那么要么表明使用 Hash 函数本身是有问题的，
要么说明容器的实现存在问题。这时就应该直接报错了。</p>
<h3 id="u5220_u9664_u64CD_u4F5C"><a href="#u5220_u9664_u64CD_u4F5C" class="headerlink" title="删除操作"></a>删除操作</h3><p>删除操作是加入操作的逆运算，其基本原理也类似。在删除时，现在 Trie 中找到对应的对象，然后依次递归地删除。
在从子节点删除一个元素时，我们也一样要分配一个新的子节点，这个子节点的宽度比原来少1。
之后将剩余的子元素按照规则放回新的子节点并维护 Bit Map 字段的值。最后用新的子节点替换原来的节点并递归向上进行。
一般来讲，在递归时有如下几个情况：</p>
<ol>
<li>在子节点进行删除操作之后，子节点不再包含任何子元素，则删除当前子节点并返回空</li>
<li>当前子节点只剩下一个元素，且这个元素为值元素，则应该降低树的高度，直接返回值元素</li>
<li>当前子节点只剩下一个元素，且这个元素是子节点，则保留这个子节点，回到上一个节点</li>
</ol>
<h1 id="u6301_u4E45_u5316_HAMT"><a href="#u6301_u4E45_u5316_HAMT" class="headerlink" title="持久化 HAMT"></a>持久化 HAMT</h1><p>由于 HAMT 本质上还是 Trie，因此我们可以按照之前 Vector Trie 一样的策略来实现持久化。
简单来说还是在需要修改节点时，不对原来的节点进行直接的修改，而是生成新节点并复制节点到根的路径。
同样，通过在节点中添加 <code>id</code> 字段，我们也可以在 HAMT 上实现 Transient 以加快批量操作的速度。</p>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>在按照上述介绍的空间压缩方法和 Trie 操作方法实现了 HAMT 之后，还有一些问题需要注意：</p>
<ol>
<li>从算法分析上来讲，HAMT 的各项操作时间复杂度都在常数级别内，但是如前文所提，仍需要注意 Pop Count
等操作的时间花费，尽量针对不同平台选用性能最高的实现方案</li>
<li>HAMT 不像传统的 Hash Table 那样集中地分配大量空间，而是在每次加入和删除时重新生成子节点并分配小块的空间，
因此内存申请的时间花费在这里不可以被忽略。事实上，Benchmark 表明 HAMT 的一般实现当中内存管理花费的时间是最显著的。
在这种情况下，由容器自己维护一个内存池是必要的。也就是说，在每次生成新的节点时，并不直接申请新的内存，
而是先从内存池当中尝试获取一个目标宽度的子节点。同理，在释放一个子节点的时候也是将节点返回给这一内存池。
线程安全的内存池的实现又是另外一个巨大的主题了，这里也不再赘述</li>
<li>HAMT 的设计是针对像 C 或 C++ 这样完面向内存、可以细力度控制数据结构在内存中布局的编程语言设计的，
因此在 JVM 和 Golang 这种比较远离硬件的编程语言上进行实现，内存的痕迹和操作的性能均可能不能达到真正的理想状态。
近期有一篇名为
<a href="https://michael.steindorfer.name/publications/oopsla15.pdf" target="_blank" rel="noopener">Optimizing Hash-Array Mapped Tries for Fast and Lean Immutable JVM Collections</a>
的论文讨论了在 JVM 上优化 HAMT 的实现，有兴趣的读者可以进一步阅读。</li>
</ol>
<p>综上所述，HAMT 是一种适合于实现持久化 Hash Map 的数据结构，下一篇文章将会介绍 HAMT 在 Go 语言下的实现，
从而为我们的 Golang 持久化数据结构添加另一个重要的成员。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在之前的一个系列的文章里，我们从基本原理开始，一步步实现了基于 Vector Trie 的持久化 List 数据结构。
接下来将要研究的是使用 HAMT 这一数据结构实现持久化 Hash Table。</p>]]>
    
    </summary>
    
      <category term="Golang" scheme="https://io-meter.com/tags/Golang/"/>
    
      <category term="go" scheme="https://io-meter.com/tags/go/"/>
    
      <category term="functional programming" scheme="https://io-meter.com/tags/functional-programming/"/>
    
      <category term="fp" scheme="https://io-meter.com/tags/fp/"/>
    
      <category term="persist datastructure" scheme="https://io-meter.com/tags/persist-datastructure/"/>
    
      <category term="immutable" scheme="https://io-meter.com/tags/immutable/"/>
    
      <category term="essay" scheme="https://io-meter.com/tags/essay/"/>
    
      <category term="hamt" scheme="https://io-meter.com/tags/hamt/"/>
    
      <category term="Functional Go" scheme="https://io-meter.com/categories/Functional-Go/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Functional Go: Transient 及持久化]]></title>
    <link href="https://io-meter.com/2016/10/01/Functional-Go-Transient-and-Persistent/"/>
    <id>https://io-meter.com/2016/10/01/Functional-Go-Transient-and-Persistent/</id>
    <published>2016-10-01T14:21:46.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>在之前的文章中，我们介绍了一些持久化数据结构实现的基本原理和 Vector Trie 这一数据结构在 Golang 下的实现过程。
这篇文章终于来到了实现持久化 List 的最后一步: 实现 Transient 和持久化的功能。</p>
<a id="more"></a>
<p>这篇文章是系列文章的一部分，如果还没有浏览过文章的其它部分请参考：</p>
<ol>
<li><a href="https://io-meter.com/2016/09/03/Functional-Go-persist-datastructure-intro/">持久化数据结构简介</a></li>
<li><a href="https://io-meter.com/2016/09/15/functional-go-implement-vector-trie/">Vector Trie 的实现</a></li>
<li><a href="https://io-meter.com/2016/10/01/Functional-Go-Transient-and-Persistent/">Transient 及持久化</a> (本文)</li>
</ol>
<p>在之前的文章中，我们已经看到了如何实现一个 Vector Trie，也知道如何使用 Vector Trie 来实现共享数据结构的持久化 List：
在每次修改时，我们复制从根节点到被修改节点路径上的所有节点，并使用得到的新的 Root 节点构造一个新的 List 的 HEAD
数据结构。这样通过新的 HEAD 我们就可以访问到新的数据，通过旧的 HEAD 我们可以得到旧的数据。</p>
<p>按照这样的思路，我们需要更改 List 的接口，对于每一个会修改 List 元素的操作，我们都要返回一个新的 List
对象而不是在原来的对象上修改。比如说:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> List <span class="keyword">interface</span> &#123;</span><br><span class="line">        Get(n <span class="keyword">int</span>) (<span class="keyword">interface</span>&#123;&#125;, <span class="keyword">bool</span>)</span><br><span class="line">        Set(n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;) (List, <span class="keyword">bool</span>)</span><br><span class="line">        PushBack(value <span class="keyword">interface</span>&#123;&#125;) List</span><br><span class="line">        RemoveBack() (List, <span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">        Len() <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了实现这样的接口，我们有两种选择：</p>
<ol>
<li>对于 <code>Set</code>、<code>PushBack</code> 和 <code>RemoveBack</code> 函数，我们把它们修改成返回新的 <code>listHead</code> 的形式</li>
<li>先实现 <code>TransientList</code>，对于<code>Set</code>、<code>PushBack</code> 和 <code>RemoveBack</code> 函数，我们把它改造成先把自己转换成 <code>TransientList</code>
并修改，最后返回将 <code>Transient</code> 持久化的结果</li>
</ol>
<p>由于我们之前的代码设计上预先做了准备，两种方案的实现难度其实差别不大。但是因为 Transient
支持对数据结构一连串操作的高效执行，我们决定采用第二种方案。第二种方案也会使得代码更简洁、复用的程度更高。</p>
<p>那么什么是 Transient 呢？下面我们就来介绍它。</p>
<h2 id="Transient__u7684_u539F_u7406"><a href="#Transient__u7684_u539F_u7406" class="headerlink" title="Transient 的原理"></a>Transient 的原理</h2><p>前面说道，持久化数据结构的实现原理是复制一条路径上的节点。在我们的设计中，每个节点的宽度是32，
那么如果我们连续地修改几个相邻的元素，即使这些元素都在一个叶子节点上，它也会被复制很多遍。
这样的行为是非常低效的。为了能让我们高效地进行一连串的修改，一种解决方案就是允许一个持久化数据结构临时地变成非持久的，
在我们一连串的修改之后，再转变回来。这样每次修改都会在原地进行，从而极大地改善了性能。
这里临时产生的非持久化数据结构就是我们所说的 Transient。</p>
<p>但是同样我们也要知道，使用 Transient 是有一定风险的。首先作为一种可变数据结构，它一般来说会被实现为非线程安全的类型，
因此如果并发地操作它，就可能产生 Race condition 等问题。另外，如果用户在使用时保留了对于 Transient 的引用，
把 Transient 转变为持久化之后仍然对 Transient 进行了修改，那么生成的持久化对象实际上也会被改变。
也就是说，引入 Transient 可能会导致无效的持久化。</p>
<p>尽管 Transient 带来了一些风险，但是考虑到性能上的提升，它还是值得的。Transient 的实现有两个关键点:</p>
<ol>
<li>为每个 Transient 分配一个全局唯一的<code>id</code>，当 Transient 每次对内部结构进行修改时，保证修改过的节点都被打上这个<code>id</code>
作为标记</li>
<li>当 Transient 每次需要对节点进行修改时，它先检查目标节点是否和自己有相同的<code>id</code>，如果相同，
那么这个节点是自己之前曾经修改或复制过的，因此可以在节点上直接进行修改。否则这个节点可能是之前的 Transient 生成的，
为了防止改变原来的数据，我们应该复制当前节点一份。</li>
</ol>
<p>这两条策略保证我们可以安全地修改 Transient 而不会改变原来的数据。关键在于，通过为 Vector Trie 的节点打上<code>id</code>
标志，Transient 可以判断一个节点的内存是不是由自己分配出来的。对于<code>id</code>不一样的节点，它是由当前 List 
修改历史上出现过的某个 Transient 产生的，而之前那个 Transient 可能已经被转换为持久对象，因此那些节点不应该被直接修改。
而如果<code>id</code>一致，则表明当前 Transient 新近修改过这一节点，我们就可以再次修改。这一步是基于持久化过的 Transient
不再会被使用者修改的假定。这也是为什么如果 Transient 持久化之后仍被修改，则生成的持久化对象的不可变性就会被破坏的原因。</p>
<p>下图对比了持久化 List 和 Transient 在执行修改时的不同。</p>
<p><img src="/img/posts/with-without-transient.png" alt="Without vs. With transient"></p>
<p>图中上方是不使用 Transient 时的情况，右边三种不同的颜色代表连续的三次修改。在这种情况下，
我们的每次修改都会产生一个新的 Root 节点和一份新的叶子节点。这样显然是没有效率的。</p>
<p>在图中的下方是使用了 Transient 时的情况，每个节点都包含了一个 ID (图中紫色标记)，当第一次修改进行的时候我们为 Transient
分配了一个新的 ID <code>b</code>，在修改的过程中检查需要更新的节点，发现他们都具有 ID <code>a</code>，与当前 ID 不同，因此需要进行一次复制。
在接下来的两次修改中，由于 Transient 在其生命周期中 ID 不变，进行修改时发现目标节点的 ID 与当前 Transient 一致，
因此我们不需要再复制节点，可以直接进行 In-place 的更新。</p>
<p>以上就是 Transient 的基本原理。由这个基本原理可以看出，实际上 Transient 和我们的持久化 List
可以共享一套底层的数据结构，其差别仅在于 Transient 拥有一个 ID 而 List 没有。实际上，为了区分这两种情况，
我们为所有的 List 的 <code>HEAD</code> 分配一个特殊的 ID，譬如<code>0</code>。在 List 和 Transient 之间转换可以使用下列手段:</p>
<ol>
<li>将 List 转化为 Transient，我们使用某种 ID 生成器生成一个唯一且不同于 List ID 的 ID (如正整数)并分配给 List</li>
<li>将 Transient 转为 List，我们将 Transient 的 ID 重置为 List ID (如<code>0</code>)</li>
</ol>
<p>在我们的情况下， 由于 Golang 特殊的面向对象设计，我们实际上可以将 List 内部数据结构实现为 Transient 
内部数据结构的一个 alias。</p>
<h2 id="Transient__u7684_u5B9E_u73B0"><a href="#Transient__u7684_u5B9E_u73B0" class="headerlink" title="Transient 的实现"></a>Transient 的实现</h2><h3 id="Unique_ID__u751F_u6210_u5668_u7684_u5B9E_u73B0"><a href="#Unique_ID__u751F_u6210_u5668_u7684_u5B9E_u73B0" class="headerlink" title="Unique ID 生成器的实现"></a>Unique ID 生成器的实现</h3><p>对于 Transient 来讲，如何为每次修改生成独一无二的 ID 是一件重要的问题。在现实中存在很多功能各异的独特 ID 生成算法，
他们有的只能工作在单机情况下，有的可以保证分布式情况下的唯一性，有的生成成本比较高，有的则非常轻量。
在这里，我们选择最简单的一种方式：累计<code>uint64</code>类型的正整数。</p>
<p>通过在单例情况下累计正整数的方式，我们可以保证生成的 Unique ID 在当前进程中是具有唯一性的。
其原理是通过<code>sync/atomic</code>包下的原子操作<code>AddUint64</code>来实现递增操作。这一操作既快速又线程安全。</p>
<p>以下是实现这一功能的内部包<code>counter</code>:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"sync/atomic"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> id <span class="keyword">uint64</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Next</span><span class="params">()</span> <span class="title">uint64</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> atomic.AddUint64(&amp;id, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="List__u63A5_u53E3_u7684_u66F4_u65B0"><a href="#List__u63A5_u53E3_u7684_u66F4_u65B0" class="headerlink" title="List 接口的更新"></a>List 接口的更新</h3><p>前面我们说道，可以将 List 实现为 Transient 的一个 alias。在这一步，我们先将之前博客里实现的 List 内部数据结构重命名为
<code>tListHead</code>，代表他是一个 Transient List 的 Head，之前实现的方法也都一并转移过来。除此之外，
我们还要在新的<code>tListHead</code>和它内部的 Trie 树节点上都添加 ID 字段:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Transient List Head</span></span><br><span class="line"><span class="keyword">type</span> tListHead <span class="keyword">struct</span> &#123;</span><br><span class="line">    id     <span class="keyword">uint64</span></span><br><span class="line">    <span class="built_in">len</span>    <span class="keyword">int</span></span><br><span class="line">    level  <span class="keyword">int</span></span><br><span class="line">    offset <span class="keyword">int</span></span><br><span class="line">    root   *trieNode</span><br><span class="line">    tail   *trieNode</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Trie Node</span></span><br><span class="line"><span class="keyword">type</span> trieNode <span class="keyword">struct</span> &#123;</span><br><span class="line">    id       <span class="keyword">uint64</span></span><br><span class="line">    children []<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们重新定义 List 的接口和实现方法:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> List <span class="keyword">interface</span> &#123;</span><br><span class="line">    Get(n <span class="keyword">int</span>) (<span class="keyword">interface</span>&#123;&#125;, <span class="keyword">bool</span>)</span><br><span class="line">    Set(n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;) (List, <span class="keyword">bool</span>)</span><br><span class="line">    PushBack(value <span class="keyword">interface</span>&#123;&#125;) List</span><br><span class="line">    RemoveBack() (List, <span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">    TransientList() TransientList</span><br><span class="line">    Len() <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> listHead tListHead</span><br></pre></td></tr></table></figure>
<p>新的接口不再是在原来的基础上进行修改，而是每次操作都返回新的 List 对象。我们还添加了一个方法用于将当前 List
转换为一个 Transient。注意到<code>listHead</code>只是<code>tListHead</code>的一个 alias，因此在 Go 语言中他们之间可以相互类型转换。
接下来我们定义一个全局公共的 <code>empty</code> 变量代表空的 List，由于我们希望所有的空 List 都一样而持久化 List 是不会被改变的，
因此我们并不会在 New 时创建新的空对象而是每次都返回这一个对象。这样也节约了新建 List 时的内存消耗。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> empty = &amp;listHead&#123;<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="literal">nil</span>, <span class="literal">nil</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">()</span> <span class="title">List</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> empty</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>List 的 <code>Get</code> 因为不会改变元素的值，我们直接通过类型转化的方法将<code>listHead</code>转换为
<code>tListHead</code>并调用后者的对应方法获得结果:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">Get</span><span class="params">(n <span class="keyword">int</span>)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> (*tListHead)(head).Get(n)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于其它修改操作，我们都先将其转换为 Transient 执行完修改操作之后再持久化回来。这样就可以获得新的 List 了。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">Set</span><span class="params">(n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(List, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">    t := head.TransientList()</span><br><span class="line">    <span class="keyword">if</span> t.Set(n, value) &#123;</span><br><span class="line">        <span class="keyword">return</span> t.Persist(), <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> head, <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">PushBack</span><span class="params">(value <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">List</span></span> &#123;</span><br><span class="line">    t := head.TransientList()</span><br><span class="line">    t.PushBack(value)</span><br><span class="line">    <span class="keyword">return</span> t.Persist()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">RemoveBack</span><span class="params">()</span> <span class="params">(List, <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> head.<span class="built_in">len</span> == <span class="number">1</span> &#123;</span><br><span class="line">        value, _ := head.Get(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> empty, value</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        t := head.TransientList()</span><br><span class="line">        value := t.RemoveBack()</span><br><span class="line">        <span class="keyword">return</span> t.Persist(), value</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面给出了<code>TransientList</code>方法的实现。由于 List 的不可变性质需要被保留，因此转化为 Transient 
实际上需要新建立一个 <code>tListHead</code>，这样对于 Transient 的修改就不会影响到原来的 List。这里调用了之前实现的 <code>counter</code>
包来获得 Unique ID。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">TransientList</span><span class="params">()</span> <span class="title">TransientList</span></span> &#123;</span><br><span class="line">    id := counter.Next()</span><br><span class="line">    <span class="keyword">return</span> &amp;tListHead&#123;id, head.<span class="built_in">len</span>, head.level, head.offset, head.root, head.tail&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Transient__u4FEE_u6539_u64CD_u4F5C_u7684_u5B9E_u73B0"><a href="#Transient__u4FEE_u6539_u64CD_u4F5C_u7684_u5B9E_u73B0" class="headerlink" title="Transient 修改操作的实现"></a>Transient 修改操作的实现</h3><p>接下来还需要更新 Transient 修改操作的实现来保证不会影响到其它 Transient 以及之前的持久化 List。
之前的 List 在实现的过程中我们已经部分考虑到这种问题了，大部分操作被设计为递归执行，同时对 Trie 
树的递归操作会赋值给原来节点。在这一基础上我们首先为 <code>trieNode</code> 添加<code>clone</code>和<code>setChild</code>两个方法。</p>
<p><code>clone</code> 方法会将当前节点的内容复制一边并返回新的节点，它接受一个<code>id</code>参数，新复制出来的节点的<code>id</code>属性会被设定为这一参数。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(node *trieNode)</span> <span class="title">clone</span><span class="params">(id <span class="keyword">uint64</span>)</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    children := <span class="built_in">make</span>([]<span class="keyword">interface</span>&#123;&#125;, NODE_SIZE)</span><br><span class="line">    <span class="built_in">copy</span>(children, node.children)</span><br><span class="line">    <span class="keyword">return</span> &amp;trieNode&#123;id, children&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>setChild</code> 则是方便实现修改节点功能的函数，它的第一个参数也是<code>id</code>。如果传入的<code>id</code>与节点原来的<code>id</code>相同，
则这一方法直接在原来的节点上进行修改并返回原来的节点，否则它将会<code>clone</code>节点并在新的节点上进行操作。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(node *trieNode)</span> <span class="title">setChild</span><span class="params">(id <span class="keyword">uint64</span>, n <span class="keyword">int</span>, child <span class="keyword">interface</span>&#123;&#125;)</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> node.id == id &#123;</span><br><span class="line">        node.children[n] = child</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        newNode := node.clone(id)</span><br><span class="line">        newNode.children[n] = child</span><br><span class="line">        <span class="keyword">return</span> newNode</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之前 List 修改操作的各个内部函数也都被加上了<code>id</code>作为参数。除此之外，如果<code>Set</code>前后 List 包含值相同，
我们希望实际效果是对象没有被修改，在这一步我们也做了一些小心的操作来尽可能保证。
具体的代码不再赘述，完整的代码请参考<a href="https://github.com/shanzi/persist/blob/master/list/transient_list.go" target="_blank" rel="noopener">这个文件</a>。</p>
<p>下面是将 Transient 转化为持久化的函数，由于我们预期用户在将 Transient 持久化之后不会再修改原来的 Transient
(尽管无法从代码上保证)，所以我们可以简单地使用类型转换来将 <code>tListHead</code> 转换为 <code>listHead</code>。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *tListHead)</span> <span class="title">Persist</span><span class="params">()</span> <span class="title">List</span></span> &#123;</span><br><span class="line">    perisitHead := (*listHead)(head)</span><br><span class="line">    perisitHead.id = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> perisitHead</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>这篇文章介绍了 Transient 的实现原理和最终实现持久化 List 的方法。可以看出 Transient 是为了提高持久化 List
在连续修改操作下的效率而引进的数据结构，同时引入 Transient 也会简化持久化 List 实现的复杂度。
但是如果用户以不正确的方式使用 Transient ，可能会破坏持久化 List 的持久性。
在 Transient 存在的情况下，持久化 List 的修改操作被实现为先转换为 Transient 并修改，最终将 Transient 持久化这样的方法。</p>
<p>至此，我们就实现了一个功能较为完整的持久化 List 类。持久化 List 类是持久化数据结构当中最容易实现的一种，
但是通过研究它的实现过程，我们可以体会到实现持久化数据结构的一些主要思路。这篇文章的结束宣告 Functional Go
这一系列 Blog 暂时告一段落。下一个系列将会开始探讨另一类非常重要的数据结构 Map 的持久化实现方法(Hash Array Mapped Trie)。</p>
<p>本文实现的代码已经<a href="https://github.com/shanzi/persist/" target="_blank" rel="noopener">开源在 GitHub 上</a>。按照计划，
配合 Blog 的更新，我也会继续将进一步实现的持久化数据结构添加到这一仓库中。
也欢迎各位读者对我实现的代码提出意见建议或反馈 Bug 以及贡献代码。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在之前的文章中，我们介绍了一些持久化数据结构实现的基本原理和 Vector Trie 这一数据结构在 Golang 下的实现过程。
这篇文章终于来到了实现持久化 List 的最后一步: 实现 Transient 和持久化的功能。</p>]]>
    
    </summary>
    
      <category term="Golang" scheme="https://io-meter.com/tags/Golang/"/>
    
      <category term="go" scheme="https://io-meter.com/tags/go/"/>
    
      <category term="functional programming" scheme="https://io-meter.com/tags/functional-programming/"/>
    
      <category term="fp" scheme="https://io-meter.com/tags/fp/"/>
    
      <category term="persist datastructure" scheme="https://io-meter.com/tags/persist-datastructure/"/>
    
      <category term="immutable" scheme="https://io-meter.com/tags/immutable/"/>
    
      <category term="essay" scheme="https://io-meter.com/tags/essay/"/>
    
      <category term="vector trie" scheme="https://io-meter.com/tags/vector-trie/"/>
    
      <category term="Functional Go" scheme="https://io-meter.com/categories/Functional-Go/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Functional Go: Vector Trie 的实现]]></title>
    <link href="https://io-meter.com/2016/09/15/functional-go-implement-vector-trie/"/>
    <id>https://io-meter.com/2016/09/15/functional-go-implement-vector-trie/</id>
    <published>2016-09-15T08:47:52.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p><a href="/2016/09/03/Functional-Go-persist-datastructure-intro/">上一篇</a> 文章介绍了多种实现函数式编程当中持久化数据结构的思路，
其中重点对 Vector Trie 这种数据结构的实现原理进行了解释。这一次我们就使用 Golang 来初步地实现这种数据结构。</p>
<a id="more"></a>
<p>这篇文章是系列文章的一部分，如果还没有浏览过文章的其它部分请参考：</p>
<ol>
<li><a href="https://io-meter.com/2016/09/03/Functional-Go-persist-datastructure-intro/">持久化数据结构简介</a></li>
<li><a href="https://io-meter.com/2016/09/15/functional-go-implement-vector-trie/">Vector Trie 的实现</a> (本文)</li>
<li><a href="https://io-meter.com/2016/10/01/Functional-Go-Transient-and-Persistent/">Transient 及持久化</a> </li>
</ol>
<p>首先我们来回顾一下 Vector Trie 的设计思路，为了代替 ArrayList 这种数据结构以及兼顾高性能的随机访问和内存使用，
Vector Trie 主要采用了以下几种设计：</p>
<ol>
<li>将 ArrayList 连续的地址空间切分成一段一段定长的数组</li>
<li>使用 Trie 树结构将这些分段组织起来</li>
<li>读取和写入的时候，利用 Trie 树检索的方法查找目标元素所在的位置</li>
</ol>
<p>值得注意的是，Vector Trie 作为一种高效的 ArrayList 替代，并非一定要用来实现持久化操作，
在这篇文章当中，我们将会先完成一个不具备持久化能力的 Vector Trie 实现。将 Vector Trie
转变为不可变数据结构以及 Transient 的实现将会留作下一篇文章的内容。</p>
<h2 id="List__u7684_u8BBE_u8BA1"><a href="#List__u7684_u8BBE_u8BA1" class="headerlink" title="List 的设计"></a>List 的设计</h2><p>首先我们定义一些常数：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> (</span><br><span class="line">    SHIFT     = <span class="number">5</span></span><br><span class="line">    NODE_SIZE = (<span class="number">1</span> &lt;&lt; SHIFT)</span><br><span class="line">    MASK      = NODE_SIZE - <span class="number">1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>其中，<code>NODE_SIZE</code> 是 List 内部节点的宽度，这里我们选用了通用的$2^{5}$，也就是 32 作为 Trie 树节点的宽度。
这意味着每个 Trie 树节点将会最多有 32 个子节点。<code>SHIFT</code> 和 <code>MASK</code> 这两个常数将会在我们实现 Trie 树的过程中被用到。</p>
<p>我们将要完成的 List 在 Golang 下接口定义是:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> List <span class="keyword">interface</span> &#123;</span><br><span class="line">    Get(n <span class="keyword">int</span>) (<span class="keyword">interface</span>&#123;&#125;, <span class="keyword">bool</span>)</span><br><span class="line">    Set(n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">    PushBack(value <span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line">    RemoveBack() <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">    Len() <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这一步我们还未考虑持久化的实现，每个操作会直接在原来的基础上进行修改，因此在这里不会返回新的对象。
可以看到，目前的 List 定义非常简单，只包含四种基本的操作和获取当前 List 长度的 <code>Len</code> 方法。</p>
<p>由于我们的 List 是以 Trie 树为基础的，先给出 Trie 节点的定义和构造函数：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> trieNode <span class="keyword">struct</span> &#123;</span><br><span class="line">    children []<span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newTrieNode</span><span class="params">()</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;trieNode&#123;</span><br><span class="line">        children: <span class="built_in">make</span>([]<span class="keyword">interface</span>&#123;&#125;, NODE_SIZE),</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到目前为止我们的内部节点非常简单，结构体只包含一个数组用来保存子节点。
我们要将 List 的值元素保存在 Trie 树最底层的叶子节点，因此使用了<code>interface{}</code>这种通用类型的数组。
这样我们就既可以使用它指向子节点，又可以用来保存值元素。
在这里我为<code>trieNode</code>编写了两个方便的工具函数来分别获取子节点和值。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(node *trieNode)</span> <span class="title">getChildNode</span><span class="params">(index <span class="keyword">int</span>)</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> child := node.children[index]; child != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> child.(*trieNode)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(node *trieNode)</span> <span class="title">getChildValue</span><span class="params">(index <span class="keyword">int</span>)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">    <span class="keyword">return</span> node.children[index]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于在 Trie 树的内部节点中，最底层保存的是值，其它节点的<code>children</code>数组则保存指向子节点的引用，
维护和记录 Trie 树的高度<code>level</code>是必要的。通过<code>level</code>的值访问 Trie 树的时候我们就可以知道什么时候改获取子节点，
什么时候该获得值。这个<code>level</code>在查询 Trie 树的时候也很有用。</p>
<p>作为访问 List 元素的入口， 我们数据的 Head 的定义如下:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> listHead <span class="keyword">struct</span> &#123;</span><br><span class="line">    <span class="built_in">len</span>    <span class="keyword">int</span></span><br><span class="line">    level  <span class="keyword">int</span></span><br><span class="line">    root   *trieNode</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这一结构体保存了 List 的长度、Trie 树的深度以及 Trie 树根节点的引用等信息，我们所有的 List 操作都将会由<code>listHead</code>
来实现，因此它必须服从我们的<code>List</code>接口。</p>
<p><code>listHead</code>的构造函数就是<code>List</code>的构造函数，在这里我们返回一个空的<code>listHead</code>:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">New</span><span class="params">()</span> <span class="title">List</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;listHead&#123;<span class="number">0</span>, <span class="number">0</span>, <span class="literal">nil</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上述定义下，我们的<code>List</code>实现具有如下图所示的结构:</p>
<p><img src="/img/posts/vector-trie-impl.png" alt="Vector Trie"></p>
<p>为了简便起见，图中的 TrieNode 宽度只有 4。在这一结构的基础上，我们就可以实现 List 的一些基本操作了。</p>
<h2 id="Get__u548C_Set"><a href="#Get__u548C_Set" class="headerlink" title="<code>Get</code> 和 <code>Set</code>"></a><code>Get</code> 和 <code>Set</code></h2><p>我们先来看 Vector Trie 的查询和修改操作。这两个操作非常相似，都需要根据给定的 Index 在 Trie 树中找到对应的位置，
区别在于<code>Get</code>操作将会返回目标位置储存的元素而<code>Set</code>操作将会修改它。</p>
<p>Trie 树的中文名称是前缀树，从这个名字当中就可以一窥这类数据结构的查询方法。
简单来说，对于由 $n$ 个 Symbol $s_i$ 组成的关键字 $\mathcal{K}={s_0, s_1, \cdots, s_n}$，
我们先使根节点为当前节点，之后使用 $s_0$ 查询得到的子节点作为当前节点，然后再依次使用 $s_1, s_2, \cdots$
在当前节点上查询得到的子节点作为当前节点，得到一个最终节点作为结果。</p>
<p>具体来说，在这里用户用来查询的关键字 $\mathcal{K}$ 是一个32位类型的整型数。
我们要将这个整形数看作一连串符号的连接，最简单的做法当然是把这个整型树看作其二进制表示，
每隔 $m$ 位看作一个独立的符号，这样从这个整型数的二进制表示的高位开始往下，就依次可以被划分成$s_0, s_1, \cdots, s_n$。
由此我们也就可以将其用于 Trie 的查询。这也是为什么我们选择 $2^{m}$ 作为 TrieNode 的宽度的原因了，
通过使用二进制位运算，我们可以非常快速的从整数当中获得 $s_i$ 的值。在程序中 $m$ 的值由 <code>SHIFT</code> 定义，我们使用 5 作为
$m$，则每个 Symbol 的取值范围则是 $[0, 31]$，恰好是长度 32 的数组当中元素 Index 的范围，得到 Symbol 的值之后，
我们可以直接从数组当中取得目标元素。</p>
<p>下图展示了 $m = 2$ 时的这一过程:</p>
<p><img src="/img/posts/persist-ds-trie-traverse.png" alt="Trie Traverse"></p>
<p>另外需要注意的一点是，我们显然不会直接从 32 位的整数的最高位开始编码 $s_i$。原因在于，当数组元素较少时，
列表里每个元素的 Index 数值都比较小，因此二进制位表示当中高位基本上都是 0， 因此创建这样一连串的只有 0
位置不为空的树是非常不划算的行为，这也是为什么我们要记录和维护当前 Trie 树的高度。</p>
<p>下面给出了 <code>Get</code> 方法的实现。由于 <code>Get</code> 方法是不会修改列表中的元素的，直接使用循环获取到目标元素即可。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">Get</span><span class="params">(n <span class="keyword">int</span>)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">0</span> || n &gt;= head.<span class="built_in">len</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    root := head.root</span><br><span class="line">    <span class="keyword">for</span> lv := head.level - <span class="number">1</span>; ; lv-- &#123;</span><br><span class="line">    index := (n &gt;&gt; <span class="keyword">uint</span>(lv*SHIFT)) &amp; MASK</span><br><span class="line">    <span class="keyword">if</span> lv &lt;= <span class="number">0</span> &#123;</span><br><span class="line">        <span class="comment">// Arrived at leaves node, return value</span></span><br><span class="line">        <span class="keyword">return</span> root.getChildValue(index), <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Update root node</span></span><br><span class="line">        root = root.getChildNode(index)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>Set</code> 操作与之类似，但是我们这里使用递归的方法进行，这样做的目的是为了让 <code>Set</code>
函数在递归调用的每次返回时可以复写当前节点，直至最后复写 <code>root</code> 节点。
但是在未来实现持久化的时候，可以通过返回新的节点的方式获得从根节点到叶子节点这条路径的一个副本。</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">Set</span><span class="params">(n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">0</span> || n &gt;= head.<span class="built_in">len</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(<span class="string">"Index out of bound"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    head.root = setInNode(head.root, n, head.level, value)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setInNode</span><span class="params">(root *trieNode, n <span class="keyword">int</span>, level <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;)</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    index := (n &gt;&gt; <span class="keyword">uint</span>((level<span class="number">-1</span>)*SHIFT)) &amp; MASK</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> level == <span class="number">1</span> &#123;</span><br><span class="line">        root.children[index] = value</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        child := root.getChildNode(index)</span><br><span class="line">        root.children[index] = setInNode(child, n, level<span class="number">-1</span>, value)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> root</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>特别值得注意的是 <code>index = (n &gt;&gt; uint((level - 1)*SHIFT)) &amp; MASK</code> 这一语句了，
它根据<code>level</code>的值计算当前应该用来查询子元素的$s_i$，也就是目标子元素在数组中的位置。
其中 <code>SHIFT = 5</code>，<code>MASK = (1 &lt;&lt; SHIFT) - 1 = 31</code>，<code>MASK</code>的二进制表示从最低位开始向上恰好是 5 个 1，
这样我们就把 <code>n</code> 每 5 位一组分为一个 Symbol 进行查询了。</p>
<h1 id="tail__u4F18_u5316"><a href="#tail__u4F18_u5316" class="headerlink" title="<code>tail</code> 优化"></a><code>tail</code> 优化</h1><p>可以在 List 当中查询和修改元素之后，我们还需要允许在 List 当中添加和删除元素，
不过在此之前，我们要先介绍我们将要采用的一种针对 Vector Trie 的优化手段：<code>tail</code> 优化。</p>
<p>在 Vector Trie 所支持的 4 种基础操作 <code>Get</code>、<code>Set</code>、<code>PushBack</code>和<code>RemoveBack</code>中，
只有后两种会修改列表中所储存的元素长度。同时也只有 <code>PushBack</code> 操作可能会分配新的内存空间。
由于 <code>PushBack</code> 和 <code>RemoveBack</code> 是 List 所应该支持的高频操作，针对这两个操作进行性能优化是一件很有必要的事情。
这两种操作都是直接作用于 List 尾部，参考链表的尾指针的思想，我们容易想到可以直接保留一个指向 Trie
树最末尾元素节点的引用，这样每次对尾部进行操作就不需要进行耗时的 Trie 树查询操作了。</p>
<p>Tail 优化技巧的应用思路如下：</p>
<ol>
<li><code>PushBack</code> 和 <code>RemoveBack</code> 操作直接作用于<code>tail</code>指针所指向的 <code>trieNode</code></li>
<li><code>PushBack</code> 之前如果当前的 <code>tail</code> 已满，则将<code>tail</code>放回到 Trie 树上再创建一个新的</li>
<li><code>RemoveBack</code> 之后，如果当前 <code>tail</code> 已空，则释放当前 <code>tail</code>，并将 Trie 树的最后一个 <code>trieNode</code> 取出作为新的 <code>tail</code></li>
</ol>
<p>我们总是保持 <code>tail</code> 段非空，也就是说 <code>tail</code> 要么是 <code>nil</code>，代表整个 List 当中没有储存任何元素，
要么至少包含一个元素。这样的设计可以简化 <code>RemoveBack</code> 的实现，也可以提高未来可能会提供的 <code>GetLast</code> 等方法的操作性能。</p>
<p>为了实现上述的操作，我们需要维护一个<code>offset</code>值，它代表的是列表中在 <code>tail</code> 节点之前的节点当中储存的元素的数量，
同时也是 <code>tail</code> 节点中下标<code>0</code>的元素在整个 List 当中的 Index。在<code>Get</code>、<code>Set</code>操作之时，我们先检查目标 Index
是否大于等于<code>offset</code>，如果为真，我们就直接在 <code>tail</code> 节点上进行操作。
否则说明目标元素在 Trie 树当中，我们仍然使用之前的 Trie 树操作。
下图展示添加 <code>tail</code> 之后的数据结构：</p>
<p><img src="/img/posts/vector-trie-impl-with-tail.png" alt="Vector Trie with Tail"></p>
<p>修改之后的<code>Get</code>和<code>Set</code>方法如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">Get</span><span class="params">(n <span class="keyword">int</span>)</span> <span class="params">(<span class="keyword">interface</span>&#123;&#125;, <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">0</span> || n &gt;= head.<span class="built_in">len</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n &gt;= head.offset &#123;</span><br><span class="line">        <span class="keyword">return</span> head.tail.getChildValue(n - head.offset), <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get elements in the trie</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">Set</span><span class="params">(n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> n &lt; <span class="number">0</span> || n &gt;= head.<span class="built_in">len</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(<span class="string">"Index out of bound"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> n &gt;= head.offset &#123;</span><br><span class="line">        head.tail = setTail(head.tail, n-head.offset, value)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        head.root = setInNode(head.root, n, head.level, value)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setTail</span><span class="params">(tail *trieNode, n <span class="keyword">int</span>, value <span class="keyword">interface</span>&#123;&#125;)</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> tail == <span class="literal">nil</span> &#123;</span><br><span class="line">        tail = newTrieNode()</span><br><span class="line">    &#125;</span><br><span class="line">    tail.children[n] = value</span><br><span class="line">    <span class="keyword">return</span> tail</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="PushBack__u548C_RemoveBack"><a href="#PushBack__u548C_RemoveBack" class="headerlink" title="<code>PushBack</code> 和 <code>RemoveBack</code>"></a><code>PushBack</code> 和 <code>RemoveBack</code></h2><p>在加入 <code>tail</code> 之后，我们终于可以开始实现把元素插入和删除的操作了，目前我们只支持从数组尾部添加和删除元素。
由于使用了 <code>tail</code> 优化，两个操作的主要实质内容其实都发生在 <code>tail</code> 节点上，
但是在这一过程中需要考虑维护<code>tail</code>节点的问题。</p>
<p>如前文所述，我们如果我们在试图进行<code>PushBack</code>的时候<code>tail</code>中的元素已满，那么我们需要将当前的<code>tail</code>节点放入 Trie 中，
维护和更新<code>offset</code>的值，然后新建一个<code>tail</code>出来并把元素插入到新的<code>tail</code>上。
由于<code>offset</code>是<code>tail</code>当中第一个元素在 List 中的位置，利用这一特点，
我们可以在 Trie 树中找出<code>offset</code>位置的元素应该存在的位置，那里自然也就是<code>tail</code>应该被放置的地方。
参考<code>setInNode</code>的递归实现，我们容易得到如下代码:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">putTail</span><span class="params">(root *trieNode, tail *trieNode, n <span class="keyword">int</span>, level <span class="keyword">int</span>)</span> *<span class="title">trieNode</span></span> &#123;</span><br><span class="line">    index := (n &gt;&gt; <span class="keyword">uint</span>((level<span class="number">-1</span>)*SHIFT)) &amp; MASK</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> root == <span class="literal">nil</span> &#123;</span><br><span class="line">        root = newTrieNode()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> level == <span class="number">1</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> tail</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        root.children[index] = putTail(root.getChildNode(index), tail, n, level<span class="number">-1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> root</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是这一步过程当中存在一个问题，那就是如果当前的 Trie 树也是满的，在放入 <code>tail</code> 之时，
必须先提高 Trie 树的深度，也就是使 <code>level</code> 增加 $1$。Trie 树等层数增长很容易实现，
我们只需要新建一个<code>root</code>节点，然后将原来的<code>root</code>节点设置为新节点的第一个子节点。</p>
<p>那我们该如何判断是否需要进行层增长的操作呢？在这里我们依然要利用<code>offset</code>的特点，
由于在增加后的 Trie 树中<code>offset</code>所代表的 Index 将会可以在 Trie 树中查询到，
因此对于 Trie 树的高度<code>level</code>，必须满足<code>(offset &gt;&gt; (level * SHIFT)) == 0</code>。
通过这个表达式，我们就可以保证在<code>putTail</code>时 Trie 树的层数是足够高的了。</p>
<p>下面的是<code>PushBack</code>的实现代码：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">PushBack</span><span class="params">(value <span class="keyword">interface</span>&#123;&#125;)</span></span> &#123;</span><br><span class="line">    <span class="comment">// Increase the depth of tree while the capacity is not enough</span></span><br><span class="line">    <span class="keyword">if</span> head.<span class="built_in">len</span>-head.offset &lt; NODE_SIZE &#123;</span><br><span class="line">        <span class="comment">// Tail node has free space</span></span><br><span class="line">        head.tail = setTail(head.tail, head.<span class="built_in">len</span>-head.offset, value)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Tail node is full</span></span><br><span class="line">        n := head.offset</span><br><span class="line">        lv := head.level</span><br><span class="line">        root := head.root</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> lv == <span class="number">0</span> || (n&gt;&gt;<span class="keyword">uint</span>(lv*SHIFT)) &gt; <span class="number">0</span> &#123;</span><br><span class="line">            parent := newTrieNode()</span><br><span class="line">            parent.children[<span class="number">0</span>] = root</span><br><span class="line">            root = parent</span><br><span class="line">            lv++</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        head.root = putTail(root, head.tail, n, lv)</span><br><span class="line">        head.tail = <span class="literal">nil</span></span><br><span class="line">        head.tail = setTail(head.tail, <span class="number">0</span>, value)</span><br><span class="line"></span><br><span class="line">        head.level = lv</span><br><span class="line">        head.offset += NODE_SIZE</span><br><span class="line">    &#125;</span><br><span class="line">    head.<span class="built_in">len</span>++</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为我们会保证<code>tail</code>节点非空，所以<code>RemoveBack</code>也总是作用在<code>tail</code>上。它的实现很容易，需要注意的主要有以下3点:</p>
<ol>
<li>如果执行<code>RemoveBack</code>之后<code>tail</code>变成空的，则需要从 Trie 树里取出最后一个<code>trieNode</code>作为新的<code>tail</code></li>
<li>如果执行<code>RemoveBack</code>之后 List 长度变为 0，则直接重置列表到空的状态</li>
<li>如果从 Trie 树中取出节点之后<code>root</code>节点只有一个孩子，那么我们把<code>root</code>节点替换成它的孩子，由此 Trie 的高度减小 $1$</li>
</ol>
<p>下面是从 Trie 当中获得一个节点的代码:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getTail</span><span class="params">(root *trieNode, n <span class="keyword">int</span>, level <span class="keyword">int</span>)</span> <span class="params">(*trieNode, *trieNode)</span></span> &#123;</span><br><span class="line">    index := (n &gt;&gt; <span class="keyword">uint</span>((level<span class="number">-1</span>)*SHIFT)) &amp; MASK</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> level == <span class="number">1</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span>, root</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        child, tail := getTail(root.getChildNode(index), n, level<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> index == <span class="number">0</span> &amp;&amp; child == <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="comment">// The first element has been removed, which means current node</span></span><br><span class="line">            <span class="comment">// becomes empty, remove current node by returning nil</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nil</span>, tail</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// Current node is not empty</span></span><br><span class="line">            <span class="keyword">return</span> root, tail</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为了能使用上述函数获得最后一个<code>trieNode</code>，我们使<code>n = len - 1</code>，也就是最后一个元素 Index。
在取出<code>tail</code>之后，我们需要检查 Trie 是否需要降低层数。由于我们总是保证 Trie 树中的元素编号是从 0
开始连续到达<code>offset - 1</code>的，因此如果<code>root</code>只剩下一个孩子，那么它一定是第<code>0</code>号孩子。
设 Trie 的高度是<code>level</code>，<code>n = offset - 1</code>，那么也就有 <code>(n&gt;&gt;uint((lv-1)*SHIFT)) == 0</code>为真。
通过这个判断我们就可以决定是否降低 Trie 树的层数了。</p>
<p>完整的 <code>RemoveBack</code> 实现如下:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(head *listHead)</span> <span class="title">RemoveBack</span><span class="params">()</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line">    <span class="keyword">if</span> head.<span class="built_in">len</span> == <span class="number">0</span> &#123;</span><br><span class="line">        <span class="built_in">panic</span>(<span class="string">"Remove from empty list"</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    value := head.tail.getChildValue(head.<span class="built_in">len</span> - head.offset - <span class="number">1</span>)</span><br><span class="line">    head.tail = setTail(head.tail, head.<span class="built_in">len</span>-head.offset<span class="number">-1</span>, <span class="literal">nil</span>) <span class="comment">// clear reference to release memory</span></span><br><span class="line"></span><br><span class="line">    head.<span class="built_in">len</span>--</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> head.<span class="built_in">len</span> == <span class="number">0</span> &#123;</span><br><span class="line">        head.level = <span class="number">0</span></span><br><span class="line">        head.offset = <span class="number">0</span></span><br><span class="line">        head.root = <span class="literal">nil</span></span><br><span class="line">        head.tail = <span class="literal">nil</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> head.<span class="built_in">len</span> &lt;= head.offset &#123;</span><br><span class="line">            <span class="comment">// tail is empty, retrieve new tail from root</span></span><br><span class="line">            head.root, head.tail = getTail(head.root, head.<span class="built_in">len</span><span class="number">-1</span>, head.level)</span><br><span class="line">            head.offset -= NODE_SIZE</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Reduce the depth of tree if root only have one child</span></span><br><span class="line">        n := head.offset - <span class="number">1</span></span><br><span class="line">        lv := head.level</span><br><span class="line">        root := head.root</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> lv &gt; <span class="number">1</span> &amp;&amp; (n&gt;&gt;<span class="keyword">uint</span>((lv<span class="number">-1</span>)*SHIFT)) == <span class="number">0</span> &#123;</span><br><span class="line">            root = root.getChildNode(<span class="number">0</span>)</span><br><span class="line">            lv--</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        head.root = root</span><br><span class="line">        head.level = lv</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="u6027_u80FD_u6D4B_u8BD5"><a href="#u6027_u80FD_u6D4B_u8BD5" class="headerlink" title="性能测试"></a>性能测试</h2><p>至此我们的 Vector Trie 就实现了，虽然持久化的功能尚未完成，但是我们已经拥有了一个可用的 List 容器类。
接下来让我们测试一下这一容器的性能。我编写了如下的 Benchmark 代码:</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkPushBack</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line">    list := New()</span><br><span class="line">    <span class="keyword">var</span> v <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">        list.PushBack(v)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkGet</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line">    mask := (<span class="number">1</span> &lt;&lt; <span class="number">10</span>) - <span class="number">1</span></span><br><span class="line">    list := generateList(<span class="number">0</span>, mask+<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">        list.Get(i &amp; mask)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkSet</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line">    mask := (<span class="number">1</span> &lt;&lt; <span class="number">10</span>) - <span class="number">1</span></span><br><span class="line">    list := generateList(<span class="number">0</span>, mask+<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> v <span class="keyword">interface</span>&#123;&#125; = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">        list.Set(i&amp;mask, v)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">BenchmarkRemoveBack</span><span class="params">(b *testing.B)</span></span> &#123;</span><br><span class="line">    mask := (<span class="number">1</span> &lt;&lt; <span class="number">20</span>) - <span class="number">1</span></span><br><span class="line">    list := generateList(<span class="number">0</span>, mask+<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; b.N; i++ &#123;</span><br><span class="line">        <span class="keyword">if</span> list.Len() &gt; <span class="number">0</span> &#123;</span><br><span class="line">            list.RemoveBack()</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            b.StopTimer()</span><br><span class="line">            list = generateList(<span class="number">0</span>, mask+<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            b.StartTimer()</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>值得注意得是，在 Golang 中将原始数据类型如<code>int</code>等转换为<code>interface{}</code>其实会产生内存分配操作，
因此会拖慢程序的运行，为了了解原始的操作性能，<code>Set</code>和<code>PushBack</code>操作使用的都是固定的<code>value</code>。
<code>Get</code>操作则是在一个长度为 $1024$ 的 List 上进行循环的读操作。下面是 Benchmark 的结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BenchmarkPushBack-2     20000000           67.8 ns/op       34 B/op     0 allocs/op</span><br><span class="line">BenchmarkGet-2          100000000          11.4 ns/op        0 B/op     0 allocs/op</span><br><span class="line">BenchmarkSet-2          50000000           20.6 ns/op        0 B/op     0 allocs/op</span><br><span class="line">BenchmarkRemoveBack-2   50000000           25.3 ns/op        0 B/op     0 allocs/op</span><br></pre></td></tr></table></figure>
<p>由此可见，我们实现的 Vector trie 在 <code>Get</code>、<code>Set</code>和<code>RemoveBack</code>上的性能比较让人满意，基本控制在<code>30ns</code>以下，
<code>PushBack</code>操作的时间略高于预期，经过进一步的分析发现时间主要花费在<code>runtime.scanobject</code>方法上，
也就是说 Golang 自己的 GC 性能影响了我们的实现性能。在未来也许可以对我们<code>PushBack</code>时所进行的内存操作进行进一步的优化，
从另一个角度来说，Golang 自己的 GC 性能也还有进一步提升的空间。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>在这篇文章中，我们初步实现了不带持久化功能的 Vector Trie 并对其进行了简单的性能分析。</p>
<p>从当前的实现中已经可以看到将其转变为不可变数据结构的曙光。在下一篇文章中我们将会继续讨论 Vector Trie，
给出将其变化为不可变数据结构的最终实现方法和使其具备高性能读写的 Transient 数据结构的实现。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="/2016/09/03/Functional-Go-persist-datastructure-intro/">上一篇</a> 文章介绍了多种实现函数式编程当中持久化数据结构的思路，
其中重点对 Vector Trie 这种数据结构的实现原理进行了解释。这一次我们就使用 Golang 来初步地实现这种数据结构。</p>]]>
    
    </summary>
    
      <category term="Golang" scheme="https://io-meter.com/tags/Golang/"/>
    
      <category term="go" scheme="https://io-meter.com/tags/go/"/>
    
      <category term="functional programming" scheme="https://io-meter.com/tags/functional-programming/"/>
    
      <category term="fp" scheme="https://io-meter.com/tags/fp/"/>
    
      <category term="persist datastructure" scheme="https://io-meter.com/tags/persist-datastructure/"/>
    
      <category term="immutable" scheme="https://io-meter.com/tags/immutable/"/>
    
      <category term="essay" scheme="https://io-meter.com/tags/essay/"/>
    
      <category term="vector trie" scheme="https://io-meter.com/tags/vector-trie/"/>
    
      <category term="Functional Go" scheme="https://io-meter.com/categories/Functional-Go/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Functional Go: 持久化数据结构简介]]></title>
    <link href="https://io-meter.com/2016/09/03/Functional-Go-persist-datastructure-intro/"/>
    <id>https://io-meter.com/2016/09/03/Functional-Go-persist-datastructure-intro/</id>
    <published>2016-09-03T09:16:15.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>函数式编程模型因其天生对并发具备良好的支持，近些年来越来越受到重视。从这篇文章开始，
我将以一个系列的博客来记录函数式编程的一个重要组件：持久化数据结构在 Go 语言下的实现。</p>
<a id="more"></a>
<p>这篇文章是系列文章的一部分，如果还没有浏览过文章的其它部分请参考：</p>
<ol>
<li><a href="https://io-meter.com/2016/09/03/Functional-Go-persist-datastructure-intro/">持久化数据结构简介</a> (本文)</li>
<li><a href="https://io-meter.com/2016/09/15/functional-go-implement-vector-trie/">Vector Trie 的实现</a></li>
<li><a href="https://io-meter.com/2016/10/01/Functional-Go-Transient-and-Persistent/">Transient 及持久化</a> </li>
</ol>
<p>函数式编程不是新概念，像 Haskell、Clojure、Scala 等函数式／类函数式编程语言也已经出现和存在了很长时间，
很多函数式编程的概念现今已经被应用在很多其他领域，比如 Facebook 在 <a href="https://facebook.github.io/react/" target="_blank" rel="noopener">React</a>
的基础上提出的 <a href="https://facebook.github.io/flux/" target="_blank" rel="noopener">Flux</a> 应用结构抽象就强调了引入持久化数据结构的好处。
事实上，Facebook 还开源了自己的 JavaScript 持久化数据结构实现 <a href="https://facebook.github.io/immutable-js/" target="_blank" rel="noopener">ImmutableJS</a>。
尽管之前已经有 <a href="http://elm-lang.org/" target="_blank" rel="noopener">Elm</a> 这样更纯粹的函数式实现，Facebook 的 React + Flux + ImmutableJS
还是为在一般的前端开发提供了第一个被大规模应用的案例和流行的契机。</p>
<p>尽管很早之前就对函数式编程感兴趣，但是引起我对持久化数据结构兴趣的还是 ImmutableJS，
通过在 React 应用里使用它，我体会到持久化数据结构在很多方面的应用潜力。为了将持久化数据结构应用于 Go
语言编写的后端程序，也为了更好理解这类数据结构的实现，我决定亲自动手用编写这样一套程序。</p>
<p>作为系列博客的第一篇，这篇博客将会先给出一些持久化数据结构的简介并以最简单的 List （列表）数据结构为例，
介绍一些常见的持久化数据结构实现方法。这一个系列的文章都主要参考了
<a href="http://hypirion.com/musings/understanding-persistent-vector-pt-1" target="_blank" rel="noopener">Understanding Persistent Vector</a>
这篇非常经典的文章，其中一些章节甚至可以看作是对它内容的翻译。建议有兴趣的读者浏览原文作为参考。</p>
<h2 id="u6301_u4E45_u5316_u6570_u636E_u7ED3_u6784_u7B80_u4ECB"><a href="#u6301_u4E45_u5316_u6570_u636E_u7ED3_u6784_u7B80_u4ECB" class="headerlink" title="持久化数据结构简介"></a>持久化数据结构简介</h2><p>持久化(Persistent)数据结构又叫不可变(Immutable)数据结构，顾名思义，这类数据结构的内容是不可变的。
也就是说，对于这类数据结构的修改操作，都会返回一个新的副本，而原来的数据结构保存的内容不会有任何改变。
这样的数据结构是有意义的，比方说我们现在所编写的所有程序，都可以看作是一个状态机，
也就是说在程序运行的过程的每一个时刻，程序本身可以被看作存在一个状态(State)，我们的语句作用在当前状态上，
从而不断地产生出进一步的状态，由此循环往复。如果按照这样的模型，那么就存在两个可能的问题需要解决：</p>
<ol>
<li>我们的有些行为可以看作一系列对状态的修改，比如说通过一个函数内的一系列操作来实现一个功能，
先读出数据库里的内容来进行修改等。这时，我们希望这一连串操作是原子的。也就是说整个过程要么全部成功，
要么全部失败。这样的要求在数据库里是通过事务(Transaction)来实现的，某些编程语言(如Haskell)也提供了类似的方案，
而持久化数据结构也是解决这一问题的一种方法——将原来的状态保存在不可变的数据结构中，
只有当整个操作成功完成再将生成的新状态替换回去，这样系统就不会进入过程错误导致的中间状态。</li>
<li>在并发程序中，一个函数的执行可能会带有副作用——同样的输入和函数，
得到的返回结果却可能不一样。比方说，将一个数组传递进一个函数进行遍历处理，在函数执行的过程中，
另一个线程修改了数组的内容，这样就产生的线程同步等复杂的问题，增加了程序出现问题的可能性，也增加了 Debug 的难度。
由于持久化数据结构本身不会被修改，因此将它传入一个函数是安全的，任何对他的修改都表现在一个新的对象上，
因此你传入函数的输出并不会被影响。</li>
</ol>
<p>有些数据结构的实现为了在并发条件下安全运行，比如使用一些方法为数据结构加锁，
这一行为实际上会增加数据结构实现的难度和运行性能， 持久化数据结构不会改变原来的状态，自然也就不会有加锁的必要。 
事实上，持久化数据结构天生是一种无锁的数据结构。</p>
<p>当然，持久化数据结构也有一些缺陷，主要体现在以下几个方面：</p>
<ol>
<li>由于持久化数据结构在修改时需要生成新的对象，因此往往会比普通数据结构更加耗费内存空间。因此，
任何持久化数据结构在设计上都要考虑如何节省空间这一问题</li>
<li>持久化数据结构往往是在原始数据结构上的包装，通过更复杂的操作保证原始数据结构的数据的不变性，
这不但体现在修改操作上，也体现在读取操作上。因此持久化数据结构的读写速度往往会慢于普通数据结构，
其实现也更复杂</li>
<li>持久化数据结构脱胎于函数式编程，与一般的过程式编程语言在思维模式上差别比较大，
操作起来也有很大不同，因此对于习惯了传统过程式编程语言的学习者来说接受起来有一定的困难</li>
</ol>
<p>尽管如此，持久化数据结构仍然有很大的应用空间，下面给出它们的一些应用场景。</p>
<h2 id="u6301_u4E45_u5316_u6570_u636E_u7ED3_u6784_u7684_u5E94_u7528"><a href="#u6301_u4E45_u5316_u6570_u636E_u7ED3_u6784_u7684_u5E94_u7528" class="headerlink" title="持久化数据结构的应用"></a>持久化数据结构的应用</h2><p>持久化数据结构在很多情况下是有优势的，虽然大部分数据库帮我们实现了事务模型，
让我们可以安全放心的使用，但是在大多数其他软件系统中并没有现成的事务工具供我们使用，
事务模型依赖于对数据操作的记录，如果运行失败需要对状态进行 Rollback，这不但是一个很难实现的功能，
Rollback 过程也需要花费不少时间。相比起来持久化数据结构就成了一种更容易获得的选择。
实际上，除去 Clojure、Scala 等这种自带了持久化数据结构的编程语言，
绝大部分编程语言都有成熟可靠的开源库提供了此类数据结构。</p>
<p>在 React + Flux 模型中，不可变数据结构还被用来加速状态改变的对比，因为 React 
依赖于对比前后两个状态之间的改变来发现需要对 Virtual DOM 进行的最小改变，因此必须要保留每一次修改之后的状态。
所有的操作都必须通过<code>setState</code>方法进行，很难保证之前的状态没有被其他地方意外的修改，而对比本身也是耗时的。
但是在引入<code>ImmutableJS</code>后，每个 View 的状态就可以很安全的保存起来了。由于在 React 里，<code>state</code>
改变总是从一个最初的状态衍生而来的一系列状态，在对前后两个状态进行递归的比较时，如果两个对象的引用是一样的，
那么它们一定是一个不可变的对象，如果两个对象的引用不一致，那么一定经过了修改。因此通过这样的优化可以加速比较的过程。</p>
<p>持久化数据结构的另一个应用是实现文件系统的 Copy on Write 功能，很多文件系统以及虚拟机(VirtualBox)和容器(Docker)
都提供 Snapshot 的功能，也就是说你可以保存文件系统在某一时刻的完整状态并在未来某个时间方便地恢复到当前状态。
这在部署服务的时候非常有用——如果新上线的系统出现问题，我们可以快速简单地回复到原来正常的状态。
传统的 CoW 实现是在某一文件修改的过程时候再复制它，这种实现在遇到比较大的文件时是比较浪费空间的。
然而很多持久化数据结构的实现本身就考虑到了节省空间的问题，因此可以很大程度上缓解这一问题。也就是说，
对于一个文件，我们可以只在写入的时候复制其中一小部分来实现块级别的 CoW。
在接下来的文章中我们可以看到，Vector trie 这种数据结构就很适合实现这一功能。</p>
<p>持久化数据结构的最广泛的应用还是在并发编程当中，结合函数式编程的模型实现高性能且安全易于预测的代码编写。
在一些多人联机系统(协作工具、联机游戏)当中，多个用户会并发地对某一个中心的状态进行修改，而这个中心状态还需要定期的保存。
使用不可变数据结构，每一个被传入的状态都是当时状态的不可变的快照，因此我们可以安全的在一个新的线程上执行保存操作。
这提高了我们程序的并发性。</p>
<h2 id="u6301_u4E45_u5316_u6570_u636E_u7ED3_u6784_u7684_u5B9E_u73B0"><a href="#u6301_u4E45_u5316_u6570_u636E_u7ED3_u6784_u7684_u5B9E_u73B0" class="headerlink" title="持久化数据结构的实现"></a>持久化数据结构的实现</h2><p>在介绍了持久化数据结构的特点和应用之后，我们以最简单的顺序储存结构 List
(列表)为例，从简入繁介绍几种实现不可变数据结构的方法和思路。</p>
<p>首先，我们把 List 定义为一种顺序储存结构，它所保存的元素从 0 开始编号，依次向后储存。
这一储存结构包含如下几种基础的操作：</p>
<ol>
<li><code>New</code> 新建一个 List</li>
<li><code>Get(index)</code> 获得指定 Index 的元素</li>
<li><code>Set(index, value)</code> 修改指定 Index 的元素</li>
<li><code>PushBack(value)</code> 在 List 末尾添加一个元素</li>
<li><code>RemoveBack(value)</code> 从 List 末尾去除一个元素</li>
</ol>
<p>此外，这个 List 可能还可以支持如下的一些操作，它们都可以用上面方法来实现(尽管有些数据结构支持更直接的方法)：</p>
<ol>
<li><code>Insert(index, value)</code> 在指定位置插入一个元素</li>
<li><code>Remove(index, value)</code> 在指定位置删除一个元素</li>
<li><code>Slice(i, j)</code> 获得 List 当中 <code>i</code> 到 <code>j</code> 之间元素的一个切片</li>
<li><code>Splice(i, j, List)</code> 将 List 当中 <code>i</code> 到 <code>j</code> 之间的元素替换为传入的 List 当中的元素</li>
</ol>
<p>在实现持久化数据结构的过程中，我们主要考虑的问题是每一种操作的时间消耗和数据结构的空间效率。
我们的目标自然是寻找一种在空间和时间上都比较有效的解决方案，然而也需要注意到各种不同的思路都有比较适合的使用场景，
并不存在在各种情况下都最佳的实现。</p>
<p>在讨论的过程中，除了使用大 O 表示法来衡量数据结构的时间效率，
还使用数据元素所占空间除以数据结构使用的总空间所得的比例来衡量数据结构的空间效率。</p>
<h3 id="u6570_u7EC4"><a href="#u6570_u7EC4" class="headerlink" title="数组"></a>数组</h3><p>数组是最简单的线性储存结构了，它在 C++ 中是 <code>vector</code> ，在 Java 中是 <code>ArrayList</code>，在 Golang 中则是 <code>slice</code>。
数组本质上是一段连续的内存空间，数据元素一个接着一个的摆放。</p>
<p>一般来讲，数组在创建时会预先分配一部分空间，当<code>PushBack</code>操作用完已经分配的所有空间之后，
需要分配一块大小为原来 2 倍(Java 中是 1.5 倍)的空间，再将原来的数据拷贝过来。显然，在现今的内存模型中，
对于数组元素进行 <code>Get</code> 和 <code>Set</code> 操作的时间复杂度都是 $O(1)$ 的，也就是说数组数据结构特别适合随机访问。
尽管在空间耗尽的时候需要进行空间倍增和复制的操作，但是均摊下来，每次 <code>PushBack</code> 操作的时间复杂度也是 $O(1)$ 的。</p>
<p>尽管看起来倍增操作让数组比较浪费空间，但是实际情况下数组数据结构是空间利用率最高的数据结构之一，
譬如说对于 Java 来说，平均的空间效率是 75% 。</p>
<p>这些特点使得数组成为最常用的数据结构之一，它同时也是一些其他数据结构(如 Hash 表)的基础。但是对于数组来说，
<code>Insert</code>、<code>Remove</code> 和 <code>Splice</code> 操作的时间复杂度都比较高($O(N)$)。数组的另一个缺点在于如果数据量较大，
倍增时需要分配非常大的空间可能是比较困难的。</p>
<p>数组作为我们通向持久化数据结构的引子，其本身并非一个合适的选择——如下图所示，如果我们要保证每次修改时原来的数据不会被修改，
唯一的办法是将所有的数据复制一遍。接下来我们可以看到，在数组基础上进行的一些改进将有助于解决这一问题。</p>
<p><img src="/img/posts/persist-ds-array.png" alt="ArrayList"></p>
<h3 id="u94FE_u8868"><a href="#u94FE_u8868" class="headerlink" title="链表"></a>链表</h3><p>上面我们提到过，数组类型的数据结构一个比较大的问题就是需要分配大块连续的空间，这在内存比较紧张的环境下可能比较困难，
另外一个巨大的缺点在于由于数组是必须是连续的空间，导致如果我们想在它的基础上实现持久化数据结构比较困难。</p>
<p>一种解决方案是链表，链表的特点是将储存的每个数据拆开来存放，对于简单的单链表来说，
每一个数据单元包括一个数据字段和一个指针字段。每个指针指向当前单元的下一个单元或者 <code>NULL</code> 代表链表的结束。
如果使用链表结构，<code>Get</code> 和 <code>Set</code> 的平均时间复杂度都是 $O(N)$，尽管如此，在末尾插入和删除数据的 <code>PushBack</code>
和 <code>RemoveBack</code> 可以实现为 $O(1)$。实际上，链表特别适合这种频繁在头部和尾部进行增删操作的使用场景，
因此特别适合作为队列或者栈。如果将链表作为顺序储存结构，那么在进行数据修改的时候，我们可以复用所有当前修改之后的数据单元，
如下图所示，我们将第二个单元的数据 <code>b</code> 改为 <code>e</code> ，只需要将其之前的 <code>a</code> 所在的单元也复制一遍，由此节省了不少空间。</p>
<p><img src="/img/posts/persist-ds-linkedlist.png" alt="LinkedList"></p>
<p>实际上，链表实现的栈是持久化栈实现的理想数据结构，假定我们保留一个指向栈顶的<code>HEAD</code>指针，那么当我们在栈中进行<code>Push</code>
和<code>Pop</code>操作的时候，只需要复制<code>HEAD</code>指针以及修改指向的位置即可，下图的<code>HEAD0</code>、<code>HEAD1</code>、<code>HEAD2</code>分别代表原始栈、
<code>Pop</code>一次、<code>Push</code>一次之后整个栈的结构关系。可以看到，只要我们记录下操作过程中的<code>HEAD</code>，就可以获得对应状态的一个快照，
这些快照本身不知晓其他快照的存在，但是却共享了大部分空间。</p>
<p><img src="/img/posts/persist-ds-linkedstack.png" alt="LinkedStack"></p>
<p>然而链表作为一种顺序储存结构，其缺点也是很明显的。首先就是对随机数据访问的支持较差，每次访问一个数据单元，
都要遍历之前所有的单元，此外链表的空间效率也很低——由于每个数据单元必定至少包含一个指针字段，
链表的数据效率根本无法超过 50% 。</p>
<h3 id="u4E32"><a href="#u4E32" class="headerlink" title="串"></a>串</h3><p>为了解决链表存在的问题，一个很自然的想法就是增加一个数据单元当中数据字段本身所占有的比例，
这就是串的实现原理：在每个结构体当中用一个固定长度的数组储存数据。这样的做法不但增加了空间效率，
也提高了<code>PushBack</code>操作的时间效率。使用串，在每次之前分配的空间用完的时候，只需要分配一个相对较小的新的数据单元，
而不需要像数组那样倍增并复制所有的数据。串可以看作数组和链表相结合所产生的数据结构，
它具有很不错的顺序访问性能，特别是串的长度恰好可以被放进 CPU 的 Cache 当中时它不会像链表那样需要频繁从内存调入下一个单元。
用串实现持久化数据结构的时候，需要将所修改数据所在单元以及之前的数据都复制一遍，稍稍比链表更冗余一些，
但是由于串本身的空间效率很高，所以实际上还是非常划算的。</p>
<p><img src="/img/posts/persist-ds-string.png" alt="String"></p>
<p>串在实际生活中的应用不少，比如早期 Windows 的文件系统 FAT32 和 NTFS，每个文件在磁盘上就是组织为一块块数据组成的串，
但是串跟链表的缺点很像，它们都缺乏随机访问数据的能力。有没有一种数据结构能在<code>Get</code>、<code>Set</code>、<code>PushBack</code>和<code>RemoveBack</code>
上都表现出相当好的时间效率呢？其中一种常见的解决方案是平衡树。</p>
<h3 id="u5E73_u8861_u6811"><a href="#u5E73_u8861_u6811" class="headerlink" title="平衡树"></a>平衡树</h3><p>平衡树是一系列数据结构的统称，它包括各种平衡二叉树，如 AVL 树、红黑树等，也包括常用的多叉平衡树如 B+ 树、 B- 树等。
由于这些基本的数据结构不是本文的重点，本文不会对其具体实现进行逐个详细的介绍，如下是一棵红黑树的示例。</p>
<p><img src="/img/posts/persist-ds-rbtree.png" alt="Red Black Tree"></p>
<p>以平衡二叉为例，一般的二叉树都可以保证<code>Get</code>、<code>Set</code>、<code>Insert</code> 和 <code>Remove</code> 等操作具备 $O(\log N)$ 的最差时间复杂度，
在很多情况下已经非常优秀，最重要的一点是<strong>一些平衡二叉树每次操作最多修改 $O(\log N)$ 个内部节点</strong>。
这启发我们，如果我们把所有这些修改节点的操作变为复制，那么就能在不改变原来数据的情况下，获得新的数据的一个快照！
使用这种方式，我们可以在没有明显时间效率损失的情况下极大程度地复用原来空间。</p>
<p>事实上，平衡树确实是非常流行的持久化数据结构实现方案，在很多情况下它的时间效率都令人满意。
然而，平衡树的空间效率相当低下，拿一般的平衡二叉树来说，
每个数据节点至少包含一个数据字段和两个指针字段，还可能需要其他字段储存信息以便于获得快速平衡二叉树的能力，
因此它们的空间效率一般最多在 30% 左右，在有些情况下并不能让人满意。</p>
<h3 id="Vector_trie"><a href="#Vector_trie" class="headerlink" title="Vector trie"></a>Vector trie</h3><p>终于来到了我们要介绍的重点: Vector trie 。Vector trie 可以看作将前述的几种数据结构的思路相结合的产物，
首先我们可以观察到如下两点：</p>
<ol>
<li>串数据结构虽然具有较好的空间效率，但是却缺乏随机访问的时间效率</li>
<li>树数据结构虽然有较好的操作性能，但是空间效率和顺序访问的时间效率较差</li>
</ol>
<p>那么如果我们将两种数据结构结合起来是否能构造一个在两方面都表现优秀的数据结构呢？答案是肯定的。
将两种数据结构结合起来的是一种新的数据结构 trie (前缀树)。关于前缀树的特点这里不再赘述，
不了解的读者可以先查询 <a href="https://zh.wikipedia.org/wiki/Trie" target="_blank" rel="noopener">Wikipedia 上的介绍</a>。
下图是一个 Vector trie 的示意图。</p>
<p><img src="/img/posts/persist-ds-vector-trie.png" alt="Vector Trie"></p>
<p>可以看到，在这种数据结构当中，所有的数据都保存在树的叶子节点，因此树的最下一层叶子节点实际上可以被看成是串，
唯一的区别是，不同于串使用末尾的指针指向下一个数据单元，Vector trie 使用 Trie
树结构作为每个数据节点的索引。在 Vector trie 当中，每次检索都从根开始，依次经过多个中间节点到达叶子节点并获得数据。</p>
<p>在实际使用中，一个内部节点的子节点被组织成数组，那么我们就可以方便地使用
Index 二进制作为 Trie 查询的依据，以一个固定宽度的窗口依次获得应该由当前节点进入哪个子节点。
如下图所示，我们以两位为单位，依次由根访问到叶子节点，最终到达目的数据所在的位置
(为简便起见，大多数 Trie 节点被省略)。</p>
<p><img src="/img/posts/persist-ds-trie-traverse.png" alt="Trie Traverse"></p>
<p>在第一张图中我们使用的每个内部节点有两个孩子节点，因此实际上退化成了二叉树，这样几个基本操作的时间复杂度都在
$O(\log N)$。 在实际实现中，Vector trie 一般使用有 32 个分支的内部节点，整个树的结构更加扁平化，
操作的时间效率也更高——一般来说为 $O(\log_{32} N)$，考虑到一般的顺序储存结构的最大容量只有
$2^{32}$，因此在 Vector trie 上进行的各项操作的时间复杂度可以认为是 $O(7)$
也就是常数时间的的操作。当然，$O(\log_{32} N) \neq O(1)$，但是很多 Vector trie 的实现为了宣传的目的，
都自诩为常数时间的时间复杂度，这也给初学者造成了一定的困惑。</p>
<p>下图揭示了 Vector trie 如何实现持久化，和一般的树结构一样，每次修改操作的时候，
我们复制从根到叶子节点的路径而不是直接修改它们，这样从两个根我们就可以访问到对数据不同时刻的两个快照。</p>
<p><img src="/img/posts/persist-ds-vector-trie-immutable.png" alt="Immutable VectorTrie"></p>
<p>Vector trie 实现持久化数据结构的基本原理由此就介绍清楚了，但是在实际为了进一步进行性能的优化还会做一些诸如
Tail 节点、Transient 实现等优化，这些内容将会留在以后进一步介绍。</p>
<p>那么 Vector trie 的时间和空间效率如何？根据
<a href="http://hypirion.com/musings/persistent-vector-performance" target="_blank" rel="noopener">Persistent Vector Performance</a> 这篇博客的介绍，
对于 <code>Get</code>，<code>Set</code> 等操作，Vector trie 确实跟一般宣传的相似，相比简单的 Array 只有一个接近常数级别的放大。
而如果利用 Transient 优化，在<code>PushBack</code>等操作上甚至有超越 Array 的趋势。更进一步，经过 Benchmark 所选择的
32 这个分支系数，也让 Vector trie 可以在常见 CPU 结构的 Cache 系统中表现出优异的顺序访问性能。另一方面，在空间使用上
Vector trie 平均有一个接近甚至超过 90% 的空间效率，令人十分印象深刻。由此可见 Vector trie
是一种理想的用于实现持久化的数据结构。</p>
<p>实际上，包括 Clojure、Scala 在内的多种编程语言都选择了这种数据结构作为持久化数组的实现。同样，
Vector trie 的索引结构也很接近一些文件系统对文件的索引结构，因此也就可以方便的被应用于实现文件系统的 Snapshot
和 Copy on Write 功能。</p>
<p>Vector trie 和普通的 Array 一样，在 <code>Insert</code>、<code>Splice</code> 等操作上时间效率很低，这是它主要的问题之一。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了函数式编程中常见的持久化数据结构的优点和常见应用，并以持久化数组为例，逐步探讨了几种实现思路。
其中 LinkedList 很适合用来实现持久化栈，而平衡树和 Vector trie 在实现持久化数组上各有优势。
我们最后选择了 Vector trie 做为我们将要使用 Golang 实现的对象。</p>
<p>当然，常用来实现持久化数据结构的方法不仅限于这些，本文尚未涉及到的一种更高级的数据结构是
<a href="https://en.wikipedia.org/wiki/Finger_tree" target="_blank" rel="noopener">Finger Tree</a>，这种数据结构在 Haskell 编程语言的部分库中得到了应用。</p>
<p>按照计划，下一篇博客将会介绍不带持久化功能的 Vector trie 的简单实现过程，再之后将会给出
vector trie 实现持久化功能的过程并介绍 Transient 的实现原理。</p>
<p>敬请期待。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>函数式编程模型因其天生对并发具备良好的支持，近些年来越来越受到重视。从这篇文章开始，
我将以一个系列的博客来记录函数式编程的一个重要组件：持久化数据结构在 Go 语言下的实现。</p>]]>
    
    </summary>
    
      <category term="Golang" scheme="https://io-meter.com/tags/Golang/"/>
    
      <category term="go" scheme="https://io-meter.com/tags/go/"/>
    
      <category term="functional programming" scheme="https://io-meter.com/tags/functional-programming/"/>
    
      <category term="fp" scheme="https://io-meter.com/tags/fp/"/>
    
      <category term="persist datastructure" scheme="https://io-meter.com/tags/persist-datastructure/"/>
    
      <category term="immutable" scheme="https://io-meter.com/tags/immutable/"/>
    
      <category term="essay" scheme="https://io-meter.com/tags/essay/"/>
    
      <category term="Functional Go" scheme="https://io-meter.com/categories/Functional-Go/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[用 Go 写个小工具：wu 的炼成]]></title>
    <link href="https://io-meter.com/2016/08/14/build-a-go-commmand-line-tool/"/>
    <id>https://io-meter.com/2016/08/14/build-a-go-commmand-line-tool/</id>
    <published>2016-08-14T10:02:47.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>最近使用 Golang 编写完成了一个命令行下的小工具: <a href="https://github.com/shanzi/wu" target="_blank" rel="noopener">wu</a>，
这个小工具的主要用途是监视文件改动并执行指定的命令。尽管有点重新发明轮子的嫌疑，
但是设计和实现它的过程中我还是有不少收获的。</p>
<a id="more"></a>
<p>我很早就对 Golang 有兴趣了，之前在没有经过系统学习的情况下跌跌撞撞地完成了一个很小的应用，
并最终总结成 <a href="https://io-meter.com/2014/07/09/simple-git-http-server/">自己动手写 Git HTTP Server</a> 这篇文章，
之后又稍微研究和总结了一下现有的 <a href="https://io-meter.com/2014/07/30/go&#39;s-package-management/">Go 语言的包依赖管理</a>。</p>
<p>自那以后，Go 语言又有了一些新的进展，比如从 1.6 版本引入的 <code>vendor</code> 的概念， 
算是在解决包管理问题上的出现新趋势，也催生出 <a href="https://github.com/kardianos/govendor" target="_blank" rel="noopener">govendor</a>
这样新的工具出来。</p>
<p>不过包管理并不是这篇文章想要主要讨论的问题。此前，通过 <a href="http://www.gopl.io/" target="_blank" rel="noopener">The Go Programming Language</a>
这本书，我系统地对 Go 语言各个方面的使用以及部分设计和实践有了更全面的了解，
因此这次以更加“正确”的方法实现了 wu 这个小工具，在此将从构思到实现各方面的思考记录一些下来，
也算是分享一点经验。在这篇文章中，我们会谈到<code>os/exec</code>、<code>flag</code>、<code>time</code>、<code>encoding/json</code>、<code>os/signal</code>等库的使用。</p>
<p>wu 的代码已经<a href="https://github.com/shanzi/wu/" target="_blank" rel="noopener">开源在 GitHub 上</a>并提供 macOS 和 Linux 平台下
<a href="https://github.com/shanzi/wu/releases" target="_blank" rel="noopener">编译好的可执行文件</a>。</p>
<h2 id="u6784_u601D_u548C_u51C6_u5907"><a href="#u6784_u601D_u548C_u51C6_u5907" class="headerlink" title="构思和准备"></a>构思和准备</h2><p>在开始着手实现之前，对于要写什么和怎么实现等方面都进行了一些思考。简单来说，
我首先确定了想要写一个通过监听文件系统修改，从而可以自动重启命令的工具。
写这样一个工具的原因是部分 Light weight 的 web framework 并没有内置自动重新加载的功能。
这样每次修改完代码就需要手动的结束原来的 Server 并重新启动。写一个小工具来自动化这一过程看起来是个不错的主意。</p>
<p>在进一步的构思之前，我简单的进行了一些检索，参考了一些同类的工具（主要是 NodeJS 社区内的一些解决方案），
确定了一些实现的目标：</p>
<ol>
<li>这个工具应该非常简单和轻量，它所完成的事情就应该是简单的监视文件和执行命令，
最多添加一些简单的配置，不应需要繁复的设置</li>
<li>这个工具应该具有最少的依赖，相比于 Gulp 和 Grunt 等 NodeJS 的解决方案，
这一工具应该可以说以便携式可执行文件的方式分发，这也是选择 Go 来实现的一个优势</li>
<li>可配置，应该有一个简单的配置文件，使得用户可以记录下来执行的选项，从而不需要每次敲打复杂的命令</li>
</ol>
<p>以上三点决定了 wu 的大部分设计，除此之外，在实现之前我也预先考虑了一下可能遇到的问题：</p>
<ol>
<li>进程通讯的问题：因为 wu 本质上是需要通过启动子进程来运行命令的，因此就需要考虑如何与子进程进行通讯，
如何获得子进程运行的状态，如何强制结束子进程等等问题都需要事先进行一定的研究</li>
<li>并发和并行的问题：除了需要启动和维护子进程，我们的工具还要侦听文件系统的改变，
随着用户的操作很多事件会并发的产生，如何正确地处理这些并发也是一个重要的问题。
幸好我们是在使用 Golang 解决这一问题，在很多地方 Go 语言确实为并发控制提供了很棒的解决方案。</li>
<li>多个文件同时写入问题：这个问题和并发问题比较类似，因为用户可能同时写入多个文件，
这时激发多次进程重启绝不是我们想要的结果。把一段时间内接受到的写入事件合并成一个来处理是一种可能的解决方案。</li>
</ol>
<p>我们的应用的主要流程大体上可以用下图表示：</p>
<p><img src="/img/posts/wu-main-loop.png" alt="Main Loop"></p>
<p>从图中可以看出应用的主循环是不断的 Start 和 Terminate 子进程的过程。其中只有红色的<code>Wait and gather changed files</code>
步骤会处理文件系统传来的信号，这一步骤也是阻塞的，也就是说如果如果没有信号出现，应用会一直停留在这一步。
我们在这里可以做一个等待，也就是说可以给这一步设定一个最短运行事件，让程序将这一段时间出现的所有文件处理事件都捕捉下来，
从而避免一次保存多个文件导致的重复执行。反过来，在这个阶段之后接收到的文件修改事件将会被留到下一个循环当中处理。
Go 语言的 channel 设计可以让我们方便地做到这一点。</p>
<h3 id="u6587_u4EF6_u7CFB_u7EDF_u4FA6_u542C"><a href="#u6587_u4EF6_u7CFB_u7EDF_u4FA6_u542C" class="headerlink" title="文件系统侦听"></a>文件系统侦听</h3><p>除了预先考虑一些可能会遇到的问题，我们还要对实现要用到的工具做一个预先的调查。
其中最重要的当然是文件系统改变如何进行侦听的问题。在这里我们使用了一个提供了 Go 语言接口库
<a href="https://github.com/fsnotify/fsnotify" target="_blank" rel="noopener">fsnotify</a>，使用之前我们需要使用<code>go get</code>命令先将对应包下载到本地环境中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go get github.com/fsnotify/fsnotify</span><br></pre></td></tr></table></figure>
<p>这个工具提供了获得文件修改事件的一个较为底层的访问接口，当指定侦听的文件或文件夹之后，
我们可以获得一个 channel 用来接收事件。fsnotify 的一点不足在于侦听文件夹并不会递归进行，
也就是当使用它侦听了某一文件夹时，这个文件夹子目录下的修改并不会被捕捉到，因此我们必须手动完成这一工作。</p>
<h3 id="u8FD0_u884C_u5B50_u8FDB_u7A0B"><a href="#u8FD0_u884C_u5B50_u8FDB_u7A0B" class="headerlink" title="运行子进程"></a>运行子进程</h3><p>解决的监视文件系统修改的问题，就要考虑如何该进行子进程的启动、守护和结束控制的方法了。
Go 语言的标准库<code>os/exec</code>完全提供了我们所需的接口。我们使用:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cmd := exec.Command(name, args...)</span><br></pre></td></tr></table></figure>
<p>可以获得一个 Command 对象，通过调用<code>cmd.Start()</code>方法就可以启动子进程。我们有两种方法结束子进程，
一个是通过<code>cmd.Process.Signal</code>方法为进程发送一个终止信号，比如<code>SIGINT</code>或<code>SIGQUIT</code>，
但是有的程序可能会忽略这些信号继续运行，因此一个必要的逻辑就是在一个 Timeout 之后应用还没有结束，
我们需要通过发送<code>SIGTERM</code>或<code>SIGKILL</code>信号强制终止进程。在最初的实现中，我使用了<code>cmd.Process.Kill()</code>
方法来结束进程，却发现了一些意外的问题，在后文中会详细的介绍遇到的问题及其解决方案。</p>
<h3 id="u547D_u4EE4_u884C_u53C2_u6570_u89E3_u6790"><a href="#u547D_u4EE4_u884C_u53C2_u6570_u89E3_u6790" class="headerlink" title="命令行参数解析"></a>命令行参数解析</h3><p>接下来就是用户交互的方式了。尽管我们的 App 是一个极简的设计，但是还是要给用户一些命令行的接口，
Go 语言的标准库提供了<code>flag</code>库方便我们完成这一任务。<code>flag</code>的功能非常简单，他有两种的使用方式，
一种是在<code>main</code>包的包层级声明指针变量作为接受参数值的位置:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var value = flag.String(&quot;option&quot;, &quot;default value&quot;, &quot;help text&quot;)</span><br></pre></td></tr></table></figure>
<p>这种方法的内部原理是 flag 在内部声明了一个变量并返回了他的指针。同样，
<code>flag</code>包也会在全局的一个单例对象上保存一个对这一变量的引用。当<code>flag.Parse()</code>被执行时，
保存在单例对象上的所有变量会被赋予解析出来的值。因为我们得到的是变量的一个指针，
因此当我们使用<code>*value</code>来获得变量值的时候，将会获得<code>flag</code>内部解析出来的值。</p>
<p>如果觉得每次都需要用取指针值操作<code>*value</code>来获得变量值的话，我们可以通过在<code>main</code>包中的
<code>init</code>方法中获取值的方法来实现同样的功能。比如说:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">var value string</span><br><span class="line">func init() &#123;</span><br><span class="line">    flag.StringVar(&amp;value, &quot;option&quot;, &quot;default value&quot;, &quot;help text&quot;)    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可见，我们传给<code>StringVar</code>的仍然是<code>value</code>变量的指针，<code>StringVar</code>在内部实际进行的是跟以前类似的操作，
最终当我们执行<code>flag.Parse()</code>后，<code>value</code>的值也会被变成解析出来的值。这里我们可以看到，
指针的存在使得一些原来可能很难表现的操作变得简单，但是同时也产生了很多的副作用。
比如说，在并发程序中，因为一个变量的引用被传递到多个未知的地方，一段简单的函数的运行过程当中，
变量的值可能会发生意想不到的改变，因而造成了预期之外的结果。在我们实现这一工具的过程当中也会遇到类似的问题需要解决。</p>
<p>好在<code>flag</code>操作本身比较简单，也不会并发和重复，这样使用还是安全的。另外，上述情况中我们都是在<code>main</code>
函数执行之前进行<code>flag</code>参数的声明工作，这是为了确保<code>main</code>函数一开始执行<code>flag.Parse</code>的时候，所有参数已经声明完毕。
我们自然也可以在函数里再进行这些工作，只要能确保执行的顺序即可。此外，如果你在同一个包的多个文件里声明了多个<code>init</code>函数，
这些函数虽然都会被执行，但是执行的顺序是未定义的行为，这也是需要注意的地方。</p>
<h3 id="u65F6_u95F4"><a href="#u65F6_u95F4" class="headerlink" title="时间"></a>时间</h3><p>接下来是<code>time</code>库的一点介绍，我们使用<code>time</code>库来实现<code>sleep</code>和<code>wait</code>的功能。简单来说，如果想要阻塞一个 goroutine 一段时间，
<code>time.Sleep(duration)</code>和<code>&lt;-time.After(duration)</code>两种方法都可以使用。请注意第二种方法中的<code>&lt;-</code>，
<code>time.After</code>方法实际上返回一个<code>&lt;-chan struct{}</code>，这个通道会在给定事件之后接受到一个消息，因此当你一开始使用<code>&lt;-</code>
操作符试图从通道中取消息时，通道会被阻塞，从而获得与<code>Sleep</code>一样的效果。这个方法实际上是非常有用的——尤其是跟
<code>select</code>语句配合使用的。当然<code>time</code>库还提供了<code>time.Tick</code>等多种方法，可供我们获得各种各样基于时间信号的通道。</p>
<h3 id="JSON__u8BFB_u5199"><a href="#JSON__u8BFB_u5199" class="headerlink" title="JSON 读写"></a>JSON 读写</h3><p>为了引进配置文件功能，我们还引入了<code>encoding/json</code>库，在这一工具当中，我们只使用了非常简单的<code>Decode</code>和<code>Encode</code>功能。
要<code>Decode</code>一个文件当中包含的 JSON，使用下面的方法:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func readJSON(filename string) SomeType &#123;</span><br><span class="line">    file, err := os.Open(filename)</span><br><span class="line">    defer file.Close()</span><br><span class="line"></span><br><span class="line">    if err == nil &#123;</span><br><span class="line">    var obj SomeType</span><br><span class="line">    if err := json.NewDecoder(file).Decode(&amp;obj); err != nil &#123;</span><br><span class="line">        // Fatal</span><br><span class="line">    &#125;</span><br><span class="line">    return obj</span><br><span class="line">    &#125;</span><br><span class="line">    // Fatal</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于我们希望输出的 Config 文件的 JSON 是有缩进的，在写入时我们使用<code>json.MarshalIntent</code>方法将 JSON
输出到<code>[]byte</code>中，再直接用<code>file</code>的<code>Write</code>方法写入文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">func writeJson(filename string, obj SomeType) &#123;</span><br><span class="line">    file, err := os.Create(filename)</span><br><span class="line">    defer file.Close()</span><br><span class="line">    </span><br><span class="line">    if err != nil &#123;</span><br><span class="line">    // Fatal</span><br><span class="line">    &#125;</span><br><span class="line">    if bytes, err := json.MarsalIntent(conf, &quot;&quot;, &quot;  &quot;); err == nil &#123;</span><br><span class="line">    file.Write(bytes)</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">    // Fatal</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，<code>SomeType</code>是一个为接受 JSON 数据而定义的<code>strunt{}</code>，值得注意的是，只有 Public 的元素才能被<code>encoding/json</code>
库读出和写入。</p>
<h2 id="POSIX_Signal__u5904_u7406"><a href="#POSIX_Signal__u5904_u7406" class="headerlink" title="POSIX Signal 处理"></a>POSIX Signal 处理</h2><p>最后一个值得注意的地方就是，如果用户通过<code>CTRL-C</code>向我们发送了终止进程的信号的话，我们如何才能优雅地结束程序。
不做任何操作的情况下程序可能会立刻停止，从而导致我们启动的子进程仍然在持续运行，从而形成了无人监管的幽灵进程。
因此我们有必要捕捉应用程序接受到的 Interrupt 信号，从而可以在此后执行一定的清理操作并终止子进程。</p>
<p>这一点可以通过<code>os/signal</code>库完成，下面的代码给出了一个简单的例子:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line">    ch := make(chan os.Signal)</span><br><span class="line">    signal.Notify(ch, os.Interrupt)</span><br><span class="line"></span><br><span class="line">    for sig := range ch &#123;</span><br><span class="line">    // Signal received!</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="u5B9E_u73B0_u4E0E_u8C03_u8BD5"><a href="#u5B9E_u73B0_u4E0E_u8C03_u8BD5" class="headerlink" title="实现与调试"></a>实现与调试</h2><p>经过多方研究做好了充分的准备之后，我们终于可以着手编写我们的主程序了。在下面的实现当中，
我们将会大量使用通道(channel)作为 goroutine 之间通讯和同步的工具。同时我们也用到了一些 Go 
语言的使用模式和最佳实践。</p>
<h3 id="Runner__u7684_u5B9E_u73B0"><a href="#Runner__u7684_u5B9E_u73B0" class="headerlink" title="Runner 的实现"></a>Runner 的实现</h3><p>首先的需求就是，我们希望以面向对象的方式将我们的主运行循环包装成对象，这样当我们通过<code>os/signal</code>
捕捉到用户传来的信号时，就可以通过一个方法来执行退出循环的方法。同样我们也需要一个结构体来保存进行执行的状态，
比如说保留一个对执行 Command 的引用等。</p>
<p>在这里我们要使用到一个简单的模式，那就是如何模仿一般面向对象当中的构造函数模式。总所周知，
由于 Go 语言面向对象的实现模式不同，我们没法强制用户在新建对象和结构体的时候一定要执行我们指定的某一函数。
比如说用户总可以通过<code>SomeType{&quot;some&quot;, &quot;params&quot;}</code>字面量的形式来生成新的<code>struct{}</code>对象。
这在需要对结构体字段正确性进行验证或对某些字段进行自动初始化的时候很不方便。</p>
<p>然而如果更换一个思路，我们其实可以保证用户新建对象时一定要通过构造函数进行。最简单的方法就是通过定义子包来进行访问控制。
我们知道，在一个包中小写字母开通的类型、函数和变量外部都不可以访问，因此通过如下步骤我们就可以模仿传统的构造函数模式了:</p>
<ol>
<li>定义一个子包，比如<code>github.com/shanzi/wu/runner</code></li>
<li>在子包中定义一个公共的接口，比如<code>Runner</code></li>
<li>在子包中定义一个私有的结构体类型，比如<code>runner</code></li>
<li>为公共的接口<code>Runner</code>声明一个构造函数，这个构造函数返回私有的结构体类型<code>runner</code></li>
</ol>
<p>由于<code>Runner</code>是一个接口(<code>interface</code>)，它为外界提供了一个类似鸭子类型的方法提示。在 Go 语言的设计当中，
一个类型服从一个接口并不需要显式地声明出来——只要类型提供了接口所声明的所有方法即可。
这一有趣的设定使得外界可以通过接口的定义在一定成都上窥探出所接受到的对象的内部结构而不需要知道对象具体的类型，
因此如果我们在<code>Runner</code>的构造函数中放回一个<code>runner</code>对象的时候，外界就将<code>runner</code>当作<code>Runner</code>所定义的那样使用，
从而实现了暴露<code>runner</code>所提供的方法的目的。反过来，因此<code>runner</code>是私有的结构体，外界也不能直接访问和构造出它的对象来。</p>
<p>由于 Go 语言的接口只能定义方法，如果外界想要获得结构体的属性，就必须通过<code>Getter</code>和<code>Setter</code>方法。
在我们的设计中，希望将应用侦听的目录路径、侦听的文件匹配模式和命令暴露出来，因此定义了如下的接口和结构体:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">type Runner interface &#123;</span><br><span class="line">    Path() string</span><br><span class="line">    Patterns() []string</span><br><span class="line">    Command() command.Command</span><br><span class="line">    Start()</span><br><span class="line">    Exit()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type runner struct &#123;</span><br><span class="line">    path     string</span><br><span class="line">    patterns []string</span><br><span class="line">    command  command.Command</span><br><span class="line"></span><br><span class="line">    abort chan struct&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func New(path string, patterns []string, command command.Command) Runner &#123;</span><br><span class="line">    return &amp;runner&#123;</span><br><span class="line">        path:     path,</span><br><span class="line">        patterns: patterns,</span><br><span class="line">        command:  command,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意到，我们在<code>runner</code>结构体当中添加了一个没有暴露的<code>abort</code>通道，这个通道配合<code>select</code>
将会为我们提供一个优雅地结束 goroutine 的方法: 由于我们并不能从外部强制结束另一运行当中的 goroutine，
因此我们需要通过通道传递信号来通知 goroutine 结束运行。在介绍这个以前，我们先来看 <code>Start</code> 方法的实现:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">func (r *runner) Start() &#123;</span><br><span class="line">    r.abort = make(chan struct&#123;&#125;)</span><br><span class="line">    changed, err := watch(r.path, r.abort)</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">        log.Fatal(&quot;Failed to initialize watcher:&quot;, err)</span><br><span class="line">    &#125;</span><br><span class="line">    matched := match(changed, r.patterns)</span><br><span class="line">    log.Println(&quot;Start watching...&quot;)</span><br><span class="line"></span><br><span class="line">    // Run the command once at initially</span><br><span class="line">    r.command.Start(200 * time.Millisecond)</span><br><span class="line">    for fp := range matched &#123;</span><br><span class="line">        files := gather(fp, matched, 500*time.Millisecond)</span><br><span class="line"></span><br><span class="line">        // Terminate previous running command</span><br><span class="line">        r.command.Terminate(2 * time.Second)</span><br><span class="line"></span><br><span class="line">        log.Println(&quot;File changed:&quot;, strings.Join(files, &quot;, &quot;))</span><br><span class="line"></span><br><span class="line">        // Run new command</span><br><span class="line">        r.command.Start(200 * time.Millisecond)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，<code>Start</code>函数其实包含了我们应用主循环的全部内容，它首先构造一个新的<code>abort</code>通道，
传递进入<code>watch</code>函数调用<code>fsnotify</code>开始监听工作，然后通过<code>range</code>开始我们的主循环。
在这里<code>changed</code>和<code>matched</code>都是新生成的通道，<code>changed</code>输出对当前目录下所有文件监听获得的事件，
<code>matched</code>输出将<code>changed</code>当中事件以文件模式匹配过滤后的机构。在这里我们对通道的使用非常像 Python
当中的生成器。不但如此，我们通过将通道串联起来，还可以进行逐级过滤，从而在最后只获得我们关心的内容。
在这里通道不但可以被看作生成器，也可以被看作有些编程语言提供的 Lazy Sequence (惰性求值列表)。
实际上，很多 Gopher 直接将 Channel 当成一个高效且线程安全的队列使用。这种生成器/过滤器也是一种常用的模式。</p>
<p>回到我们的<code>watch</code>函数，我们将从这一函数的实现中看到<code>abort</code>通道是如何发挥作用的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">func watch(path string, abort &lt;-chan struct&#123;&#125;) (&lt;-chan string, error) &#123;</span><br><span class="line">    watcher, err := fsnotify.NewWatcher()</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">        return nil, err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for p := range list(path) &#123;</span><br><span class="line">        err = watcher.Add(p)</span><br><span class="line">        if err != nil &#123;</span><br><span class="line">            log.Printf(&quot;Failed to watch: %s, error: %s&quot;, p, err)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    out := make(chan string)</span><br><span class="line">    go func() &#123;</span><br><span class="line">        defer close(out)</span><br><span class="line">        defer watcher.Close()</span><br><span class="line">           for &#123;</span><br><span class="line">            select &#123;</span><br><span class="line">            case &lt;-abort:</span><br><span class="line">                // Abort watching</span><br><span class="line">                err := watcher.Close()</span><br><span class="line">                if err != nil &#123;</span><br><span class="line">                    log.Fatalln(&quot;Failed to stop watch&quot;)</span><br><span class="line">                &#125;</span><br><span class="line">                return</span><br><span class="line">            case fp := &lt;-watcher.Events:</span><br><span class="line">                if fp.Op == fsnotify.Create &#123;</span><br><span class="line">                    info, err := os.Stat(fp.Name)</span><br><span class="line">                    if err == nil &amp;&amp; info.IsDir() &#123;</span><br><span class="line">                        // Add newly created sub directories to watch list</span><br><span class="line">                        watcher.Add(fp.Name)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                out &lt;- fp.Name</span><br><span class="line">            case err := &lt;-watcher.Errors:</span><br><span class="line">                log.Println(&quot;Watch Error:&quot;, err)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    return out, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们可以看到，在<code>watch</code>函数中，我们开启了一个新的 goroutine，在这个 goroutine 当中我们进行了以下工作:</p>
<ol>
<li>如果 abort 通道返回，结束监听，函数返回</li>
<li>如果有文件事件产生，进行初步过滤和处理，对于新建的文件夹，要在这里显式加入侦听当中</li>
<li>发现文件错误，通过 Log 打印出来并忽略</li>
</ol>
<p>我们把这个<code>select</code>语句包含在一个永真<code>for</code>循环中，这样除非<code>abort</code>信号获得消息，其他的消息处理之后就会立即进入新的循环。</p>
<p>看过了<code>Start</code>函数，我们来看<code>Exit</code>函数的实现:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func (r *runner) Exit() &#123;</span><br><span class="line">        log.Println()</span><br><span class="line">        log.Println(&quot;Shutting down...&quot;)</span><br><span class="line"></span><br><span class="line">        r.abort &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">        close(r.abort)</span><br><span class="line">        r.command.Terminate(2 * time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，除了一些打 Log 的工作，<code>Exit</code>函数的主要工作就是向<code>abort</code>通道中传递信息并关闭它。最后结束我们的 Command。</p>
<p>在这里必须简单提到一点，对于这种传递的消息不包含信息量而只有消息的到达本身有含义的通道为什么我们要通过传递<code>struct{}</code>
类型而不是写起来更短的<code>int</code>或者<code>bool</code>来完成呢？这是因为在 Go 语言中只有<code>struct{}{}</code>是不占用空间的——他的<code>size</code>是<code>0</code>。
其他任何类型都不能保证除了通道内部本身的空间使用之外不添加新的空间占用。因此无论是这种通道，还是我们希望使用<code>map</code>
模拟集合，都应该用<code>struct{}{}</code>做为值的类型。</p>
<h2 id="Command__u7684_u5B9E_u73B0"><a href="#Command__u7684_u5B9E_u73B0" class="headerlink" title="Command 的实现"></a>Command 的实现</h2><p>为了方便我们对子进程的管理，wu 的实现当中，我们还将 Command 相关的操作封装到了<code>github.com/shanzi/wu</code>包当中，
下面给出了 Command 包定义的接口和构造函数的定义是:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">type Command interface &#123;</span><br><span class="line">        String() string</span><br><span class="line">        Start(delay time.Duration)</span><br><span class="line">        Terminate(wait time.Duration)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type command struct &#123;</span><br><span class="line">        name   string</span><br><span class="line">        args   []string</span><br><span class="line">        cmd    *exec.Cmd</span><br><span class="line">        mutex  *sync.Mutex</span><br><span class="line">        exited chan struct&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func New(cmdstring []string) Command &#123;</span><br><span class="line">        if len(cmdstring) == 0 &#123;</span><br><span class="line">                return Empty()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        name := cmdstring[0]</span><br><span class="line">        args := cmdstring[1:]</span><br><span class="line"></span><br><span class="line">        return &amp;command&#123;</span><br><span class="line">                name,</span><br><span class="line">                args,</span><br><span class="line">                nil,</span><br><span class="line">                &amp;sync.Mutex&#123;&#125;,</span><br><span class="line">                nil,</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看到，在结构体当中，我们除了保存一些传进来的参数，还用<code>cmd</code>字段保存了当前运行的 Command 的引用，
此外，因为多个方法可能会并发地修改结构体中元素的值，我们使用<code>sync</code>类提供的<code>Mutex</code>锁来实现对象的互斥访问。
最后还保留了一个 Channel 用来在进程结束之后获得通知。</p>
<p>Command 的<code>Start</code>方法是 wu 当中最复杂的一部分，它首先会强制<code>Sleep</code>一段时间，以免子进程在很短的时间里被重复启动，
此后通过<code>mutex</code>加锁获得对<code>command</code>结构体对象修改的权限，随后构造和启动子进程，并在新的 goroutine 里通过<code>cmd.Wait()</code>
来等待进程结束。当进程结束之后将会打印 Log 并通过<code>exited</code>通道发布结束消息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">func (c *command) Start(delay time.Duration) &#123;</span><br><span class="line">        time.Sleep(delay) // delay for a while to avoid start too frequently</span><br><span class="line"></span><br><span class="line">        c.mutex.Lock()</span><br><span class="line">        defer c.mutex.Unlock()</span><br><span class="line"></span><br><span class="line">        if c.cmd != nil &amp;&amp; !c.cmd.ProcessState.Exited() &#123;</span><br><span class="line">                log.Fatalln(&quot;Failed to start command: previous command hasn&apos;t exit.&quot;)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        cmd := exec.Command(c.name, c.args...)</span><br><span class="line"></span><br><span class="line">        cmd.Stdin = os.Stdin</span><br><span class="line">        cmd.Stdout = os.Stdout</span><br><span class="line">        cmd.Stderr = os.Stdout // Redirect stderr of sub process to stdout of parent</span><br><span class="line"></span><br><span class="line">        // Make process group id available for the command to run</span><br><span class="line">        cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123;Setpgid: true&#125;</span><br><span class="line"></span><br><span class="line">        log.Println(&quot;- Running command:&quot;, c.String())</span><br><span class="line"></span><br><span class="line">        err := cmd.Start()</span><br><span class="line">        exited := make(chan struct&#123;&#125;)</span><br><span class="line"></span><br><span class="line">        if err != nil &#123;</span><br><span class="line">                log.Println(&quot;Failed:&quot;, err)</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">                c.cmd = cmd</span><br><span class="line">                c.exited = exited</span><br><span class="line"></span><br><span class="line">                go func() &#123;</span><br><span class="line">                        defer func() &#123;</span><br><span class="line">                                exited &lt;- struct&#123;&#125;&#123;&#125;</span><br><span class="line">                                close(exited)</span><br><span class="line">                        &#125;()</span><br><span class="line"></span><br><span class="line">                        cmd.Wait()</span><br><span class="line">                        if cmd.ProcessState.Success() &#123;</span><br><span class="line">                                log.Println(&quot;- Done.&quot;)</span><br><span class="line">                        &#125; else &#123;</span><br><span class="line">                                log.Println(&quot;- Terminated.&quot;)</span><br><span class="line">                        &#125;</span><br><span class="line">                &#125;()</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Command 的<code>Terminate</code>方法也利用到了<code>select</code>语句，它的主要逻辑是，先给子进程发送<code>SIGINT</code>信号促使子进程自然退出，
此后用<code>select</code>同时侦听<code>exited</code>通道和<code>time.After(wait)</code>通道，以便在<code>SIGINT</code>失效的情况下设法强制退出。
前面提到过，<code>time.After(wait)</code>会返回一个在给定时间后发送消息的通道，这里使用<code>select</code>从两个通道当中选择先得到的消息，
因此当<code>wait</code>时间过后<code>exited</code>还没有消息传来，就会进入强制退出的分支。这就是一般在 Go 语言中实现 Timeout
的模式或者说方法。</p>
<p>目前为止，已经将 wu 的主要代码逻辑介绍完了，在之后的调试当中，主要发现和修正了两个比较严重且有代表性的问题，
那就是空命令的问题和结束命令的问题。</p>
<h3 id="Empty_Command"><a href="#Empty_Command" class="headerlink" title="Empty Command"></a>Empty Command</h3><p>第一个问题在于，如果用户没有给定运行的 Command 程序应该如何处理的问题。在 wu 里，我选择了什么也不做。
在这里，我们并没有通过分支语句来在函数中进行判断。得益于 Go 语言接口类型的设计，我们并不一定要在<code>Command
构造函数里返回</code>command<code>结构体——任何服从</code>Runner`接口的类型皆可。为此，我们可以使用最简单的方式定义一个空的 Command 类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">// An empty command is a command that do nothing</span><br><span class="line">type empty string</span><br><span class="line"></span><br><span class="line">func Empty() Command &#123;</span><br><span class="line">        return empty(&quot;Empty command&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c empty) String() string &#123;</span><br><span class="line">        return string(c)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c empty) Start(delay time.Duration) &#123;</span><br><span class="line">        // Start an empty command just do nothing but delay for given duration</span><br><span class="line">        &lt;-time.After(delay)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (c empty) Terminate(wait time.Duration) &#123;</span><br><span class="line">        // Terminate empty command just return immediately without any error</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Kill_Command"><a href="#Kill_Command" class="headerlink" title="Kill Command"></a>Kill Command</h3><p>之前提到过，<code>os/exec</code>包中的<code>Command</code>类其实可以通过<code>cmd.Process.Kill()</code>方法来结束。在一般的执行当中都取得了成功。
但是我却发现当使用<code>wu go run main.go</code>启动一个 Web Server 时，在文件修改后旧的子进程总是不能被正确地结束。
显示发送<code>SIGINT</code>没有效果，之后执行了<code>Kill</code>函数之后，尽管<code>go run</code>命令退出，但是 Web Server 仍然在运行，
因此导致了端口占用的问题，使得新的 Command 执行失败。</p>
<p>经过检索后发现，这是因为<code>go run</code>命令实际上相当于<code>build</code>和执行两条命令，它本身也是通过子进程来运行编译好的新进程，
因此当信号发送给<code>go run</code>时，它运行的子进程本身没有收到<code>SIGINT</code>因此并不会退出。<code>go run</code>也因为一直等待子进程而保持运行。
最后当执行<code>Kill</code>函数之后，只有<code>go run</code>命令被结束，而他的子进程仍然在执行当中。</p>
<p>知道原因之后就可以提出解决方案了，首先在执行 Command 之前，我们要强制新的 Command 和他的子进程可以获得 Group PID。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// Make process group id available for the command to run</span><br><span class="line">cmd.SysProcAttr = &amp;syscall.SysProcAttr&#123;Setpgid: true&#125;</span><br></pre></td></tr></table></figure>
<p>此后，我们需要自己实现一个<code>kill</code>函数，为整个子进程组都发送同样的信号:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">func (c *command) kill(sig syscall.Signal) error &#123;</span><br><span class="line">        cmd := c.cmd</span><br><span class="line">        pgid, err := syscall.Getpgid(cmd.Process.Pid)</span><br><span class="line">        if err == nil &#123;</span><br><span class="line">                return syscall.Kill(-pgid, sig)</span><br><span class="line">        &#125;</span><br><span class="line">        return err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由此，我们模拟了用户在按下<code>CTRL-C</code>后 Shell 的行: 为整个进程组发送结束信号。这样，我们运行的 Command
就可以保证被正确结束了。当然，这一套操作只在 *NIX 操作系统上可用。在 Windows 上并没有这样的信号机制——
还好，wu 并不需要支持 Windows。</p>
<h2 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h2><p><img src="/img/posts/wu-screenshot.png" alt="Screen Shot"></p>
<p>wu 是我完成的又一个有点规模的 Go 语言的应用。由于这次对于 Channel 和 Go 的一些理念有了更深的认识，
编写代码也更加顺畅，也更能体会出一歇 Go 设计上的优点了。</p>
<p>Go 语言在很多方面的设计上确实有独到之处，比如使用通道作为并发同步的工具，而 Channel 的作用又不仅限于此，
它还可以用来模拟队列、生成器、惰性列表，用来实现多级过滤模式等等。Go 语言的接口和面向对象的设计在很多时候也非常灵活。</p>
<p>然而，没有范型使得容器类难以实现，没有异常捕捉使得很多函数调用有点啰嗦等问题也确实为代码的编写引入了一些麻烦。
虽然引入了 Vendor ，支持<code>internal</code>包的概念，但是总体来说 Go 语言在包管理上仍然有很大的提升空间。</p>
<p>我个人使用 Go 语言的体验还是不错的，接下来一段时间仍将在这门语言上在做一些研究。</p>
<p>最后，如果你对 wu 的详细实现感兴趣，它的代码已经<a href="https://github.com/shanzi/wu" target="_blank" rel="noopener">开源在 GitHub 上</a>，
我还上传了编译好的可执行文件<a href="https://github.com/shanzi/wu/releases" target="_blank" rel="noopener">可供下载</a>，欢迎 Bug 反馈和代码贡献。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最近使用 Golang 编写完成了一个命令行下的小工具: <a href="https://github.com/shanzi/wu" target="_blank" rel="noopener">wu</a>，
这个小工具的主要用途是监视文件改动并执行指定的命令。尽管有点重新发明轮子的嫌疑，
但是设计和实现它的过程中我还是有不少收获的。</p>]]>
    
    </summary>
    
      <category term="golang" scheme="https://io-meter.com/tags/golang/"/>
    
      <category term="programming" scheme="https://io-meter.com/tags/programming/"/>
    
      <category term="wu" scheme="https://io-meter.com/tags/wu/"/>
    
      <category term="filesystem" scheme="https://io-meter.com/tags/filesystem/"/>
    
      <category term="watch" scheme="https://io-meter.com/tags/watch/"/>
    
      <category term="utility" scheme="https://io-meter.com/tags/utility/"/>
    
      <category term="os" scheme="https://io-meter.com/tags/os/"/>
    
      <category term="cli" scheme="https://io-meter.com/tags/cli/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[diumoo 开源啦]]></title>
    <link href="https://io-meter.com/2016/06/18/diumoo-is-open-sourced/"/>
    <id>https://io-meter.com/2016/06/18/diumoo-is-open-sourced/</id>
    <published>2016-06-18T06:03:16.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>在接近三年的维护空荡期之后，我终于又抽出时间为 diumoo 发布了一个修复多个严重问题的 <a href="https://github.com/shanzi/diumoo/releases" target="_blank" rel="noopener">1.5.0 版本</a>，
这一版本也将会成为 diumoo 开发过程当中的一个里程碑: diumoo 在 GitHub 上正式开源了！</p>
<a id="more"></a>
<p>粗略算来，自 <a href="http://diumoo.net" target="_blank" rel="noopener">diumoo</a> 发布已经接近五年了。diumoo 作为我第一个比较成功的 App，
中间经过数个小版本更新和两个大的版本的更新，终于一路走到今天。在此次更新之前，diumoo 
经历了长达两年的维护空档期，直到最近因豆瓣方面的页面调整而导致的严重问题，才终于迫使我又拿起这个项目。
在此，我不得不向所有支持 diumoo 的用户们表示歉意。</p>
<p>经过一段时间的考虑，我终于确信只有将 diumoo 开源，才能让此项目长期发展下去——在开源的开发模式下，
diumoo 不会再因为我一个开发者不能活跃维护而迟迟不能更新了。
而我也更希望在开源之后，其他开发者可以加入其中，按照自己的想法定制和修改 diumoo，
从而衍生出更多更好的选择。这样即使用户最后不再使用 diumoo，它也可以继续实现自己的价值。</p>
<p>总之，欢迎各位有能力的开发者在关注 <a href="https://github.com/shanzi/diumoo" target="_blank" rel="noopener">diumoo 在 GitHub 上的仓库</a>。
在接下来的文章里，我会稍微介绍一下 diumoo 的开发历程。</p>
<h1 id="u8D77_u6E90"><a href="#u8D77_u6E90" class="headerlink" title="起源"></a>起源</h1><p>diumoo 的开发大约开始于我读大三的时候，当时在自己的联想 Y450 电脑上折腾出来一个 Hackintosh，也就是俗称的黑苹果。
因此逐渐将主力操作系统从 Linux 切换到 OSX 上了。在当时，豆瓣电台是 Mac 上听音乐最好的选择之一，它以优秀的推荐算法著称，
很多其他的竞争对手尚未发展起来。但是长期以来，豆瓣仍奉行 Web 服务为主的特点，不要说 Mac App，
连移动应用也没有给予足够的重视。</p>
<p>我对当时可以找到的一些电台 App 不甚满意，因此想要自己开发一个。当时的我比较熟悉的是 Web 开发和一点 Qt 开发，
对于 OSX 开发完全没有经验。因此最初想法其实是使用 Web 技术开发这一 App 然后将其打包成原生应用发布。
像 <a href="https://github.com/electron/electron" target="_blank" rel="noopener">Electron</a> 这么方便的工具还没有出现，因此开发遇到了不少困难。
制作出来一些 Prototype 之后自己都很不满意，因此下定决心要使用 Native 的 Cocoa API 进行开发。</p>
<p>从零入门 Objective-C 是一件挺困难的事情，在真正接触之前我其实一直不怎么喜欢它奇怪的语法，
而且当时的 Objective-C 还没有 ARC 这种方便的 GC 功能，在开发 diumoo 时尤其是在内存管理和多线程并发过程当中遇到很多问题，
然而就这样磕磕绊绊，竟然也终于完成了一个较为稳定的版本——尽管那个版本时不时还是会突然崩溃，
但是稳定性已经满足了最低的需求。也就是在这个时候，我将 diumoo 的第一个版本发布出去了。</p>
<p>diumoo 取得了预料之外的成功，前几天的下载量都超过千次。与此同时，很多博客也陆续推荐和介绍了 diumoo，
那段时间真是晚上都兴奋的睡不着。当时 App 的 UI 主要就是在状态栏上的一个 Menu 构成，
添加了一些诸如声音渐变的效果，最主要的 Feature 其实是添加了一个所谓的 Desktop Wave 的功能。
这个功能被很多用户所喜爱。</p>
<p><img src="/img/posts/diumoo-old.jpg" alt="最早的 diumoo"></p>
<p>这一版本让我最惊讶的时候是被当时的电脑报的一个栏目推荐了。在当时纸媒虽然已经开始走下坡路，
但是电脑报在一般熟悉计算机的人心中还是又很高的地位的。总之，尽管第一个版本的 diumoo 还有很多问题，
却仍然得到了很多用户的认可和支持。也有很多用户通过各种渠道为 diumoo 捐款，令我非常感动。</p>
<p>另外一个必须提到的事情是，diumoo 的另一个主要开发者 <a href="https://github.com/AnakinMac" target="_blank" rel="noopener">AnakinMac</a>
也是在这一阶段主动加入到开发行列的。作为一个野生 OSX 开发者，很多地方我都写的很糟糕，从 Anakin
那里我学到了很多东西。</p>
<h1 id="u53D1_u5C55"><a href="#u53D1_u5C55" class="headerlink" title="发展"></a>发展</h1><p>在此后一段时间，Apple 的产品越来越受欢迎，Mac OS 的开发速度也开始加快，并且从 iOS 上吸收过来很多东西。
此后，Objective-C 2.0 发布，从此 Mac 开发者可以使用 ARC 进行内存管理，再也不需要手动操作引用计数了。
另一个重大的改变是，之前 Mac 上使用的 <code>QuickTime.Framework</code> 被弃用，取而代之的是从 iOS 上引入的 <code>AVFoundation</code>，
这导致 diumoo 在新版本的 OSX 上无法运行。此时 diumoo 还在活跃维护的阶段，因此很快就开始编写新的版本。</p>
<p>新版本的 diumoo 几乎是完全重写的代码，从 UI 到内核都进行了完全的重构。Apple 也很快发布了配备
Retina 屏幕的 Macbook Pro，因此对于 Retina 的支持也被规划在内。尽管 <code>AVFoundation</code> 对开发者更友好一些，
但是底层音频的 API 没有 <code>QuickTime.Framework</code> 暴露的多。尽管可以使用 <code>CoreAudio</code>
来获得更底层的访问，我们最终还是决定放弃实现 Desktop Wave 这种功能。
另一个放弃它的原因在于尽管看起来很炫酷，这一功能对 CPU 的占用还是比较大的，因此容易导致过热。</p>
<p>在这一版本，除了全新的 UI 和音乐播放内核，我们把重点放在了实现 Time Machine 和 diumoo search 这两个功能上。
使用 Time Machine，用户可以浏览和检索已经播放过的歌曲并且跳回原来的歌曲播放。其中使用 Time Machine 
的形式浏览歌曲历史的功能，是我有一天在学校吃完发走在路上，突发奇想得到的 Idea，这可能是我在 diumoo
整个设计当中做出的最有创意的事情了。</p>
<p><img src="/img/posts/diumoo-timemachine.png" alt="Time Machine"></p>
<p>在 Time Machine 当中，用户在历史中翻看自己播放过的歌曲记录，遇到想要再听一遍歌曲只需要点击 Restore 按钮，
diumoo 就可以开始播放了。这一 API 在后来的 OSX 当中逐渐被淡化了，使用的 App 不多，而 diumoo
这种使用方式也许也是最另类的吧。除此之外，这个版本的 diumoo 还可以使用 search 功能直接找到听过的歌曲：</p>
<p><img src="/img/posts/diumoo-search.png" alt="diumoo Search"></p>
<p>尽管有一些用户捐款，但是作为一个穷学生，当时的我慢慢有点承受不了维护 diumoo
的一些开销，比如域名和服务器的租用费用等。当时的 Mac Apple Store 也在上升期，
很多 App 都转移到商店发布了。同时，商店作为一个发布平台，也可以让 diumoo 接触到更多的用户。
因此就跟 Anakin 商量要不要上架一个收费的版本，象征性地收取一点费用用来 Cover 一些固定开支。
毕竟就捐款来说，连 Mac Apple Store 每年的订阅费用都不够。</p>
<p>因此 Anakin 同学就购买了 Mac App Store 的账号。然而在 Mac App Store 上发布收费软件的复杂性超出了我们的预期，
迫于老版本 diumoo 已经存在严重的运行问题的情况，我们只好先发布了一个功能不完整的 Lite 版。
这个版本是一个巨大的错误，因为并没有提供为了这一版本开发的独特功能，仅仅是因为上架存在困难而提供的临时解决方案，
评价并不是很好。最终，我们还是将 diumoo 直接上架到 Mac Apple Store 上去免费发布了。在此也要特别感谢
Anakin 同学一直以来订阅 Mac Apple Store 以维持 diumoo 上架的贡献。</p>
<p>在这一版本的 diumoo 发布之后一段时间，diumoo 的开发就渐渐进入了停滞期。</p>
<h1 id="u505C_u6EDE"><a href="#u505C_u6EDE" class="headerlink" title="停滞"></a>停滞</h1><p>diumoo 开发的停滞主要是由于我个人的原因，在本科的最后一年，我决定要报考研究生，因此花了将近半年的时间复习考试，
因此也就不再有什么时间来维护项目了。考研成功后，diumoo 做了一些日常的更新，当时一些其他的电台音乐软件，
譬如网易云等都开始发力。一些音乐服务如 QQ 音乐和网易云音乐都推出了官方 Mac 版，diumoo 因此也慢慢淡出了 Mac Apple Store
上的音乐类排行榜。</p>
<p>在上研之前的一个暑假，我有幸拿到了豆瓣的实习 Offer，因此也进入豆瓣认识了当时负责音乐部分的 Su27 老师和
另一个豆瓣电台客户端 dRadio 的开发者 lembacon 同学。在豆瓣的两个月我其实主要的工作还是 Python 和 Web 开发，
但是中间确实有机会接触到了豆瓣电台的官方 API (未公开)。中间更有机会为豆瓣官方的 Mac 电台客户端出一份力，
但是最终这一计划还是流产了。</p>
<p>关于豆瓣电台官方 Mac App 也是一个 Sad Story，我本人作为一个半路出家的野生 Mac 程序员，
确实在这方面技术还是有点 Too young，再加上在开发过程中一些问题上的争执，最后没有成型也是难以避免。
后来，我就到了上海交通大学去读研，期间还试图挣扎着试图使用官方 API 重构一次，Su27 老师也很大方，
允许我离开豆瓣之后继续查看 API 文档以及为我提供 API Key。但是由于研究生期间的学业问题以及兴趣爱好还是转移到了
Web 和膜蛤这边，终于还是没能将这件事情完成。</p>
<p>就这样，diumoo 的开发陷入了停滞的状态，我自己也将豆瓣电台的红心歌曲通过网易云音乐同步和下载到本地，
从此成为了本地音乐党，一度将所有能找到无损音质的歌曲都换成无损音质了。而豆瓣电台本身这一段时间也没有太大的变化，
diumoo 还可以一直使用。</p>
<p>不得不说，从我结束豆瓣实习到现在，豆瓣本身也出现了很多变化。Su27 老师现在已经不再负责音乐组，豆瓣内部的架构听说也有一些调整。
这些年，尽管有一些失败的产品尝试，但是豆瓣已经逐渐开始重视移动端开发，在按照自己的步调慢慢发展着。
从某种角度来说，因为豆瓣 API 的修改而导致 diumoo 无法登录的问题也是豆瓣电台还在不断改进的一个标志。</p>
<h1 id="u5F00_u6E90_3A__u65B0_u7684_u5F00_u59CB"><a href="#u5F00_u6E90_3A__u65B0_u7684_u5F00_u59CB" class="headerlink" title="开源: 新的开始"></a>开源: 新的开始</h1><p>因为近期出现的登录问题，我不得不又回到 diumoo 的开发上来。在这段时间里，我在微博和主页上发出了征召开发者的请求，
很多用户表达了参与的意愿。这些用户的支持是我终于下定决心要将 diumoo 开源出来重要原因。</p>
<p>在开源之前，我还先着手将目前所遇到的不能登录的问题解决了，做了一些的修正和代码处理。
得到了现在的 1.5.0 版本。下图就是现在的 diumoo 运行截图了，为了更好的显示效果 diumoo 现在也已经支持 OSX 的
Dark mode。这一版本同时也修正了一些豆瓣电台页面和 API 修改所遇到的问题。</p>
<p><img src="/img/posts/diumoo-newversion.png" alt="diumoo"></p>
<p>不得不说，在使用过一段时间离线音乐之后，
重新拿起 diumoo 来，我又喜欢上了豆瓣电台这种推荐音乐的方式: 电台音乐不会像本地音乐那样反复听容易厌倦，
而自己写的 App，用起来还是最舒服的感觉。</p>
<p>总而言之，diumoo 开源了，diumoo 的开发也进入了一个新的阶段。这并不是 diumoo 开发的结束而是一个新的开始——
集合更多人的力量支持 diumoo 的维护，减轻我本人的压力是我目前比较现实的期望。
如果其他开发者能为 diumoo 贡献更多功能、让 diumoo 发展的更好那真的是再好不过了。</p>
<p>如果你喜欢 diumoo、使用过 diumoo 或者是一个感兴趣的开发者，欢迎你在 <a href="https://github.com/shanzi/diumoo" target="_blank" rel="noopener">GitHub</a> 上关注
diumoo。也欢迎你通过在 GitHub 上添加 Issue 的方式为 diumoo 反馈 Bug，支持 diumoo 的继续发展！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在接近三年的维护空荡期之后，我终于又抽出时间为 diumoo 发布了一个修复多个严重问题的 <a href="https://github.com/shanzi/diumoo/releases" target="_blank" rel="noopener">1.5.0 版本</a>，
这一版本也将会成为 diumoo 开发过程当中的一个里程碑: diumoo 在 GitHub 上正式开源了！</p>]]>
    
    </summary>
    
      <category term="cocoa" scheme="https://io-meter.com/tags/cocoa/"/>
    
      <category term="diumoo" scheme="https://io-meter.com/tags/diumoo/"/>
    
      <category term="osx" scheme="https://io-meter.com/tags/osx/"/>
    
      <category term="open source" scheme="https://io-meter.com/tags/open-source/"/>
    
      <category term="douban" scheme="https://io-meter.com/tags/douban/"/>
    
      <category term="music" scheme="https://io-meter.com/tags/music/"/>
    
      <category term="github" scheme="https://io-meter.com/tags/github/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Play with Intel NUC]]></title>
    <link href="https://io-meter.com/2016/05/29/play-with-nuc/"/>
    <id>https://io-meter.com/2016/05/29/play-with-nuc/</id>
    <published>2016-05-29T04:50:22.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>话说最近入手了一台 Intel NUC 用来做下载机，买回来之后为了更加充分的利用这台小主机的性能，那么呢，我就做了三件小事：
第一件事就是给 NUC 装上了 Ubuntu 14.04 系统，并配置了 Docker 和 Dokku 的环境；第二件事呢，部署了 Transmission 下载服务和NFS；
第三件事，就是给 NUC 安装了 Splunk 做 Monitor。如果说还有什么其他事情的话，
那就是写了这篇博客，供大家娱乐娱乐，这也是很大的，但是关键还是前面那三件小事儿。很惭愧，只做了一点微小的工作。</p>
<a id="more"></a>
<h1 id="Intel_NUC__u7B80_u4ECB"><a href="#Intel_NUC__u7B80_u4ECB" class="headerlink" title="Intel NUC 简介"></a>Intel NUC 简介</h1><p>所谓的 <a href="http://www.intel.com/content/www/us/en/nuc/overview.html" target="_blank" rel="noopener">Intel NUC</a>，
指的就是下图当中由 Intel 原厂提供的小主机。NUC 迄今为止已经出到第六代了,
其配置从低端的 i3 版本到高端的 i7 版本都有。Intel NUC 原装配置是不含内存和硬盘的，但是一般的淘宝店家都会提供套餐。
最新的 6 代 NUC 分为薄厚两种，厚版除了一块插在主板上的 SSD 外，还可以另配一块笔记本硬盘或 SSD。
尽管无论哪个版本的 NUC，其 CPU 等都是配置的笔记本级别的低电压硬件，不能和台式机相比。
但是作为 x86 架构的微型主机，NUC 的性能还是相当令人满意的。除了可以流畅运行包括 Windows 在内的各种操作系统，
最新的第六代还可以支持 4K 视频显示。</p>
<p><img src="/img/posts/intel-nuc.png" alt="Intel NUC"></p>
<p>要说我买 Intel NUC 这件事，那可以说也是历史的行程。之前在学校的时候，我一直使用实验室的主机做下载机，
现在毕业了，原来的主机自然不好继续使用，但是我还是有固定的下载需求的。如果能在内网做部署一台下载机，
我就可以让它离线挂机下载，下载到的视频文件还是直接在线串流播放，避免了再下载到笔记本上的繁琐操作。</p>
<p>单就下载这个功能来说，其实并不需要太好的性能。现在有的路由器和开发版都可以处理得了。
在我面前的选择主要是树莓派、Intel NUC 和 Gen 8 三种。这里要提一下 HP 的 Gen 8，它是专门开发来家用的 NAS，
可以说最为符合我的需求。Gen 8 具有良好的扩展性，可以挂载多块大容量硬盘，CPU 也可以更换。
最终选择 NUC 的原因在于，它相对于 ARM 架构的树莓派更加具有适用性，性能也比较强。而 Gen 8 原装的 CPU
略微不能满足的需求，升级 CPU 的成本也比较高。NUC 还有一个优点是内置硬件和接口非常齐全，视频上支持 HDMI 和 DP 两种接口，
自带千兆以太网卡、蓝牙和 WIFI，除此之外还有红外接口等。</p>
<p>在综合以上这些考虑之后，我就念了两句诗，最终购买了配备 i3 CPU 的 NUC6i3SYH 版本。淘宝套餐当中还包括 8G 内存、
128G SSD 和遥控器。这样以后如果有屏幕或电视的话，NUC 也可以用来做家用的媒体中心。</p>
<h1 id="u5B89_u88C5_Ubuntu_14-04__u548C_Dokku"><a href="#u5B89_u88C5_Ubuntu_14-04__u548C_Dokku" class="headerlink" title="安装 Ubuntu 14.04 和 Dokku"></a>安装 Ubuntu 14.04 和 Dokku</h1><p>Ubuntu 14.04 并不是 NUC 的首选。事实上，Intel 官方的 Linux 显卡驱动只兼容到 15.10 ，
这导致在 14.04 下的显示性能会比较差。当时我最终还是选用它的原因在于而我希望部署的 Dokku
目前仍然被 Lock 在作为 LTS 版本的 14.04 上。</p>
<p>为什么一定要考虑 <a href="https://github.com/dokku/dokku" target="_blank" rel="noopener">Dokku</a> 呢？Dokku 是一个极精简的 PaaS 平台，它可以在你的 VPS 和主机上模拟 Heroku
那样的使用体验——只需要将你写好的代码仓库 push 到主机上，Dokku 就会替你完成一系列部署工作，
将你的 Web 服务运行在一个 Docker container 当中并配置好 Nginx，这使得你可以方便地自定义域名。
再加上 Dokku 提供一系列方便的插件用来管理各种 Service ，比如各种关系型数据库、NoSQL、memcached 等等，
这些服务都是跑在各自的 Docker 容器内，具有很好的隔离性。Dokku 甚至有一个插件帮你加入和配置 <a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a> 证书。
这一系列方便的特性使得想要充分利用 NUC 性能部署更多服务的我来说是具有极大吸引力的。</p>
<p>NUC 到货的时候系统是预装的 Windows，想要在没有屏幕的情况下换装成 Ubuntu 还是花费了我一些心思。
后来还遇到 NUC 在家里的 WIFI 环境中丢包严重的问题，总之颇费了一些周折。在系统准备好了之后，
就正式开始 Dokku 的安装过程了。</p>
<p>在一般情况下，我们只需要在终端当中执行下述命令就可以成功安装 Dokku 了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/dokku/dokku/v0.5.7/bootstrap.sh</span><br><span class="line">sudo DOKKU_TAG=v0.5.7 bash bootstrap.sh</span><br></pre></td></tr></table></figure>
<p>这一命令会依次完成检查环境、安装必备依赖安装并设置 Dokku 的工作。然而这一招在国内的网络上并不好使，
究其原因，还是因为部分资源收到了 GFW 的干扰，导致安装缓慢以至于无法安装。如果有条件的话，建议先配置好代理或 VPN
等翻墙方案再安装。除此之外，我在安装的最后一步还遇到了 <code>gnu_utils</code> 爆出的 HTTPS 认证错误。
导致依赖安装完成之后无法继续。这一方面可能是国内网络的原因，另一方面可能跟 Dokku 使用的一个第三方镜像源托管站
<a href="https://packagecloud.io" target="_blank" rel="noopener">Package Cloud</a> 自身的问题有关。解决这一问题的方法是我们先手动把缺失的最后几个包使用 Wget
工具下载下来，再使用 <code>dpkg</code> 命令手动安装。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://packagecloud.io/dokku/dokku/packages/ubuntu/trusty/gliderlabs-sigil_0.4.0_amd64.deb</span><br><span class="line">wget https://packagecloud.io/dokku/dokku/packages/ubuntu/trusty/sshcommand_0.4.0_amd64.deb</span><br><span class="line">wget https://packagecloud.io/dokku/dokku/packages/ubuntu/trusty/sigil_0.4.0_amd64.deb</span><br><span class="line">wget https://packagecloud.io/dokku/dokku/packages/ubuntu/trusty/dokku_0.5.7_amd64.deb</span><br><span class="line">wget https://packagecloud.io/dokku/dokku/packages/ubuntu/trusty/herokuish_0.3.13_amd64.deb</span><br><span class="line"></span><br><span class="line">dpkg -i gliderlabs-sigil_0.4.0_amd64.deb sshcommand_0.4.0_amd64.deb sigil_0.4.0_amd64.deb dokku_0.5.7_amd64.deb herokuish_0.3.13_amd64.deb</span><br></pre></td></tr></table></figure>
<p>注意，在这里最好将 <code>herokuish</code> 这个包最后一个安装，这个包实际上是 Dokku 整个功能的核心，它会给 Docker import
一个叫做 <a href="https://github.com/gliderlabs/herokuish" target="_blank" rel="noopener">Herokuish</a> 的镜像，这个镜像则是另一个类似 PaaS 工具 <a href="https://deis.io/" target="_blank" rel="noopener">Deis</a> 提供的。
由于众所周知的原因，从 DockerHub 当中导入镜像的速度十分缓慢，因此在这一步很容易出错。建议一定要使用 Tmux 或 Screen
这样的工具保证进程可以在后台执行。在 <code>heorkuish</code> 安装的最后一步会在对应的 Docker Image 之中执行 <code>herokuish install</code>
命令，这一过程很遗憾也是会因为网络原因失败的。如果你使用的是代理方式翻墙，此时在 Docker 
当中运行的命令可能无法获得你的代理配置，因此在这一步最好在 VPN 环境下进行操作，或者直接使用下面的命令进入 Docker
容器手动执行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">docker run -it gliderlabs/herokuish /bin/bash</span><br><span class="line"></span><br><span class="line"># Now in docker environment</span><br><span class="line">export http_proxy=[your proxy config]</span><br><span class="line">export https_proxy=$http_proxy</span><br><span class="line"></span><br><span class="line">herokuish install</span><br><span class="line">ln /bin/herokuish /start</span><br><span class="line">ln /bin/herokuish /exec</span><br><span class="line">ln /bin/herokuish /build</span><br><span class="line">exit # Exit from docker</span><br><span class="line"></span><br><span class="line"># Out of Docker</span><br><span class="line">docker ps -a # Find containter id of recent changes</span><br><span class="line">docker commit [container id] gliderlabs/herokuish:latest</span><br></pre></td></tr></table></figure>
<p>这样，我们就完成了基本的设置。最后，我们只需要在主机上执行下述命令就可以完成 Dokku 的初始化设置，
在这一步当中，Dokku 将会自动为系统添加一个名叫 dokku 的新用户，并提供一些交互式的选项以供选择。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dokku plugins-install-dependencies</span><br></pre></td></tr></table></figure>
<p>Dokku 的实现原理是什么呢？其实 Dokku 本身只是一系列脚本和插件组成的插件集合，这些脚本的做用是方便用户管理和修改配置。
模拟 Heroku 的工作主要是 Herokuish 提供的，这个包会模仿 Heroku 的行为来检查你所要部署的代码类型、
自动安装依赖并 build 成 Docker Images。这一工具提供的功能几乎和 Heroku 完全一样，甚至大多数为 Heroku 编写的 buildpack
都可以无缝拿来使用。唯一的区别是 Dokku 使用 Docker 作为容器而 Heroku 则实用的是自己开发的容器系统。</p>
<p><code>sshcommand</code> 也是一个重要的命令，当你使用 <code>git push</code> 将代码 Push 到 Dokku 这里时，Dokku 需要使用你的 Public Key
来验证你的身份。在这一步当中，使用平常使用 Public Key 登录的方法将 <code>id_rsa.pub</code> 的内容加到 <code>.ssh/authorized_keys</code>
里是不管用的——<code>git</code>使用不同的方法来验证。因此需要使用 sshcommand 来添加公钥。例如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat .ssh/id_rsa.pub|sudo sshcommand acl-add dokku chase@chase-nuc</span><br></pre></td></tr></table></figure>
<p>只需要将你的 <code>id_rsa.pub</code> 的内容作为 <code>sshcommand</code> 的标准输入即可，这一步可以通过 <code>ssh</code> 来做，
从而也可以把本地机器的公钥加入。</p>
<p>接下来就可以像使用 Heroku 那样使用 Dokku 了，更详细的 Deploy 教程可以查看 Dokku
的<a href="http://dokku.viewdocs.io/dokku~v0.5.7/application-deployment/" target="_blank" rel="noopener">官方文档</a>。</p>
<h1 id="Transmission__26amp_3B_NFS"><a href="#Transmission__26amp_3B_NFS" class="headerlink" title="Transmission &amp; NFS"></a>Transmission &amp; NFS</h1><p>配置完 Dokku，要做的第一件事当然就是将 Transmission 部署进去了。<a href="https://www.transmissionbt.com" target="_blank" rel="noopener">Transmission</a>
是一款知名的 BT 客户端，他的主要特点就是提供了 Web 访问接口，从而很适合用来安装在下载机上进行远程控制。
把 Transmission 部署在 Docker 里其实不算是罕见的需求了，Github 上已经有一批现成的 Dockerfile。
参考其中两个，我修改出来一个适合部署在 Dokku 中的版本。因为 Dokku 实际上是允许使用 Dockerfile 进行 Build，
所以要注意的问题主要只有一下几点：</p>
<ol>
<li>Transmission 默认需要开放 <code>51413</code> 端口的 TCP 和 UDP 访问作为 Peer 连入的端口，但是如果直接在 Dockerfile
里 EXPOSE 出来，Dokku 会自动使用 Nginx 为这些端口设置代理，而 Nginx 是不支持 UDP 代理的，
所以我们并不在 Dockerfile 中指定 Expose 端口</li>
<li>Dokku 会自动为 Build 出来的 Docker Image 添加一个 <code>PORT</code> 环境变量，默认会使用 Nginx 将对应域名的 <code>80</code>
端口 Proxy 到 Docker 容器的这个端口，因此我们希望将 Transmission 的 Web Interface 暴露到这里</li>
<li>很自然地，我们需要为 Transmission 所在的 Docker 容器挂载一些外部文件系统。
其中下载目的位置希望能够映射到主机的固定位置。但是 Dockerfile 本身并不支持直接指定主机挂载的目录。</li>
<li>Dokku 的 zero down time deploy 功能会在重新部署的时候检查新的容器是否启动成功，
只有在启动成功之后才会关闭老的容器。这一功能在部署一般的 Web 服务时非常方便，
但是在部署 Transmission 时，由于 Docker 会绑定 PEERPORT，因此会导致新的进程无法启动成功。
因此需要 disable 这个功能，同样在每次部署之前也要手动 Shutdown 老的容器。</li>
</ol>
<p>为了解决这些问题，最后只能手动地完成一些设置工作。我将修改好的 Dockerfile 和运行脚本放在了 GitHub 上的
<a href="https://github.com/shanzi/dokku-transmission" target="_blank" rel="noopener">dokku-transmission</a> 仓库上了。如果要使用它，只需要先 clone 下来，
然后在 Dokku 所在机器上执行下述命令新建 App :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker apps:create [your_app_name]</span><br></pre></td></tr></table></figure>
<p>预先为 App 设置一些环境变量，譬如 Web Interface 的用户名和密码等:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker config:set [your_app_name] USERNAME=[username] PASSWORD=[password] PEERPORT=51413</span><br></pre></td></tr></table></figure>
<p>在之后，最重要的一步就是使用 Dokku 为运行 App 添加一些 Docker Options，这些 Docker Options
将会在 Dokku 每次启动 Docker 容器时追加作为参数，因此我们可以在这里指定主机相关的设置:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export $PEERPORT=51413</span><br><span class="line">dokku docker-options:add [your_app_name] deploy,run &quot;-v [PATH_ON_HOST_MACHINE]:/root/Downloads -p $PEERPORT/udp -p $PEERPORT/tcp&quot;</span><br></pre></td></tr></table></figure>
<p>我们可以用如下命令禁用掉 Dokku 对我们的 Transmission app 进行 zero down time 检查:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dokku checks:disable [your_app_name]</span><br></pre></td></tr></table></figure>
<p>最后，只需将仓库 Push 到 Dokku 这里，Transmission 进程就可以跑起来了。</p>
<p>尽管使用上麻烦一点，但是好在我们并不需要频繁地更新我们的 App。Dokku
会帮我们做好进程的守护工作——在应用挂掉或者系统启动时都会自动帮我们启动进程。</p>
<p>下图就是 Transmission Web Interface 部署成功后的样子了，终于可以开心的下载 BT 资源了！</p>
<p><img src="/img/posts/transmission.png" alt="Transmission Web"></p>
<p>把东西下载到了 NUC 上，还要想办法把这些东西通过网络暴露出来访问。除了传统的 HTTP server
和 FTP 等方法，我选择了使用 NFS。这样在其他机器上就可以将 NUC 上对应的文件夹通过网络挂载起来了。</p>
<p>安装 NFS 的方法，来自 Digital Ocean 的<a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-14-04" target="_blank" rel="noopener">这篇文章</a>
讲的很好了。简单来说我们只需要通过 <code>sudo apt-get install nfs-kernel-server</code> 命令来安装 NFS Server，
之后再在 <code>/etc/exports</code> 文件中配置目录设定即可。需要注意的是，如果想要 Mac 可以挂载 NUC 暴露出来的 NFS，
必须要添加 <code>insecure</code> 选项，否则会连接失败(尽管可以通过在终端中输入命令成功挂载)。我的配置文件内容如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/nfs 192.168.0.0/24(rw,sync,no_subtree_check,insecure)</span><br></pre></td></tr></table></figure>
<p>接下来就可以在 Mac 上通过 Finder 的 Go &gt; Connect to Server 功能直接挂载 NFS 了。</p>
<p><img src="/img/posts/nfs.png" alt="NFS"></p>
<p>顺便说一下，NFS 除了这种使用，还可以代替传统的 Volume 挂载方法，作为向 Docker 容器提供储存的一种解决方案。
此外，大规模分布式使用中，还有 <a href="https://github.com/ClusterHQ/flocker" target="_blank" rel="noopener">Flocker</a> 这种工具。
不过杀鸡焉用牛刀，在 NUC 上我就选择了简单直接的解决方案。</p>
<h1 id="Splunk_for_Monitor"><a href="#Splunk_for_Monitor" class="headerlink" title="Splunk for Monitor"></a>Splunk for Monitor</h1><p>利益相关，这里就稍微介绍一下 <a href="http://splunk.com" target="_blank" rel="noopener">Splunk</a> 吧。一般原始的方式处理 Log 当中的数据，我们都是直接写出简单的脚本来扫描 Log
文件进行处理。这种方法对于偶尔的需求还是可以处理的，但是一来需要做很多重复操作，二来不适合数据量大以及分布式的应用。
传统的脚本处理方法也并不怎么用户友好。那么一种同时面向技术和非技术类用户的产品就应运而生。
这样的工具完成了以下几个工作:</p>
<ol>
<li>Log 的收集: 从单机或分布式节点当中收集 Log 数据，发送到处理节点</li>
<li>Log 的索引: 对收集到的 Log 数据建立索引，方便日后查询</li>
<li>Log 的分析: 允许使用一定的接口从索引当中检索结果和数据并拿来可视化</li>
</ol>
<p>Splunk 是目前较为成熟的企业 Log 数据处理工具。与之相似的比较成熟的解决方案就是 <a href="https://www.elastic.co/products" target="_blank" rel="noopener">ELK</a> 了。
ELK 分别代表 Elasticsearch、Logstash 和 Kibana，这三个组件分别完成了索引、Log 收集和可视化三部分的工作，
是目前炙手可热的开源解决方案。互联网企业很多都选择了这种开源的技术，可以说对 Splunk 的产品造成了很大的威胁。</p>
<p>回到 Splunk，尽管它的免费版本一天只能处理 500M 的数据量，但对于 NUC 上的使用已经足够了。Splunk 作为企业应用，
总体来说使用体验和部署的友好程度还是不错的。从<a href="https://www.splunk.com/en_us/download/splunk-enterprise.html" target="_blank" rel="noopener">这里</a>
下载 Splunk 对应 Linux 的安装包，安装或解压到 <code>/opt/splunk</code> 即可。安装结束之后我们需要第一次运行一下
<code>/opt/splunk/bin/splunk</code> 程序， 这一步 Splunk 会要求我们接受 License 等，我们用下面一条命令全部跳过:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/splunk/bin/splunk enable boot-start --accept-license --answer-yes --no-prompt</span><br></pre></td></tr></table></figure>
<p>这一步同时也会安装一些 <code>init</code> 脚本到系统当中，Splunk 服务此时就已经安装成功了，我们可以使用下述命令启动它:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service splunk start</span><br></pre></td></tr></table></figure>
<p>Splunk 进行可视化的原理是什么呢？其实它定义了一门叫 SPL 的语言专门用来进行查询，查询的结果都可以以表格的形式显示出来。
而 Splunk 的可视化图表也可以以 SPL 的搜索结果作为输入，因此就可以以一种流水管线的形式将数据送入可视化组件进行表示。
Splunk 还支持 Realtime 的数据展示，这正是我们所需要的。</p>
<p>我的计划是将 Splunk 作为系统的 Monitor。让他可以显示当前 CPU、内存和硬盘等的使用情况。原理很简单，
既然 Splunk 是一个 Log 处理工具，那我们以一定的时间间隔将 CPU 占用、内存占用等情况以 Log 的形式打印出来，
这样 Splunk 不久可以处理了么？事实上 Splunk 官方就有一个 <a href="https://splunkbase.splunk.com/app/273/" target="_blank" rel="noopener">Splunk App for *NIX</a>
为我们提供了一个(很丑的) Web 界面来配置这些东西。值得注意的是，在使用之前必须通过 <code>sudo apt-get install sysstat</code>
安装必须的命令。</p>
<p>下图展示了使用 SPL 进行检索的示意图，使用 Log 检索工具，我们就不用每次编写脚本来查询我们在 Log 当中感兴趣的点，
更可以瞬间就得到统计以及变换后的结果并将结果输入到可视化模块进行可视化。Splunk 以及 SPL 的使用是一个大主题，
而且考虑到写的越来越像软文了，我还是就此打住吧。</p>
<p><img src="/img/posts/spl-search.png" alt="SPL Search"></p>
<p>将每种类型的数据输出成可视化图表之后还可以将其作为 Dashboard 的一个 Panel 保存下来，
这样每次访问的时候就可以从主页上看到一个概览了。除了系统的各项指标，我还配置了 Nginx 的访问次数统计和
ssh 次数的每日热度图。最终结果如下:</p>
<p><img src="/img/posts/splunk-dashboard.png" alt="Splunk Dashboard"></p>
<p>最后我还将 Splunk 配置在了 Nginx 之后使用 VHOST 访问，由于 Splunk 默认是在 <code>0.0.0.0</code> 上绑定自己的 Web
服务的，因此外界还可以直接访问，这是我不希望的。因此通过修改 <code>/opt/splunk/etc/system/local/web.conf</code>
配置，填入一下内容就可以改变 Splunk Web 服务绑定的 Host 地址了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[settings]</span><br><span class="line">enableSplunkWebSSL = 0</span><br><span class="line">server.socket_host = 127.0.0.1</span><br></pre></td></tr></table></figure>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>我的 Intel NUC 买回来两周，终于有时间好好把玩一下了。目前部署的服务对机器性能的利用率仍然很低，
未来还要好好想想有什么有趣的应用才行。总体看来，Intel x86 架构的 Mini PC 虽然价格较贵，
但是从性能和适用性上来讲还是比 ARM 开发版和路由器等更强一点，简单来说就是像我这样不怎么有时间折腾的人的选择。
当然诸如树莓派这种开发板添置各种有趣的传感器更为方便，很适合作为 Internet of Things 的一个处理节点，
以后如果有时间也应该研究一下。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>话说最近入手了一台 Intel NUC 用来做下载机，买回来之后为了更加充分的利用这台小主机的性能，那么呢，我就做了三件小事：
第一件事就是给 NUC 装上了 Ubuntu 14.04 系统，并配置了 Docker 和 Dokku 的环境；第二件事呢，部署了 Transmission 下载服务和NFS；
第三件事，就是给 NUC 安装了 Splunk 做 Monitor。如果说还有什么其他事情的话，
那就是写了这篇博客，供大家娱乐娱乐，这也是很大的，但是关键还是前面那三件小事儿。很惭愧，只做了一点微小的工作。</p>]]>
    
    </summary>
    
      <category term="NUC" scheme="https://io-meter.com/tags/NUC/"/>
    
      <category term="Linux" scheme="https://io-meter.com/tags/Linux/"/>
    
      <category term="Docker" scheme="https://io-meter.com/tags/Docker/"/>
    
      <category term="Dokku" scheme="https://io-meter.com/tags/Dokku/"/>
    
      <category term="Splunk" scheme="https://io-meter.com/tags/Splunk/"/>
    
      <category term="Ubuntu" scheme="https://io-meter.com/tags/Ubuntu/"/>
    
      <category term="Intel" scheme="https://io-meter.com/tags/Intel/"/>
    
      <category term="IoT" scheme="https://io-meter.com/tags/IoT/"/>
    
      <category term="Transmission" scheme="https://io-meter.com/tags/Transmission/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[台湾小游之城市篇]]></title>
    <link href="https://io-meter.com/2016/03/08/travel-to-taiwan-cities/"/>
    <id>https://io-meter.com/2016/03/08/travel-to-taiwan-cities/</id>
    <published>2016-03-08T08:34:31.000Z</published>
    <updated>2020-12-12T04:21:10.091Z</updated>
    <content type="html"><![CDATA[<p>欢迎来到《台湾小游之城市篇》，这篇文章是我台湾之行的分城市总结。我将按照时间顺序分别介绍台北、
高雄、花莲（瑞穗）、瑞芳以及在旅途中了解到的其他一些没去过的地方的经验。最后还有一点对这次台湾之行的总结。</p>
<a id="more"></a>
<h1 id="u53F0_u5317"><a href="#u53F0_u5317" class="headerlink" title="台北"></a>台北</h1><p>台北可能是所有来台湾旅行的人游玩的重点。我们一行人于中午的时候抵达台北松山机场，随后乘捷运直奔民宿所在处。
将行李放置妥当之后，才出门与这个城市进行了第一次亲密接触。对台北的第一印象是：果然有华人的地方就会有补习班。</p>
<p>开玩笑啦～我们到达的日子正是台北的雨季，歌曲里唱的“冬季到台北来看雨”果然不假。其实台北的雨季从冬天开始，
还会一直持续到春季。台北的街道看起来非常干净，而且由于人口并不算太多，交通情况是要好于大陆的大城市的。
同样，台北似乎并不像上海这样高楼林立，除了曾经为世界第一高楼的台北 101 大厦，你再也找不到这么高耸的建筑了。
相比来讲，台湾经济的爆发时期大概已经是十年前了，我们在台北并没有见到大陆一二线城市常见的热火朝天的住房建设。
大部分建筑给人一种细节丰富的历史感——既不是那种百年建筑的古老感，又没有新修建的楼房那种崭新的感觉。
这给人一种生活的气息。</p>
<p>台北是很多来台游客旅程的起点和终点。我们这次在台北游览的热门点包括国父纪念堂、中正纪念堂（自由广场）、
西门町、士林夜市、饶河夜市、101大厦和台北故宫博物院等等。除了这些景区之外，还有一个猫空缆车评价不错，
但是因缆车维护无法成行。</p>
<p>国父纪念堂和中正纪念堂的看点在于守备卫兵的从上午九点到下午六点每逢整点都有换岗表演，表演时长大约 5 分钟，
需要提前抢占视野好的位置才行，这个表演非常有特色，确实不可以错过。</p>
<p><img src="/img/taiwan/soldier_standing.jpg" alt="站岗的士兵"></p>
<p>中正纪念堂是几年“先总统”蒋中正（也就是蒋介石）的纪念堂，整个建筑比较宏伟，
并且使用了国民党党旗（青天白日旗）风格的白砖蓝瓦的中式风格建筑，但从建筑风格上来讲是相当漂亮的。
中正纪念堂所在的广场名为“自由广场”，对于我们这些从大陆游客来说这来到这里心里会有点五味杂呈。
一般来讲来中正纪念堂的团体游客没有国父纪念堂（纪念孙中山）的那么多。在自由广场也比较容易遇见和谐的轮子功的信徒宣传。</p>
<p><img src="/img/taiwan/freedom_square.jpg" alt="自由广场"></p>
<p>国父纪念堂距离台北 101 大厦很近，所以可以安排在一起游览。有趣的是，我们在国父纪念堂遇见一个大陆普通话讲的特别好的奶奶，
她自称是台湾本地人，在这里也是来宣传轮子功的。然而看上去她对于自己的这个工作并不上心，
只是热心的跟我们介绍翻墙技术以及大陆的政治八卦。在台湾呆的这几天我发现很多台湾人其实还是很热心的，
我们不止一次在查找公交线路或者乘坐地铁的时候得到别人的主动帮助，这位奶奶也给我们热心的介绍了参观 101
大厦的路线还有最近的诚品书店的位置等等，也是挺有意思的。</p>
<p><img src="/img/taiwan/101_mansion.jpg" alt="101 大厦"></p>
<p>据那位热心奶奶介绍，台北 101 大厦被设计为一节一节的样子，寓意是节节高升，而且 101 
大厦的夜晚灯光颜色会根据星期日到星期六的顺序按照赤橙黄绿青蓝紫的顺序切换。尽管因天气原因我们没有登上
101 大厦观景，但是我们访问了 101 大厦旁边另一个非常著名的景点——几米漫画“<em>月亮公车</em>”主题的城市景观。
非常推荐几米漫画迷游客在晚上访问游览。</p>
<p><img src="/img/taiwan/moon_bus_outside.jpg" alt="月亮公车"></p>
<p><img src="/img/taiwan/moon_bus_interior.jpg" alt="月亮公车内部"></p>
<p>台北另一个必去之处是<em>台北故宫博物院</em>。台北故宫博物院的规模不大，甚至只有一般博物馆大小的展览面积，
但是博物馆藏品确实是原紫禁城的藏品当中的精品。需要注意的是因为展览面积不大，大部分藏品实际上都保存在仓库里，
展览厅当中的特展厅会分批次的展览其中的一小部分藏品，因此不同时间去可能会看到不同的展品。
另外，台北故宫博物院新设立了台南分院，一部分精品展品也会流转到那边展览。
我们这次参观的时候就很不凑巧地错过了镇馆之宝。</p>
<p>台北故宫博物院实际上处于台北市郊，没有地铁直达，需要乘公交或打车前往。博物馆禁止拍照和携带背包、水杯进入，
里面也没有饮水机，因此前往参观之前别忘记喝水。比较有趣的是在博物馆主馆侧面还有一个人迹罕至的文史资料馆，
主要记载了台北故宫博物院文物在历史上碾转来到台湾的历程，以及先总统蒋介石对保护这些文物免遭战乱和“文化大革命”
破坏的历史功绩，看起来也是非常有意思的。</p>
<p><img src="/img/taiwan/taipei_imperial_palace_museum.jpg" alt="台北故宫博物院"></p>
<p>如果是自由行，一个比较冷门的可以参观地方是<em>国立台湾大学</em>。台大是一个开放式的大学，它与外面的街道都是开放式连接的，
只有少部分地区有围墙。台大有一个安静的校园，大部分建筑都有一种美国老牌大学那种欧式的风格，
不过我最喜欢的还是简约现代风格的<em>辜振甫先生纪念图书馆</em>。</p>
<p><img src="/img/taiwan/memorial_library_of_guzhenfu.jpg" alt="辜振甫先生纪念图书馆"></p>
<p>除了这些观光景点之外，在台北的街道行走也别有风味。台北能让你感觉到华人社会在文化和生活方式上即相同又有差异的地方。
台北不像大陆的一二线城市那样，大部分餐饮都已经被连锁企业垄断（就好像北京的簋街那样总共只有三个不同牌子的店），
大部分家庭自营小店还是生存了下来。在台北寻访这种店铺访问怎能不说是一大乐趣？除了这些自营的店铺，
台北的观光夜市也是观光客趋之若鹜的地方。台北的观光夜市有很多条，譬如著名的<em>士林夜市</em>和<em>饶河夜市</em>。
台北的观光夜市消费水平都比较低，来这里吃小吃解决晚饭也是穷游的一个方法。</p>
<p><img src="/img/taiwan/raohe_st_night_market.jpg" alt="饶河观光夜市"></p>
<p>在夜市可以品尝的特色小吃包括胡椒饼、传统豆花、丝袜奶茶、各种烧烤食物、炸鸡排等。这些小吃店铺对大陆游客来说往往别具风格。
尽管在我看来，台湾正宗的“台湾奶茶”跟国内连锁奶茶店销售的味道并没有他大差别，
但是在士林夜市的出口品尝台湾有名的豪大大鸡排（大陆连锁店叫正豪大大）的感觉那叫一个幸福。</p>
<p><img src="/img/taiwan/douhua_and_milk_tea.jpg" alt="豆花奶茶店"></p>
<p>值得注意的是在饶河夜市门外还有日本友好城市赠送的机械种，整点报时的时候机械运转会有小木人旋转出来表演。
如果恰好赶上了时间，可以在这里驻足观赏。</p>
<p>在台北购物可以去<em>西门町</em>，那里大部分土特产纪念品什么的都可以买到，譬如牛轧糖、太阳饼等特产什么的。
当然到台北还有一个必须要逛的地方就是<em>诚品书店</em>，在台湾买一些竖排繁体的小说什么的非常有纪念价值，
比如<a href="https://book.douban.com/subject/5243711/" target="_blank" rel="noopener">《台北人》</a>等。作为回墙内的纪念，我买了一本《1984》。</p>
<p><img src="/img/taiwan/chengpin_bookstore.jpg" alt="诚品书店"></p>
<p>因为台湾相对比较开放，因此在台湾比较容易能买到正版的日本漫画以及周边产品，像我这样的动漫粉当然是不会错过的。
在这样一个麻雀虽小但五脏俱全的地方呆上一下午会不会特别慵懒呢？</p>
<p><img src="/img/taiwan/comic_store.jpg" alt="一家漫画店"></p>
<p>台北的街道真的很值得多花时间去转，也许下次再来的时候，可以租一辆本地常见的机车去玩耍？
如果你还没有安排好行程，真的建议你在台北多呆一段时间，而不是去日月潭阿里山这种热门景点去凑热闹。
总而言之，来台湾，人文方面的景观在台北就可以看个七八成了。</p>
<h1 id="u9AD8_u96C4"><a href="#u9AD8_u96C4" class="headerlink" title="高雄"></a>高雄</h1><p>高雄是我们在台湾落脚的第二站，它是台湾南部较为发达的一个城市。我们到达高雄的时候天气很好，
跟民宿的房东交流过才知道高雄属于热带气候，当时十七八度的温度已经算是较冷的时候了。</p>
<p>高雄是个海滨城市，来到这里当然要去海边玩。我们一行的第一个目的地就是西子湾。
高雄市在西子湾这边的干净的街道，给人以海滨城市的一种特殊的风貌。</p>
<p><img src="/img/taiwan/xizi_bay_street.jpg" alt="西子湾附近的街道"></p>
<p>在天气良好的情况下，西子湾的景色确实不可多得，乘轮渡前往一海之隔的旗津岛也是一种不错的体验。
特别是旗津岛的居民往来于两岸生活，面积虽小但也设施齐全。我们乘坐轮渡时恰逢本地的小学组织学生春游，
看着这里生活着的人们日常，让人有种遐想——如果我是生长在这样的城市里，那将会是什么样的体验呢？</p>
<p>旗津岛很适合骑行，在轮渡口组一辆自行车，沿着海岸线游览可以欣赏到很多建筑景观。这里的海鲜据说也比较有名。</p>
<p><img src="/img/taiwan/qijin_island.jpg" alt="旗津岛上的景观"></p>
<p>我们总共只在高雄呆了一天，不小心错过了高雄等另一个热门景观——美丽岛地铁站的光之穹顶。
虽然有所遗憾，但是也留下了再来一次的期许。</p>
<h1 id="u82B1_u83B2"><a href="#u82B1_u83B2" class="headerlink" title="花莲"></a>花莲</h1><p>如果说去台北是为了体验台湾的人文，那么花莲就是游览自然风光的好去处。
花莲附近拥有花东纵谷、太鲁阁国家森林公园等自然风光。花莲的几条观光夜市也是非常有名的。</p>
<p>前往花莲之前需要注意的是，目前的花莲火车站附近其实公共交通并不是特别方便。
原因在于这个火车站是较晚迁移过来的，并非之前老的火车站，因此距离花莲县经济繁荣的地方比较远，
在选择住宿地点的时候需要考虑这个问题。</p>
<p>我们在台湾路行的第一站是太鲁阁线路，这一线路因交通并不方便，我们选择了跟团拼车游。
太鲁阁线路的主要亮点包括清水断崖、白杨步道、七星潭等。其中<em>清水断崖</em>是亮点中的亮点，
如果赶在天气晴好的时候游览，清水断崖会呈现出难以置信的美丽景色。</p>
<p><img src="/img/taiwan/qingshui_duanya.jpg" alt="清水断崖"></p>
<p>白杨步道的看点则是山中峡谷和峡谷中的溪流。这里的水非常清澈。</p>
<p><img src="/img/taiwan/baiyang_budao.jpg" alt="白杨步道"></p>
<p>七星潭是一个特别的景点，因为虽然名字叫七星潭，但是这个潭水早在日据时期就已经被填上了，
现在的七星潭景区就是一个“观海听涛”的地方。这里的海非常蓝。</p>
<p><img src="/img/taiwan/qixingtan.jpg" alt="七星潭（海）"></p>
<p>在太鲁阁线路中途，可以买到原住民土猪肉烤肠，我个人是非常推荐。那土猪肉烤肠配着蒜一起嚼着吃的感受实在是美妙啊。</p>
<p>一般来讲这种一日游大约需要 700 新台币左右，如果通过一些网站的方法可以更加节约一点。
在途中司机回带你去天祥的一家场所吃饭，不过其实你可以拒绝，因为旁边就有 7-11 ，更划算更好吃一点。</p>
<p>太鲁阁线路游玩结束之后，可以去花莲县的商业地带吃饭玩耍。这里比较推荐的美食首先是公正包子店，
这家的包子沾着秘制的酱汁吃起来很香。在这里只需要 25 新台币就可以喝到一大杯新鲜的豆浆，非常划算。
花莲地区的观光夜市现在都集中在一个地方了，就在海边专门开辟出一片小吃街。在花莲的观光夜市，
最知名的也需要数<em>蒋家官财板</em>了：拿一片后切面包，三面挖开，将菜料填入，再把上层盖上，就成了独有小吃“官财板”。
蒋家官财板尽管排队很长，但是效率也很高，很快就可以吃到嘴里。</p>
<p><img src="/img/taiwan/jiangjia_guancaiban.jpg" alt="蒋家官财板"></p>
<p>在花莲游玩的第二条线路是<em>花东纵谷</em>线，这条线路是沿着纵谷中的公路途中多个景点组成的，
譬如清水农场、北回归线碑、瑞穗牧场等。这条线路很难通过公共交通游览，也是需要租车或者拼车的。
我们采取的方式是乘坐铁路区间车前往瑞穗，在瑞穗租赁电动车前往骑行。也可以选择直接租赁机车，
但是机车需要国际驾照才能行驶，大陆的驾照并不被认可。我们这天的旅行很不巧赶上了阴雨天气，
在雨中骑行之后我们果断选择了<em>瑞穗温泉</em>作为我们旅程的终点。</p>
<p>瑞穗温泉是这一代比较古老的温泉之一，在这里可以单间泡也可以集体泡。需要注意的是集体泡池需要穿泳衣进入，
因此想要体验一把温泉的旅客要提前自备泳衣和浴巾等。</p>
<p>在花莲的旅程尽管遭遇了阴雨天气，但是那里的自然风光还是给我们留下了不错的印象。
清水断崖不愧为台湾十景之一，而七星潭的海也不啻为休闲玩乐的好去处。</p>
<h1 id="u4E5D_u4EFD_uFF0F_u5E73_u6EAA_uFF0F_u745E_u82B3"><a href="#u4E5D_u4EFD_uFF0F_u5E73_u6EAA_uFF0F_u745E_u82B3" class="headerlink" title="九份／平溪／瑞芳"></a>九份／平溪／瑞芳</h1><p>九份是我们台湾之行的最后一站，也是原计划当中最高潮的一部分。在我们停留九份的这两天，九份没有让我们失望。
九份的旅游热点就是<em>九份古街</em>，这是一座建在山坡上的城中最热闹的街道。九份古街因为曾经出现在电影中而热闹了起来，
还有传言说他是宫崎骏《千与千寻》电影当中街道的原型。为了能欣赏到最美好的风光，我们果断在山顶预定了民宿，
当清晨的阳光照进来的时候，我们走出门外，九份老城和远方的海和云在交织在一起，实在是美不胜收。</p>
<p><img src="/img/taiwan/jiufen.jpg" alt="九份海景"></p>
<p>至于传言九份是千寻的原型，可能是从九份古街当中的一家名叫“阿妹茶楼”的店而来的，
店的旁边还有汤婆婆的排位哦（虽然我觉得这个汤婆婆和千寻当中的并不是一回事）。</p>
<p><img src="/img/taiwan/amei_tea_booth.jpg" alt="阿妹茶楼"></p>
<p>在九份还有一些诸如黄金展览馆、阴阳海等等景观，因为天气原因，我们要么只粗略浏览了，要么放弃浏览了。
这些地方有的还是很值得一转的。</p>
<p>我们旅途的最高潮就是在平溪举办的国际天灯节了。这个天灯节被 Discovery 和美国国家地理评价为一生必须参加的活动之一，
而我们旅行的时间恰好覆盖了他的举办时间——元宵节。台湾人对于元宵节非常重视，除了天灯节之外，以往还会举办台北灯会。
灯会现在才用的是各县市申办的方式，今年在桃源举办。经过艰难的抉择，我们最终选择了在平溪举办的天灯节。
选择在这一天释放天灯，祈福未来。</p>
<p>参加平溪天灯节需要注意的是，一般天灯节每年会有三场，除了元宵节之外，其中一场可能会在情人节举办。
举办的地点可能是平溪旅游线路上的平溪、十分等地，但是元宵节举办的最盛大的灯会一定是在十分的<em>十分广场</em>。
台铁的十分站以及由那里延伸出来的十分老街是一条别具风格的街道。你可以看到铁路从街道当中穿过，
街道两边紧贴着就是店铺，在铁路和人之间没有栅栏，游人们就在铁路上释放天灯、品尝小吃。
当有火车来的时候，吹哨鸣笛，大家呼呼啦啦躲到一边让铁路通过。在这种特别的街道游览确实是罕见的体验。</p>
<p><img src="/img/taiwan/train_run_pass_people.jpg" alt="火车从人群当中通过"></p>
<p>在十分车站这条铁路上，你可以随意释放自己的天灯，但是想要参加平溪灯会集体释放上百只天灯，则必须要提前报名才行。
天灯节释放的天灯是分批次的，这些天灯要提前去领天灯票。领到天灯票之后可以获得一只免费的天灯，
并且按照指定的时间进入十分广场当中亲手释放，但是这些灯票是先到先得的。今年的天灯票从上午十点开始发放，
十二点的时候就已经发放完毕了，我们很遗憾没能抢到一张，只好在旁边欣赏上百只天灯齐飞的壮观场景。</p>
<p><img src="/img/taiwan/tiandeng_fly.jpg" alt="施放天灯"></p>
<p>在台湾欣赏过九份古街的美景和天灯节放天灯的壮观景象之后，在瑞芳呆了最后一天作为停留，
瑞芳是一个典型的台湾小镇的感觉，它没有台北那种现代化的规模，给人一种小家碧玉的感觉。
我们留宿的青旅老板很热情，为我们介绍了瑞芳的各种吃喝玩乐。我们去尝试了台铁便当以及特色小吃<em>龙凤腿</em>，
在来台的最后一个城市我们度过了悠闲的时光。</p>
<p><img src="/img/taiwan/taiwan_beer.jpg" alt="喝台湾啤酒，吃花生和龙凤腿"></p>
<h1 id="u9519_u8FC7_u7684_u5730_u65B9"><a href="#u9519_u8FC7_u7684_u5730_u65B9" class="headerlink" title="错过的地方"></a>错过的地方</h1><p>对于其他人来说，我们在台湾错过的地方可能是阿里山和日月潭，但是我们却觉得错过的最遗憾的地方是垦丁。
垦丁是台湾的最南端，没有铁路通行，只能通过大巴前往。垦丁也是一个看海和玩水的地方，
因为垦丁比较靠南，气候温暖，因此四季都可以作为海滨浴场，想要下海游玩的话垦丁是最佳的选择。</p>
<p>而就我个人来说，我还是错过了太多台湾的街道。在台北、在高雄，在很多地方，我们都没有细细地品味这些城市本身。
我们不断地从一个景点赶到另一个景点，却没有能够留下充足的时间在这些街道上多走走，看看这里的人和他们的生活。
如果还有下次，我希望能够安排一段更佳悠闲的行程。</p>
<h1 id="u611F_u60F3_u548C_u603B_u7ED3"><a href="#u611F_u60F3_u548C_u603B_u7ED3" class="headerlink" title="感想和总结"></a>感想和总结</h1><p>从台湾回来快要一个月了，终于完成了台湾之行的游记。在去台湾旅行的这段行程当中，我们游览了台湾的城市景观和自然风光，
近距离接触了这群与我们同宗同源却因为种种原因隔绝了多年的同胞。</p>
<p>让我印象最深刻的其实是台湾人从青壮年到老年人对自由这一理念的珍视以及对自己所拥有自由的自信。
很多被他们看作基本权力的东西，譬如言论自由的权利、自由访问互联网的权利，在这边还要在社会上争论到底要不要被限制。</p>
<p>在同胞们已经解决了政治制度之时，我们还深受其苦。一想到这里我就觉得有些忧伤。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>欢迎来到《台湾小游之城市篇》，这篇文章是我台湾之行的分城市总结。我将按照时间顺序分别介绍台北、
高雄、花莲（瑞穗）、瑞芳以及在旅途中了解到的其他一些没去过的地方的经验。最后还有一点对这次台湾之行的总结。</p>]]>
    
    </summary>
    
      <category term="life" scheme="https://io-meter.com/tags/life/"/>
    
      <category term="travel" scheme="https://io-meter.com/tags/travel/"/>
    
      <category term="taiwan" scheme="https://io-meter.com/tags/taiwan/"/>
    
      <category term="city" scheme="https://io-meter.com/tags/city/"/>
    
      <category term="essay" scheme="https://io-meter.com/categories/essay/"/>
    
  </entry>
  
</feed>
