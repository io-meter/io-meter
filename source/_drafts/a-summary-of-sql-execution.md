---
title: OLAP 任务的 SQL 执行模型总结
date: 2019-01-06 20:54:58
tags: [SQL, execution, database, OLAP]
---

之前的《[SQL 查询优化原理与 Volcano Optimizer 介绍](https://zhuanlan.zhihu.com/p/48735419)》
对优化 SQL 并获得执行方案的算法进行了总结。 本文将会介绍 OLAP 场景下高效运行物理执行方案的模型和算法。

<!-- more -->

一般来说，经过优化器处理获得的物理执行方案已经相当高效了。
很多数据库都直接使用大家都比较熟悉的 Volcano 执行模型(请注意执行模型和优化算法的区别)。
然而为了不断地压榨新硬件技术的性能，数据库的架构和物理模型的执行算法也有了很多发展。

根据运行环境和应用场景等因素的不同，物理执行的优化技巧种类丰富且形式多样，
本文将试图从仅着眼于对 OLAP 任务优化的场景下一小部分模型中抽象出一些设计思想，
希望能对大家有所启发。

本文也会结合一些新近的系统和论文如 Weld 和 Google F1 来阐述这些设计思想的应用。

## 基础模型

### 火山/迭代器(Volcano/Iterator)模型

在上面提到的优化器介绍文章中，我们知道 SQL 优化器的输出是一套树形的物理执行方案，
这一方案的叶子节点是外部输入(如 Scan 表)或值列表(如 VALUES)。这些外部节点将每一行数据以元组(Tuple)
的形式向上传递流经各个 Operator 直到最终输出结果。Volcano 模型就是对这一描述的直接实现。

具体来说，在 Volcano 模型中，每个 Operator 都实现了`getNext`方法，此方法每次调用将会输出一个元组，
计算方案从根结点开始调用`getNext`，每个 Operator 又递归地调用下层的算子，直到所有结果被输出。

![Volcano/Iterator Model]()

从上面的描述可以看出，每个算子都实现了类似迭代器的接口，因此此模型又被称作迭代器模型。

然而，这个简单的模型的问题也比较明显:

1. 递归调用链的问题：假设有一条比较长的 Operator 链，每次获得一个元组都需要从根结点一路递归调用到底层节点，
产生了相当可观的 Over head。
2. Cache Locality 问题：计算不断地在不同 Operator 之间跳转，且每次一个 Operator 被调用时只处理一个元组，
这样现代 CPU 架构不一定是缓存友好的
3. 并发控制的问题：设想又一个 Operator 存在好几个子输入(如 JOIN)节点，在最 Naive 的实现当中这个 Operator
需要依次等待每个输入返回结果，此时对于支持多线程的系统来说系统资源并没有被充分利用

鉴于现阶段绝大部分数据库都采用了 Volcano/Iterator 模型，在执行过程中应用的优化技巧很多也就是针对上述几个问题。
我们将在后文逐步介绍几种常见的方法。

### 物化(Materialization)模型 

由于 Volcano 模型相当简单及常用，所以更简单的物化模型往往被人忽视。
物化模型指的是使每个 Operator 逐一执行，每次读入它所需的所有输入，并将产生的结果全部输出到储存设备上。
输出结果的过程即为“物化”。下图展示了物化模型的执行序列:

![Materialization Model]()

物化模型的缺点十分明显：需要大量的储存空间，在 IO 速度较慢的时候十分影响性能。虽然如此，
物化模型却不存在 Volcano 模型存在的 1 和 2 两种问题。其中原因也很简单，物化模型会根据依赖关系，
从方案树的叶子节点开始调用 Operator，每个 Operator 的输入在执行前都已经准备好，因此只会执行一次。
执行过程中，一个 Operator 也是独占 CPU 资源，不存在 Context 切换的问题。

物化模型通常只使用在 OLTP 这种中间结果规模较小的情况。尽管如此，其设计依然有参考价值。
实际上，Volcano 模型并不能完全避免物化，一些 Operator 如 SORT 等天然需要将结果输出保存。

### 向量(Vectorization)模型

针对 Volcano 模型的一个很直接的优化就是向量模型。其思路也非常简单，
在实现迭代器的时候，与其依次返回一个元组，不如让每个 Operator 批量处理并返回一个向量的元组。
这种模型可以认为是介于迭代器模型和物化模型之间的解决方案。

![Materialization Model]()

这种解决方案减轻了迭代器模型中前两个问题对性能的影响，这是因为随着批量处理的加入，
调用 Operator 和 Context 切换的次数减少了。通过调整向量模型中每次处理的元素数量，
还可以使得这些输入输出的中间结果都可以大概地嵌入 CPU 的 Cache 里，避免内存 IO。
这极大程度地提高了性能。

实际上向量模型的优势不止于此，从接下来的文章里我们可以看到这一模型也为使用 CPU 的 SIMD
指令实现并行计算加速提供了方便。


## 加速执行

实现查询速度提升的第一个方向是加速执行，也就是通过更好地利用计算机系统的资源使得查询更快完成。
这个方向的优化往往需要结合硬件系统和底层操作系统的特点，采取有针对性的措施。

由于硬件类型和运行环境的差异，实现这类优化方法往往，目前来说普适性较强的几种方法是：

1. 管线(Pipeline)处理
2. 编译执行
3. 向量指令(Vectorized)执行

### 管线处理模型

管线处理模型是对迭代器模型和向量模型的优化。在最朴素的迭代器和向量模型中，
每个 Operator 的计算仍然是立即物化的。也就是说，每次一个算子被调用，它先将所有的输入读入，
进行计算处理之后，再将结果输出到 Cache、内存或外部储存中。在这一过程中向量模型仍有可以借鉴迭代器模型的方面。
为了说明这一点，请看下图当中对于一个简单的 SQL 执行方案在迭代器模型和向量模型下的伪代码。

![Pseudo-Code]()

在上述例子中，尽管向量模型减少了函数调用的次数，但是由于其储存中间结果需要多个数组，
因此占用的 CPU 缓存和内存空间更多，因此出现缓存失效的概率也上升了。为了减轻问题影响，
一种解决方案就是使用管线处理：将循环统一提取到最外层，
这样在一次循环中每个算子的调用就如同迭代器模型一样一次只处理一个元素。

这种设计使得中间结果储存的代价大大降低，也减少了指令数。上面提到，对于一些算子必须要全量物化结果，
在管线处理模型中也要处理这种情况，也就是说根据需要物化结果的边界，将树形结构的执行方案划分为多个管线。
下图展示了这种情况:

![Pipeline-Separation]()

除了加速执行上的好处，下文还会提到，使用管线处理也可以减轻并发执行控制的难度。
在之后介绍 Weld 的时候我们将会看到，管线处理实际上是一种叫做算子融合(Operator Fusion)的优化方法的子集。

### 编译执行

编译执行指的是将 SQL 的物理执行方案编译成机器码或者其他更接近硬件的指令(如 JVM Bytecode)执行。
这一优化主要是用来提高 SQL 中条件语句和表达式计算的速度。当采取一般方式执行 SQL 时，
一个条件语句或表达式往往表示成如下所示的表达式树的形式，当进行求解时，其步骤更接近解释型编程语言(如Python等)，
因此性能仍有提升空间。

![Expression Tree]()

归根结底，使用解释器进行表达式计算的主要问题在于冗余的计算指令较多，很多 CPU 时间被花费在解释器自己的执行逻辑上，
表达式的求解因此更加远离硬件了。如果只是求解一次表达式，这种开销还不明显，然而 SQL 往往需要对成千上万的元素进行处理，
因此浪费的时间就十分客观了。

编译执行的主要优点是节省了表达式解释的过程，也避免了在运行时进行诸如运算符匹配和类型检查的操作。
但是值得注意的是，编译执行方案本身需要较长的准备时间，因此只有所执行的 SQL
语句和表达式比较复杂且处理元素很多的情况下才划算，否则很多情况下可能并不如解释执行更优。
在这方面数据库往往通过缓存编译后的代码结果来优化。

一般的数据库中，编译执行的实现方法也比较简单，很多系统使用了拼接C++代码字符串然后调用外部编译工具和库
(如GCC或LLVM)等进行编译。也有直接生成 LLVM 中间表示(IR)的实现。如 PostgreSQL 等数据在新版中内置 LLVM 编译器进行编译，
Apache Calcite 和 SparkSQL 等运行在 JVM 上的工具则使用了 [Janino](https://janino-compiler.github.io/janino/)
编译拼接好的 Java 代码。

### 向量化(Vectorized)执行

向量化执行也是一种针对 CPU 指令进行的优化。它与向量模型不同，指的是利用 CPU 的 SIMD 指令加速代码计算。
这一优化之所以可能的原因在于现代处理器(包括 Intel、AMD 和 ARM)都支持一种基于指令的并行模式。
为了方便理解这种执行模式，请参看下图的表示。

![SIMD Execution]()

可以看到，和一般的多核多线程并发不一样，其所依赖的是 CPU 的寄存器宽度相比之前大大加宽，
因此在处理数组计算时，除了一次将一个元素(64bit)放入寄存器，也可以一次性放入多个元素(如256bit)，
之后应用 SIMD 指令和定义好的运算指令，在电路级别进行批量的处理。这有点像在 32bit 时代，
我们需要用多个指令计算 64bit 长整型的计算，而在 64bit 芯片下只需要一条指令。
也就是说，现代计算机的寄存器已经被扩展到可以支持更宽的数值操作了。

SIMD 指令支持的运算符不单包括加减乘除等数值运算，也可以实现条件运算、过滤运算等。
根据 CPU 支持的一次处理的向量长度，这些计算在数组上都可以获得 4x、8x 乃至 16x 的加速。
这样的加速比可以说十分可观。

显然，向量模型(Vectorization Model)对于向量化执行(Vectorized Execution)十分友好，
在以前，为了实现 SIMD 数据库系统往往需要依赖编译器对某种模式的循环语句的编译优化，譬如如下的代码:

```cpp
for (i = 0; i < len; i++) {
    c[i] = a[i] * b[i];
}
```

在一些编译器进行优化时就可以自动的转化成 SIMD 指令。
然而编译器对于可以优化的模式判断比较有限，因此往往需要手动添加编译器 Hint 等方法。
强行使用 CPU 汇编指令又会导致可迁移性下降，因此依赖编译器对数据库系统自己的代码进行优化显得十分繁琐和难以控制。

一种新的思路就是结合上述编译执行方案的方法进行优化，数据库系统在运行时调用 LLVM 编译链的同时加入对 SIMD
指令执行的支持显然是一种更优雅的方法。遗憾的是，虽然 JVM 较新版本的 JIT 编译器支持将代码转换为 SIMD 指令，
这一过程往往非常局限且难以控制。因此向量化执行这一方法对于运行在 JVM 当中的应用仍不可用。
幸运的是诸如 Weld 这样的编译执行系统被发明出来，从而使得 Python 和 Java 
这样的语言可以通过调用它们获得这样接近硬件的的优化。


## 并行执行

## 模型应用案例
### Weld
### SparkSQL
### Google F1

## 总结
