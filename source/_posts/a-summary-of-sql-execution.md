---
title: OLAP 任务的 SQL 执行模型总结
date: 2019-01-06 20:54:58
tags: [SQL, execution, database, OLAP]
---

之前的《[SQL 查询优化原理与 Volcano Optimizer 介绍](https://zhuanlan.zhihu.com/p/48735419)》
对优化 SQL 并获得执行方案的算法进行了总结。 本文将会介绍 OLAP 场景下高效运行物理执行方案的模型和算法。

<!-- more -->

一般来说，经过优化器处理获得的物理执行方案已经相当高效了。
很多数据库都直接使用大家都比较熟悉的 Volcano 执行模型(请注意执行模型和优化算法的区别)。
然而为了不断地压榨新硬件技术的性能，数据库的架构和物理模型的执行算法也有了很多发展。

根据运行环境和应用场景等因素的不同，物理执行的优化技巧种类丰富且形式多样，
本文将试图从仅着眼于对 OLAP 任务优化的场景下一小部分模型中抽象出一些设计思想，
希望能对大家有所启发。

本文也会结合一些新近的系统和论文如 Weld 和 Google F1 来阐述这些设计思想的应用。

## 基础模型

### 火山/迭代器(Volcano/Iterator)模型

在上面提到的优化器介绍文章中，我们知道 SQL 优化器的输出是一套树形的物理执行方案，
这一方案的叶子节点是外部输入(如 Scan 表)或值列表(如 VALUES)。这些外部节点将每一行数据以元组(Tuple)
的形式向上传递流经各个 Operator 直到最终输出结果。Volcano 模型就是对这一描述的直接实现。

具体来说，在 Volcano 模型中，每个 Operator 都实现了`getNext`方法，此方法每次调用将会输出一个元组，
计算方案从根结点开始调用`getNext`，每个 Operator 又递归地调用下层的算子，直到所有结果被输出。

![Volcano/Iterator Model]()

从上面的描述可以看出，每个算子都实现了类似迭代器的接口，因此此模型又被称作迭代器模型。

然而，这个简单的模型的问题也比较明显:

1. 递归调用链的问题：假设有一条比较长的 Operator 链，每次获得一个元组都需要从根结点一路递归调用到底层节点，
产生了相当可观的 Over head。
2. Cache Locality 问题：计算不断地在不同 Operator 之间跳转，且每次一个 Operator 被调用时只处理一个元组，
这样现代 CPU 架构不一定是缓存友好的
3. 并发控制的问题：设想又一个 Operator 存在好几个子输入(如 JOIN)节点，在最 Naive 的实现当中这个 Operator
需要依次等待每个输入返回结果，此时对于支持多线程的系统来说系统资源并没有被充分利用

鉴于现阶段绝大部分数据库都采用了 Volcano/Iterator 模型，在执行过程中应用的优化技巧很多也就是针对上述几个问题。
我们将在后文逐步介绍几种常见的方法。

### 物化(Materialization)模型 

由于 Volcano 模型相当简单及常用，所以更简单的物化模型往往被人忽视。
物化模型指的是使每个 Operator 逐一执行，每次读入它所需的所有输入，并将产生的结果全部输出到储存设备上。
输出结果的过程即为“物化”。下图展示了物化模型的执行序列:

![Materialization Model]()

物化模型的缺点十分明显：需要大量的储存空间，在 IO 速度较慢的时候十分影响性能。虽然如此，
物化模型却不存在 Volcano 模型存在的 1 和 2 两种问题。其中原因也很简单，物化模型会根据依赖关系，
从方案树的叶子节点开始调用 Operator，每个 Operator 的输入在执行前都已经准备好，因此只会执行一次。
执行过程中，一个 Operator 也是独占 CPU 资源，不存在 Context 切换的问题。

物化模型通常只使用在 OLTP 这种中间结果规模较小的情况。尽管如此，其设计依然有参考价值。
实际上，Volcano 模型并不能完全避免物化，一些 Operator 如 SORT 等天然需要将结果输出保存。

### 向量(Vectorized)模型

针对 Volcano 模型的一个很直接的优化就是向量模型。其思路也非常简单，
在实现迭代器的时候，与其依次返回一个元组，不如让每个 Operator 批量处理并返回一个向量的元组。
这种模型可以认为是介于迭代器模型和物化模型之间的解决方案。

![Materialization Model]()

这种解决方案减轻了迭代器模型中前两个问题对性能的影响，这是因为随着批量处理的加入，
调用 Operator 和 Context 切换的次数减少了。通过调整向量模型中每次处理的元素数量，
还可以使得这些输入输出的中间结果都可以大概地嵌入 CPU 的 Cache 里，避免内存 IO。
这极大程度地提高了性能。

实际上向量模型的优势不止于此，从接下来的文章里我们可以看到这一模型也为使用 CPU 的 SIMD
指令实现并行计算加速提供了方便。


## 加速执行

## 并行执行

## All in One: Weld to rescue

## 模型的推广：分布式批处理系统

### SparkSQL
### Google F1
